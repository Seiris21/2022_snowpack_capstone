{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seiris21/2022_snowpack_capstone/blob/main/notebooks/data_ingestion/SnowCast%20Showdown%20Data%20Wrangling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XQtxwPWn9xYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "007073a9-e687-4cc2-f496-299067ab213e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 6s (42.5 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libgdal-dev is already the newest version (2.2.3+dfsg-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 67 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "gdal-bin is already the newest version (2.2.3+dfsg-2).\n",
            "python-gdal is already the newest version (2.2.3+dfsg-2).\n",
            "python3-gdal is already the newest version (2.2.3+dfsg-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 67 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "python3-rtree is already the newest version (0.8.3+ds-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 67 not upgraded.\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (6.1)\n"
          ]
        }
      ],
      "source": [
        "#%%capture\n",
        "!apt-get update\n",
        "# Install GDAL and Geopandas\n",
        "!apt-get install libgdal-dev \n",
        "!apt install gdal-bin python-gdal python3-gdal --quiet\n",
        "!apt install python3-rtree --quiet\n",
        "!pip install git+git://github.com/geopandas/geopandas.git --quiet\n",
        "\n",
        "%pip install -U tornado"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install \"dask[complete]\"\n",
        "%pip install \"dask[complete]\" --upgrade"
      ],
      "metadata": {
        "id": "izqO08-7767U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3df8062-cc5d-4f0e-cf2f-0e2444514f45"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask[complete] in /usr/local/lib/python3.7/dist-packages (2022.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (6.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.2.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (0.11.2)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (21.3)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2022.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.11.3)\n",
            "Requirement already satisfied: distributed==2022.02.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2022.2.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.21.5)\n",
            "Requirement already satisfied: bokeh>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.3.3)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (6.1)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (5.4.8)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (1.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (57.4.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (2.0.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (2.4.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (7.1.2)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (1.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.1.1->dask[complete]) (3.10.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.1.1->dask[complete]) (2.8.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.1.1->dask[complete]) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->dask[complete]) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->dask[complete]) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->dask[complete]) (2021.3)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask[complete]) (0.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh>=2.1.1->dask[complete]) (1.15.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed==2022.02.0->dask[complete]) (1.0.1)\n",
            "Requirement already satisfied: dask[complete] in /usr/local/lib/python3.7/dist-packages (2022.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (6.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2022.2.0)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.0.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (21.3)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (0.11.2)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.11.3)\n",
            "Requirement already satisfied: bokeh>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.3.3)\n",
            "Requirement already satisfied: distributed==2022.02.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2022.2.0)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.21.5)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (57.4.0)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (5.4.8)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (7.1.2)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (2.4.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (2.0.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (1.7.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed==2022.02.0->dask[complete]) (1.0.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.1.1->dask[complete]) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.1.1->dask[complete]) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.1.1->dask[complete]) (3.10.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->dask[complete]) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->dask[complete]) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->dask[complete]) (2021.3)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask[complete]) (0.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh>=2.1.1->dask[complete]) (1.15.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed==2022.02.0->dask[complete]) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%capture\n",
        "%pip install pystac_client planetary_computer rasterio xarray-spatial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEgdiEnI8wh6",
        "outputId": "dfa783d3-f926-4ab1-c9e4-25074cc74600"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pystac_client in /usr/local/lib/python3.7/dist-packages (0.3.2)\n",
            "Requirement already satisfied: planetary_computer in /usr/local/lib/python3.7/dist-packages (0.4.5)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.7/dist-packages (1.2.10)\n",
            "Requirement already satisfied: xarray-spatial in /usr/local/lib/python3.7/dist-packages (0.3.2)\n",
            "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.7/dist-packages (from pystac_client) (2.27.1)\n",
            "Requirement already satisfied: pystac~=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pystac_client) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7 in /usr/local/lib/python3.7/dist-packages (from pystac~=1.2.0->pystac_client) (3.10.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from pystac~=1.2.0->pystac_client) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.0->pystac~=1.2.0->pystac_client) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25->pystac_client) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25->pystac_client) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25->pystac_client) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25->pystac_client) (2.0.12)\n",
            "Requirement already satisfied: click>=7.1 in /usr/local/lib/python3.7/dist-packages (from planetary_computer) (7.1.2)\n",
            "Requirement already satisfied: pydantic[dotenv]>=1.7.3 in /usr/local/lib/python3.7/dist-packages (from planetary_computer) (1.9.0)\n",
            "Requirement already satisfied: pytz>=2020.5 in /usr/local/lib/python3.7/dist-packages (from planetary_computer) (2021.3)\n",
            "Requirement already satisfied: python-dotenv>=0.10.4 in /usr/local/lib/python3.7/dist-packages (from pydantic[dotenv]>=1.7.3->planetary_computer) (0.19.2)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.7/dist-packages (from rasterio) (2.3.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.21.5)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.7)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from xarray-spatial) (7.1.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from xarray-spatial) (0.51.2)\n",
            "Requirement already satisfied: distributed>=2021.03.0 in /usr/local/lib/python3.7/dist-packages (from xarray-spatial) (2022.2.0)\n",
            "Requirement already satisfied: param>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from xarray-spatial) (1.12.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from xarray-spatial) (1.3.5)\n",
            "Requirement already satisfied: pyct<=0.4.6 in /usr/local/lib/python3.7/dist-packages (from xarray-spatial) (0.4.6)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.7/dist-packages (from xarray-spatial) (2022.2.0)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.7/dist-packages (from xarray-spatial) (0.18.2)\n",
            "Requirement already satisfied: datashader in /usr/local/lib/python3.7/dist-packages (from xarray-spatial) (0.13.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (6.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (2.4.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (1.0.3)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (1.7.0)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (2.11.3)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (0.11.2)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (2.0.0)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (5.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (21.3)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (2.0.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask->xarray-spatial) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask->xarray-spatial) (2022.2.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask->xarray-spatial) (0.2.1)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2021.03.0->xarray-spatial) (1.0.1)\n",
            "Requirement already satisfied: datashape>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from datashader->xarray-spatial) (0.5.2)\n",
            "Requirement already satisfied: colorcet>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from datashader->xarray-spatial) (3.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from datashader->xarray-spatial) (1.4.1)\n",
            "Requirement already satisfied: bokeh>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from dask->xarray-spatial) (2.3.3)\n",
            "Requirement already satisfied: multipledispatch>=0.4.7 in /usr/local/lib/python3.7/dist-packages (from datashape>=0.5.1->datashader->xarray-spatial) (0.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed>=2021.03.0->xarray-spatial) (2.0.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->xarray-spatial) (0.34.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAeHA6UB-JqZ",
        "outputId": "4eac2cd2-2b39-478d-eb19-2a3d2f926d4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lN1ofW4_-OY8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "import geopandas as gpd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "\n",
        "from pystac_client import Client\n",
        "import planetary_computer\n",
        "import xarray\n",
        "import dask.dataframe as dd\n",
        "import xrspatial\n",
        "from datashader.transfer_functions import shade, stack\n",
        "from datashader.colors import Elevation\n",
        "from datashader.utils import export_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBvbkksuJz8F"
      },
      "source": [
        "# Data Ingestion and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MsIAo5K3_9pv"
      },
      "outputs": [],
      "source": [
        "trainfeatures = pd.read_csv(\"/content/drive/MyDrive/snowcapstone team spring 2022/Competition_Data/ground_measures_train_features.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "uhyIte-eARhO",
        "outputId": "0e8b659b-c5ad-401a-f6fe-b1ce588c0162"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4879a79e-89f7-4e71-88c3-fa0cc9f4f082\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>2013-01-01</th>\n",
              "      <th>2013-01-08</th>\n",
              "      <th>2013-01-15</th>\n",
              "      <th>2013-01-22</th>\n",
              "      <th>2013-01-29</th>\n",
              "      <th>2013-02-05</th>\n",
              "      <th>2013-02-12</th>\n",
              "      <th>2013-02-19</th>\n",
              "      <th>2013-02-26</th>\n",
              "      <th>2013-03-05</th>\n",
              "      <th>2013-03-12</th>\n",
              "      <th>2013-03-19</th>\n",
              "      <th>2013-03-26</th>\n",
              "      <th>2013-04-02</th>\n",
              "      <th>2013-04-09</th>\n",
              "      <th>2013-04-16</th>\n",
              "      <th>2013-04-23</th>\n",
              "      <th>2013-04-30</th>\n",
              "      <th>2013-05-07</th>\n",
              "      <th>2013-05-14</th>\n",
              "      <th>2013-05-21</th>\n",
              "      <th>2013-05-28</th>\n",
              "      <th>2013-06-04</th>\n",
              "      <th>2013-06-11</th>\n",
              "      <th>2013-06-18</th>\n",
              "      <th>2013-06-25</th>\n",
              "      <th>2013-12-03</th>\n",
              "      <th>2013-12-10</th>\n",
              "      <th>2013-12-17</th>\n",
              "      <th>2013-12-24</th>\n",
              "      <th>2013-12-31</th>\n",
              "      <th>2014-01-07</th>\n",
              "      <th>2014-01-14</th>\n",
              "      <th>2014-01-21</th>\n",
              "      <th>2014-01-28</th>\n",
              "      <th>2014-02-04</th>\n",
              "      <th>2014-02-11</th>\n",
              "      <th>2014-02-18</th>\n",
              "      <th>2014-02-25</th>\n",
              "      <th>...</th>\n",
              "      <th>2018-05-29</th>\n",
              "      <th>2018-06-05</th>\n",
              "      <th>2018-06-12</th>\n",
              "      <th>2018-06-19</th>\n",
              "      <th>2018-06-26</th>\n",
              "      <th>2018-12-04</th>\n",
              "      <th>2018-12-11</th>\n",
              "      <th>2018-12-18</th>\n",
              "      <th>2018-12-25</th>\n",
              "      <th>2019-01-01</th>\n",
              "      <th>2019-01-08</th>\n",
              "      <th>2019-01-15</th>\n",
              "      <th>2019-01-22</th>\n",
              "      <th>2019-01-29</th>\n",
              "      <th>2019-02-05</th>\n",
              "      <th>2019-02-12</th>\n",
              "      <th>2019-02-19</th>\n",
              "      <th>2019-02-26</th>\n",
              "      <th>2019-03-05</th>\n",
              "      <th>2019-03-12</th>\n",
              "      <th>2019-03-19</th>\n",
              "      <th>2019-03-26</th>\n",
              "      <th>2019-04-02</th>\n",
              "      <th>2019-04-09</th>\n",
              "      <th>2019-04-16</th>\n",
              "      <th>2019-04-23</th>\n",
              "      <th>2019-04-30</th>\n",
              "      <th>2019-05-07</th>\n",
              "      <th>2019-05-14</th>\n",
              "      <th>2019-05-21</th>\n",
              "      <th>2019-05-28</th>\n",
              "      <th>2019-06-04</th>\n",
              "      <th>2019-06-11</th>\n",
              "      <th>2019-06-18</th>\n",
              "      <th>2019-06-25</th>\n",
              "      <th>2019-12-03</th>\n",
              "      <th>2019-12-10</th>\n",
              "      <th>2019-12-17</th>\n",
              "      <th>2019-12-24</th>\n",
              "      <th>2019-12-31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CDEC:ADM</td>\n",
              "      <td>5.90</td>\n",
              "      <td>5.90</td>\n",
              "      <td>6.50</td>\n",
              "      <td>6.50</td>\n",
              "      <td>7.40</td>\n",
              "      <td>7.60</td>\n",
              "      <td>7.40</td>\n",
              "      <td>8.00</td>\n",
              "      <td>8.00</td>\n",
              "      <td>8.00</td>\n",
              "      <td>8.50</td>\n",
              "      <td>6.20</td>\n",
              "      <td>4.10</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1.60</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.50</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.20</td>\n",
              "      <td>2.50</td>\n",
              "      <td>3.10</td>\n",
              "      <td>4.90</td>\n",
              "      <td>4.60</td>\n",
              "      <td>6.30</td>\n",
              "      <td>6.50</td>\n",
              "      <td>10.20</td>\n",
              "      <td>10.90</td>\n",
              "      <td>12.00</td>\n",
              "      <td>14.50</td>\n",
              "      <td>17.00</td>\n",
              "      <td>18.60</td>\n",
              "      <td>20.50</td>\n",
              "      <td>22.60</td>\n",
              "      <td>22.1</td>\n",
              "      <td>21.70</td>\n",
              "      <td>21.30</td>\n",
              "      <td>18.20</td>\n",
              "      <td>15.80</td>\n",
              "      <td>9.80</td>\n",
              "      <td>0.40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.20</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.70</td>\n",
              "      <td>3.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CDEC:AGP</td>\n",
              "      <td>17.52</td>\n",
              "      <td>17.54</td>\n",
              "      <td>17.85</td>\n",
              "      <td>17.39</td>\n",
              "      <td>18.03</td>\n",
              "      <td>17.70</td>\n",
              "      <td>17.65</td>\n",
              "      <td>16.66</td>\n",
              "      <td>17.21</td>\n",
              "      <td>16.26</td>\n",
              "      <td>18.00</td>\n",
              "      <td>18.11</td>\n",
              "      <td>17.96</td>\n",
              "      <td>17.94</td>\n",
              "      <td>11.41</td>\n",
              "      <td>5.39</td>\n",
              "      <td>3.82</td>\n",
              "      <td>3.60</td>\n",
              "      <td>1.06</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1.72</td>\n",
              "      <td>4.16</td>\n",
              "      <td>3.99</td>\n",
              "      <td>3.88</td>\n",
              "      <td>5.70</td>\n",
              "      <td>6.44</td>\n",
              "      <td>7.36</td>\n",
              "      <td>7.24</td>\n",
              "      <td>7.72</td>\n",
              "      <td>8.24</td>\n",
              "      <td>9.49</td>\n",
              "      <td>9.29</td>\n",
              "      <td>8.75</td>\n",
              "      <td>...</td>\n",
              "      <td>1.82</td>\n",
              "      <td>1.98</td>\n",
              "      <td>1.93</td>\n",
              "      <td>1.66</td>\n",
              "      <td>1.56</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CDEC:ALP</td>\n",
              "      <td>12.75</td>\n",
              "      <td>13.32</td>\n",
              "      <td>14.26</td>\n",
              "      <td>14.02</td>\n",
              "      <td>13.39</td>\n",
              "      <td>13.25</td>\n",
              "      <td>14.30</td>\n",
              "      <td>13.95</td>\n",
              "      <td>15.73</td>\n",
              "      <td>15.41</td>\n",
              "      <td>16.99</td>\n",
              "      <td>14.81</td>\n",
              "      <td>15.48</td>\n",
              "      <td>14.85</td>\n",
              "      <td>12.60</td>\n",
              "      <td>8.32</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.46</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.63</td>\n",
              "      <td>1.14</td>\n",
              "      <td>3.18</td>\n",
              "      <td>3.17</td>\n",
              "      <td>3.12</td>\n",
              "      <td>3.09</td>\n",
              "      <td>3.03</td>\n",
              "      <td>3.36</td>\n",
              "      <td>3.03</td>\n",
              "      <td>2.74</td>\n",
              "      <td>2.63</td>\n",
              "      <td>10.87</td>\n",
              "      <td>10.49</td>\n",
              "      <td>10.38</td>\n",
              "      <td>...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7.34</td>\n",
              "      <td>7.56</td>\n",
              "      <td>7.70</td>\n",
              "      <td>9.50</td>\n",
              "      <td>9.87</td>\n",
              "      <td>12.72</td>\n",
              "      <td>13.99</td>\n",
              "      <td>22.74</td>\n",
              "      <td>22.70</td>\n",
              "      <td>30.36</td>\n",
              "      <td>33.76</td>\n",
              "      <td>41.57</td>\n",
              "      <td>44.08</td>\n",
              "      <td>49.38</td>\n",
              "      <td>52.70</td>\n",
              "      <td>52.8</td>\n",
              "      <td>55.08</td>\n",
              "      <td>58.53</td>\n",
              "      <td>59.03</td>\n",
              "      <td>56.72</td>\n",
              "      <td>52.21</td>\n",
              "      <td>44.03</td>\n",
              "      <td>37.23</td>\n",
              "      <td>27.66</td>\n",
              "      <td>28.66</td>\n",
              "      <td>29.52</td>\n",
              "      <td>20.81</td>\n",
              "      <td>8.71</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.69</td>\n",
              "      <td>8.04</td>\n",
              "      <td>10.74</td>\n",
              "      <td>12.67</td>\n",
              "      <td>12.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CDEC:BCB</td>\n",
              "      <td>4.30</td>\n",
              "      <td>4.42</td>\n",
              "      <td>4.62</td>\n",
              "      <td>4.53</td>\n",
              "      <td>4.67</td>\n",
              "      <td>4.90</td>\n",
              "      <td>4.90</td>\n",
              "      <td>5.06</td>\n",
              "      <td>5.11</td>\n",
              "      <td>5.23</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.43</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.50</td>\n",
              "      <td>5.65</td>\n",
              "      <td>5.66</td>\n",
              "      <td>5.80</td>\n",
              "      <td>5.81</td>\n",
              "      <td>5.73</td>\n",
              "      <td>5.62</td>\n",
              "      <td>5.44</td>\n",
              "      <td>5.46</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.78</td>\n",
              "      <td>5.67</td>\n",
              "      <td>5.75</td>\n",
              "      <td>10.49</td>\n",
              "      <td>13.04</td>\n",
              "      <td>13.10</td>\n",
              "      <td>12.82</td>\n",
              "      <td>13.83</td>\n",
              "      <td>14.29</td>\n",
              "      <td>14.02</td>\n",
              "      <td>14.23</td>\n",
              "      <td>13.81</td>\n",
              "      <td>5.18</td>\n",
              "      <td>9.33</td>\n",
              "      <td>9.55</td>\n",
              "      <td>9.12</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CDEC:BCH</td>\n",
              "      <td>2.88</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.48</td>\n",
              "      <td>3.84</td>\n",
              "      <td>3.96</td>\n",
              "      <td>4.44</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.16</td>\n",
              "      <td>3.60</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.48</td>\n",
              "      <td>1.44</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.36</td>\n",
              "      <td>...</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.60</td>\n",
              "      <td>3.12</td>\n",
              "      <td>3.60</td>\n",
              "      <td>3.48</td>\n",
              "      <td>3.48</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.80</td>\n",
              "      <td>4.92</td>\n",
              "      <td>9.00</td>\n",
              "      <td>8.76</td>\n",
              "      <td>11.88</td>\n",
              "      <td>15.36</td>\n",
              "      <td>17.88</td>\n",
              "      <td>18.96</td>\n",
              "      <td>18.96</td>\n",
              "      <td>22.92</td>\n",
              "      <td>22.2</td>\n",
              "      <td>21.24</td>\n",
              "      <td>17.04</td>\n",
              "      <td>10.92</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.88</td>\n",
              "      <td>4.56</td>\n",
              "      <td>4.68</td>\n",
              "      <td>5.04</td>\n",
              "      <td>6.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 214 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4879a79e-89f7-4e71-88c3-fa0cc9f4f082')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4879a79e-89f7-4e71-88c3-fa0cc9f4f082 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4879a79e-89f7-4e71-88c3-fa0cc9f4f082');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Unnamed: 0  2013-01-01  2013-01-08  ...  2019-12-17  2019-12-24  2019-12-31\n",
              "0   CDEC:ADM        5.90        5.90  ...        3.40        3.70        3.40\n",
              "1   CDEC:AGP       17.52       17.54  ...        0.20         NaN         NaN\n",
              "2   CDEC:ALP       12.75       13.32  ...       10.74       12.67       12.57\n",
              "3   CDEC:BCB        4.30        4.42  ...         NaN         NaN         NaN\n",
              "4   CDEC:BCH        2.88        3.00  ...        4.68        5.04        6.00\n",
              "\n",
              "[5 rows x 214 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "trainfeatures.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "l8nO3aAqCzSS",
        "outputId": "2fad267f-241b-42ea-cfa5-b0611820e6f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-16bb1299-d37a-401a-bebe-52918272bb73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>station_id</th>\n",
              "      <th>date</th>\n",
              "      <th>SWE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CDEC:ADM</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>5.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CDEC:AGP</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>17.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CDEC:ALP</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>12.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CDEC:BCB</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>4.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CDEC:BCH</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>2.88</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16bb1299-d37a-401a-bebe-52918272bb73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16bb1299-d37a-401a-bebe-52918272bb73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16bb1299-d37a-401a-bebe-52918272bb73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  station_id        date    SWE\n",
              "0   CDEC:ADM  2013-01-01   5.90\n",
              "1   CDEC:AGP  2013-01-01  17.52\n",
              "2   CDEC:ALP  2013-01-01  12.75\n",
              "3   CDEC:BCB  2013-01-01   4.30\n",
              "4   CDEC:BCH  2013-01-01   2.88"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "trainfeatures = trainfeatures.melt(id_vars=['Unnamed: 0']).dropna().reset_index(drop = True)\n",
        "trainfeatures.rename(columns = {'Unnamed: 0':\"station_id\", \"variable\":\"date\", \"value\":\"SWE\"}, inplace = True)\n",
        "trainfeatures.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#These are dates where no stations had information (Discovered after using KNN approach)\n",
        "#Alternative method: Get all dates of cell_id samples, and compare those dates against what each station has for the interpolation\n",
        "nan_dates = ['2013-04-03', '2013-04-29', '2013-05-03', '2013-05-25', '2013-06-01', '2013-06-08', '2016-02-08', '2016-03-26', '2016-04-01', '2016-04-03', '2016-04-04',\n",
        " '2016-04-07', '2016-04-16', '2016-05-09', '2016-05-27', '2016-06-26', '2017-01-28', '2017-01-29', '2018-03-04', '2018-03-30', '2018-03-31', '2018-04-22', '2018-04-23', \n",
        " '2018-04-25', '2018-04-26', '2018-05-24', '2018-05-28', '2018-06-01', '2018-06-02', '2019-03-09', '2019-03-15', '2019-03-16', '2019-03-17', '2019-03-24', '2019-03-25', \n",
        " '2019-03-29', '2019-04-07', '2019-04-08', '2019-04-17', '2019-04-18', '2019-04-19', '2019-04-21', '2019-04-27', '2019-04-28', '2019-05-01', '2019-05-02', '2019-05-03', \n",
        " '2019-06-05', '2019-06-08', '2019-06-09', '2019-06-10', '2019-06-13', '2019-06-14', '2019-06-24']"
      ],
      "metadata": {
        "id": "Idoe0HdCX19m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear regression implementation, filling in based on nan_dates list\n",
        "supplement = []\n",
        "\n",
        "#Iterate through all the unique stations\n",
        "for station in trainfeatures['station_id'].unique(): #['CDEC:SSM']: #\n",
        "  #Get subset for this station\n",
        "  subset = trainfeatures[trainfeatures['station_id']==station].copy()\n",
        "  #make filler rows with missing dates\n",
        "  filler = [[station,date,np.nan] for date in nan_dates]\n",
        "  #Append filler rows to subset and sort on date and reset index\n",
        "  subset = subset.append(pd.DataFrame(filler, columns=['station_id','date','SWE'])).sort_values(by='date').reset_index(drop=True)\n",
        "  #print(station,len(subset.index))\n",
        "  #print(subset.head())\n",
        "  for date in nan_dates:\n",
        "    #Find NaN date\n",
        "    nan_index = subset.index[subset['date'] == date].tolist()[0]\n",
        "    nan_date = datetime.strptime(date,'%Y-%m-%d')\n",
        "    \n",
        "    #There is a conditional needed for stations that stopped reporting before 2019\n",
        "    try:\n",
        "      count=0\n",
        "      #Find older date that HAS value. Sometimes needed because filler inserted NaNs\n",
        "      while subset.iloc[nan_index-1-count].isnull().any():\n",
        "        count+=1\n",
        "      #Older date (nan-1)\n",
        "      if (nan_index-1-count)>=0:\n",
        "        older_date = datetime.strptime(subset.iloc[nan_index-1-count]['date'],'%Y-%m-%d')\n",
        "        older_swe = subset.iloc[nan_index-1-count]['SWE']\n",
        "      else:\n",
        "        older_date = datetime.strptime(subset.iloc[nan_index-1]['date'],'%Y-%m-%d')\n",
        "        older_swe = np.nan\n",
        "      #print('Older',nan_index-1,older_date,older_swe)\n",
        "      #print('NaN-inserted',nan_index,nan_date)\n",
        "\n",
        "      #Newer date is next date that HAS value, otherwise enter except\n",
        "      counter=0\n",
        "      while subset.iloc[nan_index+1+counter].isnull().any():\n",
        "        counter+=1\n",
        "      #Newer date\n",
        "      newer_date = datetime.strptime(subset.iloc[nan_index+1+counter]['date'],'%Y-%m-%d')\n",
        "      newer_swe = subset.iloc[nan_index+1+counter]['SWE']\n",
        "      #print('newer',nan_index+1+counter,newer_date,newer_swe)\n",
        "      #print('______________________________')\n",
        "\n",
        "      #Change per day\n",
        "      delta_day = (newer_swe-older_swe)/(newer_date-older_date).days\n",
        "\n",
        "      #Add expected change to older swe\n",
        "      est_swe = older_swe + (delta_day*(nan_date-older_date).days)\n",
        "\n",
        "      #Add \"entry\" row to supplement\n",
        "      supplement.append([station,date,est_swe])\n",
        "    #IndexError happens when the last date is actually from the nan list. Because of this, We DEFINITELY need to do some inter-station interpolation\n",
        "    except IndexError:\n",
        "      supplement.append([station,date,np.nan])\n",
        "\n",
        "#Problem with simple linear interpolation: There are large enough gaps that the \"missing days\" in the data sometimes are the closest dates to themselves"
      ],
      "metadata": {
        "id": "20uFlk86YCcx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add incomplete supplement (testing to see how many knn nans are filled in)\n",
        "trainfeatures = trainfeatures.append(pd.DataFrame(supplement, columns=['station_id','date','SWE'])).sort_values(by='date').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "u8_40htVYjCc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "j2_EMS6rFL5k",
        "outputId": "1773dffc-5c1b-450e-ae74-1b4cc89f6d09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5e06a8eb-3053-41d8-b238-08da0c92926e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>station_id</th>\n",
              "      <th>name</th>\n",
              "      <th>elevation_m</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CDEC:ADM</td>\n",
              "      <td>Adin Mountain</td>\n",
              "      <td>1889.76</td>\n",
              "      <td>41.237000</td>\n",
              "      <td>-120.792000</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CDEC:AGP</td>\n",
              "      <td>Agnew Pass</td>\n",
              "      <td>2880.36</td>\n",
              "      <td>37.726631</td>\n",
              "      <td>-119.141731</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CDEC:ALP</td>\n",
              "      <td>Alpha (Smud)</td>\n",
              "      <td>2316.48</td>\n",
              "      <td>38.804192</td>\n",
              "      <td>-120.215652</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CDEC:BCB</td>\n",
              "      <td>Blackcap Basin</td>\n",
              "      <td>3139.44</td>\n",
              "      <td>37.066685</td>\n",
              "      <td>-118.773010</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CDEC:BCH</td>\n",
              "      <td>Beach Meadows</td>\n",
              "      <td>2331.72</td>\n",
              "      <td>36.126095</td>\n",
              "      <td>-118.293457</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e06a8eb-3053-41d8-b238-08da0c92926e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e06a8eb-3053-41d8-b238-08da0c92926e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e06a8eb-3053-41d8-b238-08da0c92926e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  station_id            name  elevation_m   latitude   longitude       state\n",
              "0   CDEC:ADM   Adin Mountain      1889.76  41.237000 -120.792000  California\n",
              "1   CDEC:AGP      Agnew Pass      2880.36  37.726631 -119.141731  California\n",
              "2   CDEC:ALP    Alpha (Smud)      2316.48  38.804192 -120.215652  California\n",
              "3   CDEC:BCB  Blackcap Basin      3139.44  37.066685 -118.773010  California\n",
              "4   CDEC:BCH   Beach Meadows      2331.72  36.126095 -118.293457  California"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "trainmeta = pd.read_csv(\"/content/drive/MyDrive/snowcapstone team spring 2022/Competition_Data/ground_measures_metadata.csv\")\n",
        "trainmeta.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MoHOpJocFcCd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f177a016-87e5-45b7-bd05-5db8810b4581"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-56f850d6-7ac6-42b1-bb09-b008ca4fa5e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>station_id</th>\n",
              "      <th>date</th>\n",
              "      <th>SWE</th>\n",
              "      <th>name</th>\n",
              "      <th>elevation_m</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CDEC:ADM</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>5.9</td>\n",
              "      <td>Adin Mountain</td>\n",
              "      <td>1889.760000</td>\n",
              "      <td>41.237000</td>\n",
              "      <td>-120.792000</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SNOTEL:628_UT_SNTL</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>9.8</td>\n",
              "      <td>Mill-D North</td>\n",
              "      <td>2731.922363</td>\n",
              "      <td>40.658829</td>\n",
              "      <td>-111.636833</td>\n",
              "      <td>Utah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SNOTEL:629_CO_SNTL</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>3.6</td>\n",
              "      <td>Mineral Creek</td>\n",
              "      <td>3060.191895</td>\n",
              "      <td>37.847469</td>\n",
              "      <td>-107.726570</td>\n",
              "      <td>Colorado</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SNOTEL:633_CA_SNTL</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>9.4</td>\n",
              "      <td>Monitor Pass</td>\n",
              "      <td>2531.668701</td>\n",
              "      <td>38.668301</td>\n",
              "      <td>-119.608704</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SNOTEL:637_ID_SNTL</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>6.9</td>\n",
              "      <td>Mores Creek Summit</td>\n",
              "      <td>1859.280029</td>\n",
              "      <td>43.931999</td>\n",
              "      <td>-115.665878</td>\n",
              "      <td>Idaho</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56f850d6-7ac6-42b1-bb09-b008ca4fa5e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56f850d6-7ac6-42b1-bb09-b008ca4fa5e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56f850d6-7ac6-42b1-bb09-b008ca4fa5e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           station_id        date  SWE  ...   latitude   longitude       state\n",
              "0            CDEC:ADM  2013-01-01  5.9  ...  41.237000 -120.792000  California\n",
              "1  SNOTEL:628_UT_SNTL  2013-01-01  9.8  ...  40.658829 -111.636833        Utah\n",
              "2  SNOTEL:629_CO_SNTL  2013-01-01  3.6  ...  37.847469 -107.726570    Colorado\n",
              "3  SNOTEL:633_CA_SNTL  2013-01-01  9.4  ...  38.668301 -119.608704  California\n",
              "4  SNOTEL:637_ID_SNTL  2013-01-01  6.9  ...  43.931999 -115.665878       Idaho\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "trainfeatures = trainfeatures.merge(trainmeta, how = 'left', on='station_id')\n",
        "trainfeatures.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrRzKQu9G8pL",
        "outputId": "a1924a12-7b05-4d39-adea-d5d61dbe4345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                cell_id  ...                                           geometry\n",
            "0  0003f387-71c4-48f6-b2b0-d853bd4f0aba  ...  POLYGON ((-118.71895 37.07419, -118.71895 37.0...\n",
            "1  000617d8-8c14-43e2-b708-7e3a69fe3cc3  ...  POLYGON ((-107.07679 37.78042, -107.07679 37.7...\n",
            "2  000863e7-21e6-477d-b799-f5675c348627  ...  POLYGON ((-119.40167 37.02400, -119.40167 37.0...\n",
            "3  000ba8d9-d6d5-48da-84a2-1fa54951fae1  ...  POLYGON ((-119.32082 37.43171, -119.32082 37.4...\n",
            "4  00146204-d4e9-4cd8-8f86-d1ef133c5b6d  ...  POLYGON ((-118.52132 36.65735, -118.52132 36.6...\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "gridcells = gpd.read_file('/content/drive/MyDrive/snowcapstone team spring 2022/Competition_Data/grid_cells.geojson')\n",
        "print(gridcells.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "QBFn6NWaOnlu",
        "outputId": "f15e379a-cb15-4ff3-f190-4c1a45e33cc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-72632053-cdf7-4e1f-bd0b-344fdcc4c8ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell_id</th>\n",
              "      <th>date</th>\n",
              "      <th>SWE</th>\n",
              "      <th>region</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00c4db22-a423-41a4-ada6-a8b1b04153a4</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>12.7</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-121.93492 41.16327, -121.93492 41.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>018cf1a1-f945-4097-9c47-0c4690538bb5</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>20.4</td>\n",
              "      <td>sierras</td>\n",
              "      <td>POLYGON ((-120.61440 39.67242, -120.61440 39.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01be2cc7-ef77-4e4d-80ed-c4f8139162c3</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>37.0</td>\n",
              "      <td>sierras</td>\n",
              "      <td>POLYGON ((-119.60829 38.27575, -119.60829 38.2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>02c3ec4a-8de4-4284-9ec1-5a942d3d098e</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>2.3</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-107.19357 44.57879, -107.19357 44.5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>02cf33c2-c8e2-48b9-bf72-92506e97e251</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>8.0</td>\n",
              "      <td>central rockies</td>\n",
              "      <td>POLYGON ((-106.60068 40.39461, -106.60068 40.4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91485</th>\n",
              "      <td>fd4492f2-8aa9-4279-bdc0-73991786943f</td>\n",
              "      <td>2019-12-31</td>\n",
              "      <td>1.3</td>\n",
              "      <td>central rockies</td>\n",
              "      <td>POLYGON ((-105.07354 38.87270, -105.07354 38.8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91486</th>\n",
              "      <td>fde3221a-9ce3-45a9-857f-bd196b07aa05</td>\n",
              "      <td>2019-12-31</td>\n",
              "      <td>5.6</td>\n",
              "      <td>central rockies</td>\n",
              "      <td>POLYGON ((-106.10661 39.29804, -106.10661 39.3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91487</th>\n",
              "      <td>fdeb8912-f9d1-445d-aadb-e943534f67fe</td>\n",
              "      <td>2019-12-31</td>\n",
              "      <td>8.8</td>\n",
              "      <td>central rockies</td>\n",
              "      <td>POLYGON ((-107.92120 37.79462, -107.92120 37.8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91488</th>\n",
              "      <td>fe33672e-7ea7-4c5d-8639-96b2cc7edb0c</td>\n",
              "      <td>2019-12-31</td>\n",
              "      <td>2.9</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-122.02475 43.89659, -122.02475 43.9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91489</th>\n",
              "      <td>ff01e8c2-19a2-4a89-af0e-608b8f40ad5f</td>\n",
              "      <td>2019-12-31</td>\n",
              "      <td>4.7</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-111.37972 44.41861, -111.37972 44.4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91490 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72632053-cdf7-4e1f-bd0b-344fdcc4c8ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72632053-cdf7-4e1f-bd0b-344fdcc4c8ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72632053-cdf7-4e1f-bd0b-344fdcc4c8ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    cell_id  ...                                           geometry\n",
              "0      00c4db22-a423-41a4-ada6-a8b1b04153a4  ...  POLYGON ((-121.93492 41.16327, -121.93492 41.1...\n",
              "1      018cf1a1-f945-4097-9c47-0c4690538bb5  ...  POLYGON ((-120.61440 39.67242, -120.61440 39.6...\n",
              "2      01be2cc7-ef77-4e4d-80ed-c4f8139162c3  ...  POLYGON ((-119.60829 38.27575, -119.60829 38.2...\n",
              "3      02c3ec4a-8de4-4284-9ec1-5a942d3d098e  ...  POLYGON ((-107.19357 44.57879, -107.19357 44.5...\n",
              "4      02cf33c2-c8e2-48b9-bf72-92506e97e251  ...  POLYGON ((-106.60068 40.39461, -106.60068 40.4...\n",
              "...                                     ...  ...                                                ...\n",
              "91485  fd4492f2-8aa9-4279-bdc0-73991786943f  ...  POLYGON ((-105.07354 38.87270, -105.07354 38.8...\n",
              "91486  fde3221a-9ce3-45a9-857f-bd196b07aa05  ...  POLYGON ((-106.10661 39.29804, -106.10661 39.3...\n",
              "91487  fdeb8912-f9d1-445d-aadb-e943534f67fe  ...  POLYGON ((-107.92120 37.79462, -107.92120 37.8...\n",
              "91488  fe33672e-7ea7-4c5d-8639-96b2cc7edb0c  ...  POLYGON ((-122.02475 43.89659, -122.02475 43.9...\n",
              "91489  ff01e8c2-19a2-4a89-af0e-608b8f40ad5f  ...  POLYGON ((-111.37972 44.41861, -111.37972 44.4...\n",
              "\n",
              "[91490 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "traindf = pd.read_csv(\"/content/drive/MyDrive/snowcapstone team spring 2022/Competition_Data/train_labels.csv\")\n",
        "\n",
        "traindf = traindf.melt(id_vars=[\"cell_id\"]).dropna().reset_index(drop = True)\n",
        "traindf.rename(columns = {\"cell_id\":\"cell_id\", \"variable\":\"date\", \"value\":\"SWE\"}, inplace = True)\n",
        "\n",
        "traindf = traindf.merge(gridcells, how = 'left', on='cell_id')\n",
        "\n",
        "\n",
        "traindf = gpd.GeoDataFrame(traindf, crs =\"EPSG:4326\")\n",
        "traindf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "print(len(traindf.loc[pd.to_datetime(traindf.date) > datetime.strptime(\"2016-01-01\", \"%Y-%m-%d\"), \"region\"]))\n",
        "print(len(traindf.loc[traindf[\"region\"] == \"sierras\", \"region\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKxVUMLeMgiS",
        "outputId": "db7e4aba-36d3-4abb-d553-1aa710665b92"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68670\n",
            "37017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "kX-A4GznjM1D",
        "outputId": "1d11e257-0e08-4832-a508-6c2e801d4407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91490\n",
            "68670\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-62cbcc2c-c348-4d31-a7e2-09982f1ea081\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell_id</th>\n",
              "      <th>date</th>\n",
              "      <th>SWE</th>\n",
              "      <th>region</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00c4db22-a423-41a4-ada6-a8b1b04153a4</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>10.6</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-121.93492 41.16327, -121.93492 41.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>018cf1a1-f945-4097-9c47-0c4690538bb5</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>16.4</td>\n",
              "      <td>sierras</td>\n",
              "      <td>POLYGON ((-120.61440 39.67242, -120.61440 39.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01be2cc7-ef77-4e4d-80ed-c4f8139162c3</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>21.1</td>\n",
              "      <td>sierras</td>\n",
              "      <td>POLYGON ((-119.60829 38.27575, -119.60829 38.2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>02c3ec4a-8de4-4284-9ec1-5a942d3d098e</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>2.0</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-107.19357 44.57879, -107.19357 44.5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>02cf33c2-c8e2-48b9-bf72-92506e97e251</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>9.2</td>\n",
              "      <td>central rockies</td>\n",
              "      <td>POLYGON ((-106.60068 40.39461, -106.60068 40.4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62cbcc2c-c348-4d31-a7e2-09982f1ea081')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-62cbcc2c-c348-4d31-a7e2-09982f1ea081 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-62cbcc2c-c348-4d31-a7e2-09982f1ea081');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                cell_id  ...                                           geometry\n",
              "0  00c4db22-a423-41a4-ada6-a8b1b04153a4  ...  POLYGON ((-121.93492 41.16327, -121.93492 41.1...\n",
              "1  018cf1a1-f945-4097-9c47-0c4690538bb5  ...  POLYGON ((-120.61440 39.67242, -120.61440 39.6...\n",
              "2  01be2cc7-ef77-4e4d-80ed-c4f8139162c3  ...  POLYGON ((-119.60829 38.27575, -119.60829 38.2...\n",
              "3  02c3ec4a-8de4-4284-9ec1-5a942d3d098e  ...  POLYGON ((-107.19357 44.57879, -107.19357 44.5...\n",
              "4  02cf33c2-c8e2-48b9-bf72-92506e97e251  ...  POLYGON ((-106.60068 40.39461, -106.60068 40.4...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "print(len(traindf))\n",
        "traindf = traindf.loc[pd.to_datetime(traindf.date) >= datetime.strptime(\"2016-01-01\", \"%Y-%m-%d\")].reset_index(drop = True)\n",
        "print(len(traindf[\"region\"]))\n",
        "traindf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4-HHxU28O1j1",
        "outputId": "1e5989b6-eae5-43ee-8bec-2e3797865849"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bdd66e1e-7d86-4e04-9220-ff446ae02f0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>station_id</th>\n",
              "      <th>name</th>\n",
              "      <th>elevation_m</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>state</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CDEC:ADM</td>\n",
              "      <td>Adin Mountain</td>\n",
              "      <td>1889.760000</td>\n",
              "      <td>41.237000</td>\n",
              "      <td>-120.792000</td>\n",
              "      <td>California</td>\n",
              "      <td>POINT (-120.79200 41.23700)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CDEC:AGP</td>\n",
              "      <td>Agnew Pass</td>\n",
              "      <td>2880.360000</td>\n",
              "      <td>37.726631</td>\n",
              "      <td>-119.141731</td>\n",
              "      <td>California</td>\n",
              "      <td>POINT (-119.14173 37.72663)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CDEC:ALP</td>\n",
              "      <td>Alpha (Smud)</td>\n",
              "      <td>2316.480000</td>\n",
              "      <td>38.804192</td>\n",
              "      <td>-120.215652</td>\n",
              "      <td>California</td>\n",
              "      <td>POINT (-120.21565 38.80419)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CDEC:BCB</td>\n",
              "      <td>Blackcap Basin</td>\n",
              "      <td>3139.440000</td>\n",
              "      <td>37.066685</td>\n",
              "      <td>-118.773010</td>\n",
              "      <td>California</td>\n",
              "      <td>POINT (-118.77301 37.06668)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CDEC:BCH</td>\n",
              "      <td>Beach Meadows</td>\n",
              "      <td>2331.720000</td>\n",
              "      <td>36.126095</td>\n",
              "      <td>-118.293457</td>\n",
              "      <td>California</td>\n",
              "      <td>POINT (-118.29346 36.12609)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>SNOTEL:989_ID_SNTL</td>\n",
              "      <td>Moscow Mountain</td>\n",
              "      <td>1432.560059</td>\n",
              "      <td>46.805000</td>\n",
              "      <td>-116.853500</td>\n",
              "      <td>Idaho</td>\n",
              "      <td>POINT (-116.85350 46.80500)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>SNOTEL:990_WA_SNTL</td>\n",
              "      <td>Beaver Pass</td>\n",
              "      <td>1106.423950</td>\n",
              "      <td>48.879299</td>\n",
              "      <td>-121.255501</td>\n",
              "      <td>Washington</td>\n",
              "      <td>POINT (-121.25550 48.87930)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>SNOTEL:992_UT_SNTL</td>\n",
              "      <td>Bear River RS</td>\n",
              "      <td>2675.229492</td>\n",
              "      <td>40.885201</td>\n",
              "      <td>-110.827698</td>\n",
              "      <td>Utah</td>\n",
              "      <td>POINT (-110.82770 40.88520)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>SNOTEL:998_WA_SNTL</td>\n",
              "      <td>Easy Pass</td>\n",
              "      <td>1606.296021</td>\n",
              "      <td>48.859329</td>\n",
              "      <td>-121.438950</td>\n",
              "      <td>Washington</td>\n",
              "      <td>POINT (-121.43895 48.85933)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>699</th>\n",
              "      <td>SNOTEL:999_WA_SNTL</td>\n",
              "      <td>Marten Ridge</td>\n",
              "      <td>1072.895996</td>\n",
              "      <td>48.762920</td>\n",
              "      <td>-121.698227</td>\n",
              "      <td>Washington</td>\n",
              "      <td>POINT (-121.69823 48.76292)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>700 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdd66e1e-7d86-4e04-9220-ff446ae02f0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bdd66e1e-7d86-4e04-9220-ff446ae02f0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bdd66e1e-7d86-4e04-9220-ff446ae02f0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             station_id  ...                     geometry\n",
              "0              CDEC:ADM  ...  POINT (-120.79200 41.23700)\n",
              "1              CDEC:AGP  ...  POINT (-119.14173 37.72663)\n",
              "2              CDEC:ALP  ...  POINT (-120.21565 38.80419)\n",
              "3              CDEC:BCB  ...  POINT (-118.77301 37.06668)\n",
              "4              CDEC:BCH  ...  POINT (-118.29346 36.12609)\n",
              "..                  ...  ...                          ...\n",
              "695  SNOTEL:989_ID_SNTL  ...  POINT (-116.85350 46.80500)\n",
              "696  SNOTEL:990_WA_SNTL  ...  POINT (-121.25550 48.87930)\n",
              "697  SNOTEL:992_UT_SNTL  ...  POINT (-110.82770 40.88520)\n",
              "698  SNOTEL:998_WA_SNTL  ...  POINT (-121.43895 48.85933)\n",
              "699  SNOTEL:999_WA_SNTL  ...  POINT (-121.69823 48.76292)\n",
              "\n",
              "[700 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "gdf = gpd.GeoDataFrame(trainmeta, \n",
        "                       geometry = gpd.points_from_xy(trainmeta.longitude, trainmeta.latitude),\n",
        "                       crs = \"EPSG:4326\")\n",
        "\n",
        "gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZxpooIsbdNFY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#fig, ax = plt.subplots(figsize = (240,240))\n",
        "#\n",
        "#states = gpd.read_file('/content/drive/MyDrive/snowcapstone team spring 2022/Competition_Data/USMap/cb_2018_us_state_20m.shp')\n",
        "#states = states.to_crs(\"EPSG:4326\")\n",
        "#states = states[states['STUSPS'].isin(['WA', 'OR', 'CA', 'NV', 'MT', 'ID', 'WY', 'NM', 'CO' ,'UT', 'AZ'])]\n",
        "#statemap = states.boundary.plot(ax=ax, linewidth=5, zorder = 1)\n",
        "#\n",
        "#gpd.GeoDataFrame(traindf[\"geometry\"]).to_crs(states.crs).plot(ax=ax, facecolor=\"none\", edgecolor='grey')\n",
        "#\n",
        "#gdf[\"geometry\"].plot(ax = ax, markersize = 200, color = 'red',marker = '*', zorder = 2)\n",
        "#\n",
        "#plt.autoscale(False)\n",
        "#ax.axis(\"off\")\n",
        "#\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM2V6oLfIRBk"
      },
      "source": [
        "# Adding Station Data\n",
        "\n",
        "In this section we will take the measurements of ground stations and add those as features to our data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainfeatures = trainfeatures[['station_id',\t'date',\t'SWE',\t'name']]"
      ],
      "metadata": {
        "id": "ieW9vdPnTcGA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Balltree/KNN approach"
      ],
      "metadata": {
        "id": "C-2zyvRcpeip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import BallTree\n",
        "\n",
        "#Adapted from AutoGIS| University of Helsinki\n",
        "# https://automating-gis-processes.github.io/site/notebooks/L3/nearest-neighbor-faster.html\n",
        "def get_knearest(src_points, candidates, knn=1):\n",
        "  '''\n",
        "  K nearest neighbors for every source point given candidate points\n",
        "  '''\n",
        "  #Make candidates BallTree format\n",
        "  tree = BallTree(candidates,leaf_size=15,metric='haversine')\n",
        "\n",
        "  #Find closest points\n",
        "  distances, indices = tree.query(src_points, k=knn)\n",
        "\n",
        "  #Transpose into arrays\n",
        "  distances = distances.transpose()\n",
        "  indices = indices.transpose()\n",
        "\n",
        "  #neighbor_idx = []\n",
        "  #neighbor_dist = []\n",
        "   \n",
        "  return(indices, distances)\n",
        "  #Iterate for k neighbors\n",
        "  #for i in range(knn):\n",
        "  #  neighbor_idx.append(indices[i])\n",
        "  #  neighbor_dist.append(distances[i])\n",
        "  #Return list of lists in order of KNN\n",
        "  #return(neighbor_idx,neighbor_dist)\n",
        "\n",
        "\n",
        "\n",
        "  return distances,indices\n",
        "\n",
        "def nearest_neighbor(left_gdf, right_gdf, return_dist=False, knn=1):\n",
        "  \"\"\"\n",
        "  For each point in left_gdf, find closest point in right GeoDataFrame and return them.\n",
        "\n",
        "  NOTICE: Assumes that the input Points are in WGS84 projection (lat/lon).\n",
        "  \"\"\"\n",
        "  #Some Nan buffer to KNN search\n",
        "  knn = knn*3\n",
        "\n",
        "  left_geom_col = left_gdf.geometry.name\n",
        "  right_geom_col = right_gdf.geometry.name\n",
        "\n",
        "  # Ensure that index in right gdf is formed of sequential numbers\n",
        "  right = right_gdf.copy().reset_index(drop=True)\n",
        "\n",
        "  # Parse coordinates from points and insert them into a numpy array as RADIANS\n",
        "  # For left radians, data is in polygon format, so apply meter crs, get centroid, and revert\n",
        "  left_radians = np.array(left_gdf[left_geom_col].to_crs('epsg:4087').centroid.to_crs(\"EPSG:4326\").apply(lambda geom: (geom.x * np.pi / 180, geom.y * np.pi / 180)).to_list())\n",
        "  right_radians = np.array(right[right_geom_col].apply(lambda geom: (geom.x * np.pi / 180, geom.y * np.pi / 180)).to_list())\n",
        "\n",
        "\n",
        "  # Find the nearest points\n",
        "  # -----------------------\n",
        "  # closest ==> index in right_gdf that corresponds to the closest point\n",
        "  # dist ==> distance between the nearest neighbors (in meters)\n",
        "\n",
        "  closest, dist = get_knearest(src_points=left_radians, candidates=right_radians, knn=knn)\n",
        "\n",
        "  #return(closest,dist)\n",
        "    \n",
        "  closest_points = gpd.GeoDataFrame()\n",
        "    \n",
        "  #Loop for knn\n",
        "  for i in range(knn):\n",
        "    # Return points from right GeoDataFrame that are closest to points in left GeoDataFrame\n",
        "    #Loop to return closest starting from 0 idx\n",
        "    closest_points['station_id_'+str(i)] = right['station_id'].loc[closest[i]].values\n",
        "    closest_points['elevation_m_'+str(i)] = right['elevation_m'].loc[closest[i]].values\n",
        "\n",
        "    # Add distance if requested\n",
        "    if return_dist:\n",
        "      # Convert to meters from radians\n",
        "      earth_radius = 6371000  # meters\n",
        "      closest_points['distance_'+str(i)] = dist[i] * earth_radius\n",
        "\n",
        "  return closest_points\n",
        "\n",
        "def inverseDmean(df,power):\n",
        "  #Formula for inverse Distance Average = ((x1/d1^p)+(x2/d2^p)....)/((1/d1^p)+(1/d2^p)....)\n",
        "  #https://gisgeography.com/inverse-distance-weighting-idw-interpolation/\n",
        "  subset = df.filter(regex='distance_[0-9]+|SWE_[0-9]+')\n",
        "  numerator = pd.DataFrame()\n",
        "  denominator = pd.DataFrame()\n",
        "\n",
        "  for i in range(int(subset.shape[1]/2)):\n",
        "    numerator['x_'+str(i)]=subset['SWE_'+str(i)]/(subset['distance_'+str(i)]**power)\n",
        "    denominator['x_'+str(i)]=1/(subset['distance_'+str(i)]**power)\n",
        "\n",
        "  #There are cells without SWE data. We do not want this in the inverse Distance Calculation\n",
        "  nulls = np.where(pd.isnull(numerator))\n",
        "  for row,column in zip(nulls[0],nulls[1]):\n",
        "    denominator.at[row, denominator.columns[column]] = np.nan\n",
        "  \n",
        "  numerator['sum']=numerator.sum(axis=1)\n",
        "  #print(numerator.head())\n",
        "  denominator['sum']=denominator.sum(axis=1)\n",
        "  #print(denominator.head())\n",
        "\n",
        "  return(numerator['sum']/denominator['sum'])\n",
        "\n",
        "def swe_calculation(train, labels, closest_stations, knn=1):\n",
        "  #Join labels with closest_stations\n",
        "  labels_joined = labels.join(closest_stations)\n",
        "\n",
        "  #Prepare column names\n",
        "  SWE_names=[]\n",
        "  elevation_names=[]\n",
        "  reordered_columns = ['cell_id', 'date', 'SWE', 'region', 'geometry',\n",
        "                       'mean_inversed_swe', 'mean_local_swe',\t'median_local_swe',\t'max_local_swe', 'min_local_swe',\n",
        "                       'mean_local_elevation',\t'median_local_elevation',\t'max_local_elevation','min_local_elevation']\n",
        "  for i in range(knn):\n",
        "    reordered_columns.extend(['station_id_'+str(i),'elevation_m_'+str(i),'distance_'+str(i),'SWE_'+str(i)])\n",
        "    SWE_names.append('SWE_'+str(i))\n",
        "    elevation_names.append('elevation_m_'+str(i))\n",
        "  \n",
        "  #Merge against cell_id+date to get closest stations for each cell\n",
        "  idx = 0\n",
        "  for i in range(knn*3):\n",
        "    train\n",
        "    if i == 0:\n",
        "      tmp_merged = pd.merge(labels_joined, train, how=\"left\", left_on=['station_id_'+str(i), 'date'], right_on=['station_id','date'],suffixes=(None,'_'+str(i))).drop(columns= ['station_id'])\n",
        "    else:\n",
        "      tmp_merged = pd.merge(tmp_merged, train, how=\"left\", left_on=['station_id_'+str(i), 'date'], right_on=['station_id','date'],suffixes=(None,'_'+str(i))).drop(columns= ['station_id'])\n",
        "\n",
        "  #Filter out nearest neighbors with NaN, get 5 closest WITH VALUES\n",
        "  filtered = []\n",
        "  for idx,row in tmp_merged.iterrows():\n",
        "    index = []\n",
        "    values = []\n",
        "    i=0\n",
        "    counter=0\n",
        "    while i<knn:\n",
        "      if not pd.isna(row['SWE_'+str(counter)]):\n",
        "        i+=1\n",
        "        index.append(counter)\n",
        "      counter+=1\n",
        "    for j in index:\n",
        "      values.extend([row['station_id_'+str(j)], row['elevation_m_'+str(j)], row['distance_'+str(j)], row['SWE_'+str(j)]])\n",
        "    filtered.append(values)\n",
        "\n",
        "  #Re-merge with cell data\n",
        "  merged_train = labels.join(pd.DataFrame(filtered,columns=reordered_columns[-4*knn:]))\n",
        "\n",
        "  #Calculations\n",
        "  #Elevations\n",
        "  # Normal Mean\n",
        "  merged_train['mean_local_elevation']=merged_train[elevation_names].mean(axis=1)\n",
        "  # Median\n",
        "  merged_train['median_local_elevation']=merged_train[elevation_names].median(axis=1)\n",
        "  # Max\n",
        "  merged_train['max_local_elevation']=merged_train[elevation_names].max(axis=1)\n",
        "  # Min\n",
        "  merged_train['min_local_elevation']=merged_train[elevation_names].min(axis=1)\n",
        "\n",
        "  #SWE\n",
        "  #Inverse Distance Mean\n",
        "  merged_train['mean_inversed_swe']=inverseDmean(merged_train,2)\n",
        "  #Normal Mean\n",
        "  merged_train['mean_local_swe']=merged_train[SWE_names].mean(axis=1)\n",
        "  #Median\n",
        "  merged_train['median_local_swe']=merged_train[SWE_names].median(axis=1)\n",
        "  #Min\n",
        "  merged_train['min_local_swe']=merged_train[SWE_names].min(axis=1)\n",
        "  #Max\n",
        "  merged_train['max_local_swe']=merged_train[SWE_names].max(axis=1)\n",
        "\n",
        "  #Reorder Columns\n",
        "  merged_train=merged_train[reordered_columns]\n",
        "\n",
        "  return(merged_train)"
      ],
      "metadata": {
        "id": "-RusgZofpduJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn=5\n",
        "#DO NOT want traindf.date or trainfeatures in datetime format\n",
        "\n",
        "closest_stations = nearest_neighbor(traindf, gdf, return_dist=True,knn=knn)\n",
        "traindf = swe_calculation(train=trainfeatures, labels=traindf, closest_stations=closest_stations, knn=knn)"
      ],
      "metadata": {
        "id": "LH4_ggwkrja0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindf.sample(frac = .1).head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "mEob6VOmvsnd",
        "outputId": "1c17a3aa-e77b-43df-d82c-622e3c9a492d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e2ab5232-76d1-4204-a37e-160f01629ed2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell_id</th>\n",
              "      <th>date</th>\n",
              "      <th>SWE</th>\n",
              "      <th>region</th>\n",
              "      <th>geometry</th>\n",
              "      <th>mean_inversed_swe</th>\n",
              "      <th>mean_local_swe</th>\n",
              "      <th>median_local_swe</th>\n",
              "      <th>max_local_swe</th>\n",
              "      <th>min_local_swe</th>\n",
              "      <th>mean_local_elevation</th>\n",
              "      <th>median_local_elevation</th>\n",
              "      <th>max_local_elevation</th>\n",
              "      <th>min_local_elevation</th>\n",
              "      <th>station_id_0</th>\n",
              "      <th>elevation_m_0</th>\n",
              "      <th>distance_0</th>\n",
              "      <th>SWE_0</th>\n",
              "      <th>station_id_1</th>\n",
              "      <th>elevation_m_1</th>\n",
              "      <th>distance_1</th>\n",
              "      <th>SWE_1</th>\n",
              "      <th>station_id_2</th>\n",
              "      <th>elevation_m_2</th>\n",
              "      <th>distance_2</th>\n",
              "      <th>SWE_2</th>\n",
              "      <th>station_id_3</th>\n",
              "      <th>elevation_m_3</th>\n",
              "      <th>distance_3</th>\n",
              "      <th>SWE_3</th>\n",
              "      <th>station_id_4</th>\n",
              "      <th>elevation_m_4</th>\n",
              "      <th>distance_4</th>\n",
              "      <th>SWE_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>67763</th>\n",
              "      <td>c89dc6ca-6d69-41ce-954d-b51f64aaacb1</td>\n",
              "      <td>2019-12-03</td>\n",
              "      <td>6.8</td>\n",
              "      <td>sierras</td>\n",
              "      <td>POLYGON ((-120.03948 38.70465, -120.03948 38.7...</td>\n",
              "      <td>8.068400</td>\n",
              "      <td>7.868000</td>\n",
              "      <td>8.100000</td>\n",
              "      <td>8.300000</td>\n",
              "      <td>6.640000</td>\n",
              "      <td>2393.655370</td>\n",
              "      <td>2377.440000</td>\n",
              "      <td>2548.127930</td>\n",
              "      <td>2164.080000</td>\n",
              "      <td>SNOTEL:1067_CA_SNTL</td>\n",
              "      <td>2548.127930</td>\n",
              "      <td>4723.658181</td>\n",
              "      <td>8.300000</td>\n",
              "      <td>CDEC:CXS</td>\n",
              "      <td>2545.994400</td>\n",
              "      <td>4737.545432</td>\n",
              "      <td>8.300000</td>\n",
              "      <td>CDEC:SIL</td>\n",
              "      <td>2164.080000</td>\n",
              "      <td>8405.648525</td>\n",
              "      <td>6.640000</td>\n",
              "      <td>CDEC:EP5</td>\n",
              "      <td>2377.440000</td>\n",
              "      <td>8759.005685</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>SNOTEL:463_CA_SNTL</td>\n",
              "      <td>2332.634521</td>\n",
              "      <td>8783.741934</td>\n",
              "      <td>8.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10491</th>\n",
              "      <td>a2aa7379-4218-460b-9fff-9ec759094d26</td>\n",
              "      <td>2016-04-03</td>\n",
              "      <td>17.7</td>\n",
              "      <td>central rockies</td>\n",
              "      <td>POLYGON ((-106.62763 37.41030, -106.62763 37.4...</td>\n",
              "      <td>13.324822</td>\n",
              "      <td>16.271429</td>\n",
              "      <td>13.800000</td>\n",
              "      <td>25.214286</td>\n",
              "      <td>7.914286</td>\n",
              "      <td>3350.361572</td>\n",
              "      <td>3352.800049</td>\n",
              "      <td>3541.775879</td>\n",
              "      <td>3108.959961</td>\n",
              "      <td>SNOTEL:580_CO_SNTL</td>\n",
              "      <td>3352.800049</td>\n",
              "      <td>9379.669177</td>\n",
              "      <td>9.314286</td>\n",
              "      <td>SNOTEL:1058_CO_SNTL</td>\n",
              "      <td>3541.775879</td>\n",
              "      <td>10637.084870</td>\n",
              "      <td>13.800000</td>\n",
              "      <td>SNOTEL:874_CO_SNTL</td>\n",
              "      <td>3352.800049</td>\n",
              "      <td>18971.453266</td>\n",
              "      <td>25.114286</td>\n",
              "      <td>SNOTEL:1124_CO_SNTL</td>\n",
              "      <td>3395.471924</td>\n",
              "      <td>19374.898668</td>\n",
              "      <td>7.914286</td>\n",
              "      <td>SNOTEL:840_CO_SNTL</td>\n",
              "      <td>3108.959961</td>\n",
              "      <td>22714.930997</td>\n",
              "      <td>25.214286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37494</th>\n",
              "      <td>28dad940-9168-4416-a6b5-d34c152cead0</td>\n",
              "      <td>2018-06-01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>sierras</td>\n",
              "      <td>POLYGON ((-118.79980 37.24601, -118.79980 37.2...</td>\n",
              "      <td>1.479223</td>\n",
              "      <td>1.246305</td>\n",
              "      <td>0.512857</td>\n",
              "      <td>3.574384</td>\n",
              "      <td>0.171429</td>\n",
              "      <td>2971.800000</td>\n",
              "      <td>2956.560000</td>\n",
              "      <td>3108.960000</td>\n",
              "      <td>2773.680000</td>\n",
              "      <td>CDEC:VLC</td>\n",
              "      <td>3063.240000</td>\n",
              "      <td>13436.676022</td>\n",
              "      <td>3.574384</td>\n",
              "      <td>CDEC:RCK</td>\n",
              "      <td>2956.560000</td>\n",
              "      <td>13522.866251</td>\n",
              "      <td>0.171429</td>\n",
              "      <td>CDEC:UBC</td>\n",
              "      <td>2956.560000</td>\n",
              "      <td>15319.285135</td>\n",
              "      <td>1.637143</td>\n",
              "      <td>CDEC:WWC</td>\n",
              "      <td>2773.680000</td>\n",
              "      <td>17284.775807</td>\n",
              "      <td>0.335714</td>\n",
              "      <td>CDEC:SWM</td>\n",
              "      <td>3108.960000</td>\n",
              "      <td>27279.750979</td>\n",
              "      <td>0.512857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56822</th>\n",
              "      <td>c92ccc48-c5fb-49c9-9cc6-cb55134b4a03</td>\n",
              "      <td>2019-04-27</td>\n",
              "      <td>0.0</td>\n",
              "      <td>sierras</td>\n",
              "      <td>POLYGON ((-118.76387 36.82292, -118.76387 36.8...</td>\n",
              "      <td>43.925890</td>\n",
              "      <td>34.086000</td>\n",
              "      <td>37.415714</td>\n",
              "      <td>58.781429</td>\n",
              "      <td>3.130000</td>\n",
              "      <td>2776.728000</td>\n",
              "      <td>2956.560000</td>\n",
              "      <td>3108.960000</td>\n",
              "      <td>2026.920000</td>\n",
              "      <td>CDEC:MTM</td>\n",
              "      <td>3017.520000</td>\n",
              "      <td>7885.854431</td>\n",
              "      <td>58.781429</td>\n",
              "      <td>CDEC:GNF</td>\n",
              "      <td>2026.920000</td>\n",
              "      <td>14159.835223</td>\n",
              "      <td>3.130000</td>\n",
              "      <td>CDEC:WWC</td>\n",
              "      <td>2773.680000</td>\n",
              "      <td>19899.638770</td>\n",
              "      <td>37.415714</td>\n",
              "      <td>CDEC:UBC</td>\n",
              "      <td>2956.560000</td>\n",
              "      <td>26898.853579</td>\n",
              "      <td>48.381429</td>\n",
              "      <td>CDEC:SWM</td>\n",
              "      <td>3108.960000</td>\n",
              "      <td>29045.670672</td>\n",
              "      <td>22.721429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29209</th>\n",
              "      <td>6f764077-3026-4444-ba75-35904973589f</td>\n",
              "      <td>2018-03-31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>central rockies</td>\n",
              "      <td>POLYGON ((-107.18458 38.86571, -107.18458 38.8...</td>\n",
              "      <td>10.487887</td>\n",
              "      <td>10.025714</td>\n",
              "      <td>8.842857</td>\n",
              "      <td>18.914286</td>\n",
              "      <td>3.657143</td>\n",
              "      <td>3139.440039</td>\n",
              "      <td>3096.768066</td>\n",
              "      <td>3523.488037</td>\n",
              "      <td>2804.159912</td>\n",
              "      <td>SNOTEL:669_CO_SNTL</td>\n",
              "      <td>2804.159912</td>\n",
              "      <td>8500.607373</td>\n",
              "      <td>10.728571</td>\n",
              "      <td>SNOTEL:380_CO_SNTL</td>\n",
              "      <td>3096.768066</td>\n",
              "      <td>26262.992675</td>\n",
              "      <td>8.842857</td>\n",
              "      <td>SNOTEL:762_CO_SNTL</td>\n",
              "      <td>3523.488037</td>\n",
              "      <td>28919.608471</td>\n",
              "      <td>7.985714</td>\n",
              "      <td>SNOTEL:345_CO_SNTL</td>\n",
              "      <td>3316.224121</td>\n",
              "      <td>34961.714810</td>\n",
              "      <td>18.914286</td>\n",
              "      <td>SNOTEL:827_CO_SNTL</td>\n",
              "      <td>2956.560059</td>\n",
              "      <td>37537.256456</td>\n",
              "      <td>3.657143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2ab5232-76d1-4204-a37e-160f01629ed2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2ab5232-76d1-4204-a37e-160f01629ed2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2ab5232-76d1-4204-a37e-160f01629ed2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    cell_id  ...      SWE_4\n",
              "67763  c89dc6ca-6d69-41ce-954d-b51f64aaacb1  ...   8.100000\n",
              "10491  a2aa7379-4218-460b-9fff-9ec759094d26  ...  25.214286\n",
              "37494  28dad940-9168-4416-a6b5-d34c152cead0  ...   0.512857\n",
              "56822  c92ccc48-c5fb-49c9-9cc6-cb55134b4a03  ...  22.721429\n",
              "29209  6f764077-3026-4444-ba75-35904973589f  ...   3.657143\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindf = traindf[['cell_id','date','SWE','region','geometry','mean_inversed_swe',\n",
        "                   'mean_local_swe','median_local_swe','max_local_swe','min_local_swe',\n",
        "                   'mean_local_elevation','median_local_elevation','max_local_elevation','min_local_elevation',]]\n",
        "                   \n",
        "print(traindf.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz4DAKdyzUq4",
        "outputId": "f14906e6-e293-4200-c622-b4f2b7a303f0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cell_id                   0\n",
            "date                      0\n",
            "SWE                       0\n",
            "region                    0\n",
            "geometry                  0\n",
            "mean_inversed_swe         0\n",
            "mean_local_swe            0\n",
            "median_local_swe          0\n",
            "max_local_swe             0\n",
            "min_local_swe             0\n",
            "mean_local_elevation      0\n",
            "median_local_elevation    0\n",
            "max_local_elevation       0\n",
            "min_local_elevation       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udf7IEQnIMOe"
      },
      "source": [
        "# Modis Data\n",
        "\n",
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "import requests\n",
        "import ee\n",
        "from datetime import datetime, timedelta\n",
        "import signal\n",
        "\n",
        "class TimeoutException(Exception):   # Custom exception class\n",
        "    pass\n",
        "\n",
        "def timeout_handler(signum, frame):   # Custom signal handler\n",
        "    raise TimeoutException\n",
        "\n",
        "signal.signal(signal.SIGALRM, timeout_handler)\n",
        "\n",
        "traindf[\"date\"] = pd.to_datetime(traindf.date)\n",
        "trainfeatures['date'] = pd.to_datetime(trainfeatures.date)\n",
        "\n",
        "#I am creating a string version of the date to use as a filename\n",
        "traindf[\"datestring\"] = traindf.date.map(lambda d: str(d.year)+d.strftime('%j'))\n",
        "\n",
        "#Now I calculate my centroid from the provided geometry\n",
        "#Ignore the warnings this creates. It is in a projected crs\n",
        "traindf[\"centroid\"] = traindf.geometry.to_crs('+proj=cea').centroid\n",
        "traindf[\"center_lat\"] = traindf.centroid.y\n",
        "traindf[\"center_long\"] = traindf.centroid.x\n",
        "\n",
        "#Logging in to Earth Engine\n",
        "try:\n",
        "        ee.Initialize()\n",
        "except Exception as e:\n",
        "        ee.Authenticate()\n",
        "        ee.Initialize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqbPeNPdaI1n",
        "outputId": "452e3e5b-9dbf-463a-f107-33f43a3b4877"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def pull_MODIS(traindf, modis, overwrite = False, names_only = False):\n",
        "  filelocations = []\n",
        "  x = 0\n",
        "\n",
        "  for i in range(len(traindf.SWE)):\n",
        "\n",
        "    #create a name for the image\n",
        "    pict_name = traindf.cell_id[i] + '_' + modis + '_' + traindf.datestring[i] + '.jpg'\n",
        "\n",
        "    #create the whole filename with path to the correct folder\n",
        "    filename = os.path.join('/content/', modis, pict_name)\n",
        "\n",
        "    if names_only:\n",
        "      filelocations.append(filename)\n",
        "      x += 1\n",
        "      if x % 5000 == 0:\n",
        "        print(f'{x} files already exist')\n",
        "\n",
        "    elif os.path.exists(filename) and not overwrite:\n",
        "      filelocations.append(filename)\n",
        "      x += 1\n",
        "      if x % 5000 == 0:\n",
        "        print(f'{x} files already exist')\n",
        "\n",
        "    else:\n",
        "      #We need a start date and an end date. Just like a regular python slice, \n",
        "      #the end date is not included, so by using a 1 day frame, I am actually limiting\n",
        "      #the range to only the day in question\n",
        "      start_date = traindf.date[i] - timedelta(days = 7)\n",
        "      end_date = traindf.date[i] + timedelta(days = 1)\n",
        "\n",
        "      #First I get the image collection from the MODIS data, filter it only to the days in question\n",
        "      #and select my bands, then sort so the most recent day in the group is at the top\n",
        "      Collection = ee.ImageCollection(f'MODIS/006/{modis}') \\\n",
        "                  .filter(ee.Filter.date(start_date, end_date)) \\\n",
        "                  .filter(ee.Filter.notNull(['system:index'])) \\\n",
        "                  .select(['NDSI_Snow_Cover', 'Snow_Albedo_Daily_Tile', 'NDSI']) \\\n",
        "                  .sort('system:index', False) \n",
        "\n",
        "      #I create a google earth images point based on the area centroid\n",
        "      centroid = ee.Geometry.Point(traindf.center_long[i], traindf.center_lat[i])\n",
        "\n",
        "      #Because the image collection is limited to a single day, there is only one image\n",
        "      #So I just take it\n",
        "      point = Collection.first().unmask(0)\n",
        "\n",
        "      # Get individual band arrays and build them into an RGB image\n",
        "      # The \"buffer\" is a circular distance around the point, measured in meters right now it is 100km\n",
        "      rgb = ee.Image.rgb(point.clip(centroid.buffer(10000)).select('NDSI_Snow_Cover').divide(100), #I divide by 100 to get it between 0 and 1\n",
        "                        point.clip(centroid.buffer(10000)).select('Snow_Albedo_Daily_Tile').divide(100), #I divide by 100 to get it between 0 and 1\n",
        "                        point.clip(centroid.buffer(10000)).select('NDSI').divide(10000)).visualize() #I divide by 10000 to get it between 0 and 1\n",
        "\n",
        "      #Now I get the url for the image\n",
        "      url = rgb.getThumbURL()\n",
        "\n",
        "      #add the name to my list I created earlier\n",
        "      filelocations.append(filename)\n",
        "\n",
        "      #now I open the url and download the image to the specified file location\n",
        "      response = requests.get(url, stream=True)\n",
        "      with open(filename, 'wb') as out_file:\n",
        "          shutil.copyfileobj(response.raw, out_file)\n",
        "      del response\n",
        "    \n",
        "  #traindf[f\"{modis}_filelocations\"] = filelocations\n",
        "'''"
      ],
      "metadata": {
        "id": "uijUxpazQtC2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "9be440c1-adc7-4a2a-9095-d280935d909b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndef pull_MODIS(traindf, modis, overwrite = False, names_only = False):\\n  filelocations = []\\n  x = 0\\n\\n  for i in range(len(traindf.SWE)):\\n\\n    #create a name for the image\\n    pict_name = traindf.cell_id[i] + \\'_\\' + modis + \\'_\\' + traindf.datestring[i] + \\'.jpg\\'\\n\\n    #create the whole filename with path to the correct folder\\n    filename = os.path.join(\\'/content/\\', modis, pict_name)\\n\\n    if names_only:\\n      filelocations.append(filename)\\n      x += 1\\n      if x % 5000 == 0:\\n        print(f\\'{x} files already exist\\')\\n\\n    elif os.path.exists(filename) and not overwrite:\\n      filelocations.append(filename)\\n      x += 1\\n      if x % 5000 == 0:\\n        print(f\\'{x} files already exist\\')\\n\\n    else:\\n      #We need a start date and an end date. Just like a regular python slice, \\n      #the end date is not included, so by using a 1 day frame, I am actually limiting\\n      #the range to only the day in question\\n      start_date = traindf.date[i] - timedelta(days = 7)\\n      end_date = traindf.date[i] + timedelta(days = 1)\\n\\n      #First I get the image collection from the MODIS data, filter it only to the days in question\\n      #and select my bands, then sort so the most recent day in the group is at the top\\n      Collection = ee.ImageCollection(f\\'MODIS/006/{modis}\\')                   .filter(ee.Filter.date(start_date, end_date))                   .filter(ee.Filter.notNull([\\'system:index\\']))                   .select([\\'NDSI_Snow_Cover\\', \\'Snow_Albedo_Daily_Tile\\', \\'NDSI\\'])                   .sort(\\'system:index\\', False) \\n\\n      #I create a google earth images point based on the area centroid\\n      centroid = ee.Geometry.Point(traindf.center_long[i], traindf.center_lat[i])\\n\\n      #Because the image collection is limited to a single day, there is only one image\\n      #So I just take it\\n      point = Collection.first().unmask(0)\\n\\n      # Get individual band arrays and build them into an RGB image\\n      # The \"buffer\" is a circular distance around the point, measured in meters right now it is 100km\\n      rgb = ee.Image.rgb(point.clip(centroid.buffer(10000)).select(\\'NDSI_Snow_Cover\\').divide(100), #I divide by 100 to get it between 0 and 1\\n                        point.clip(centroid.buffer(10000)).select(\\'Snow_Albedo_Daily_Tile\\').divide(100), #I divide by 100 to get it between 0 and 1\\n                        point.clip(centroid.buffer(10000)).select(\\'NDSI\\').divide(10000)).visualize() #I divide by 10000 to get it between 0 and 1\\n\\n      #Now I get the url for the image\\n      url = rgb.getThumbURL()\\n\\n      #add the name to my list I created earlier\\n      filelocations.append(filename)\\n\\n      #now I open the url and download the image to the specified file location\\n      response = requests.get(url, stream=True)\\n      with open(filename, \\'wb\\') as out_file:\\n          shutil.copyfileobj(response.raw, out_file)\\n      del response\\n    \\n  #traindf[f\"{modis}_filelocations\"] = filelocations\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pull_MODIS_list(traindf, modis, signal_timer = 5):\n",
        "  datalist = []\n",
        "  x= 0\n",
        "\n",
        "  still_working = True\n",
        "  while still_working:\n",
        "    try:\n",
        "      Collection = ee.ImageCollection(f'MODIS/006/{modis}') \\\n",
        "                  .select(['NDSI_Snow_Cover', 'Snow_Albedo_Daily_Tile', 'NDSI'])\n",
        "      \n",
        "    except Exception as e:\n",
        "      print(\"Some Error with Image Collection\")\n",
        "    else: \n",
        "      still_working = False        \n",
        "  \n",
        "\n",
        "  for i in range(len(traindf.SWE)):\n",
        "    still_working = True\n",
        "    while still_working:\n",
        "      signal.alarm(signal_timer)\n",
        "      try:\n",
        "        row = [traindf.cell_id[i], traindf.date[i]]\n",
        "\n",
        "        #We need a start date and an end date. Just like a regular python slice, \n",
        "        #the end date is not included, so by using a 1 day frame, I am actually limiting\n",
        "        #the range to only the day in question\n",
        "        start_date = traindf.date[i] - timedelta(days = 7)\n",
        "        end_date = traindf.date[i] + timedelta(days = 1)\n",
        "\n",
        "        #First I get the image collection from the MODIS data, filter it only to the days in question\n",
        "        #and select my bands, then sort so the most recent day in the group is at the top\n",
        "        DatedCollection = Collection.filter(ee.Filter.date(start_date, end_date)) \\\n",
        "                                    .filter(ee.Filter.notNull(['system:index'])) \\\n",
        "                                    .sort('system:index', False)\n",
        "\n",
        "        #Because the image collection is limited to a single day, there is only one image\n",
        "        #So I just take it\n",
        "        point = DatedCollection.first().unmask(0)\n",
        "\n",
        "        aoi = ee.Geometry.Polygon(list(traindf.iloc[i].geometry.exterior.coords))\n",
        "\n",
        "        bands = point.reduceRegion(reducer = ee.Reducer.mean(),\n",
        "        geometry= aoi)\n",
        "\n",
        "        bands = bands.toArray(['NDSI_Snow_Cover', 'Snow_Albedo_Daily_Tile', 'NDSI']).getInfo()\n",
        "        bands = np.divide(bands, [100,100,10000] )\n",
        "\n",
        "        row.extend(bands)\n",
        "\n",
        "        datalist.append(row)\n",
        "      \n",
        "      except TimeoutException:\n",
        "        print(f\"Request Timeout for cell_id {traindf.cell_id[i]}\")\n",
        "      \n",
        "      except Exception as e:\n",
        "        print(\"Some other Error\")\n",
        "      else: \n",
        "        signal.alarm(0)\n",
        "        still_working = False\n",
        "        x+=1\n",
        "        if x % 100 == 0:\n",
        "          print(f'{x} out of {len(traindf.SWE)} complete')\n",
        "\n",
        "  data = pd.DataFrame(datalist, columns = ['cell_id', 'date', f'{modis}_SnowCover', \n",
        "                                           f'{modis}_Albedo', f'{modis}_NDSI'])\n",
        "  print(data)\n",
        "  traindf.merge(data, how = 'left', on=['cell_id', 'date'])\n",
        "  return traindf"
      ],
      "metadata": {
        "id": "GaaXWEf7P8MX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time "
      ],
      "metadata": {
        "id": "Ud6-utPfU2wJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "traindf = pull_MODIS_list(traindf, modis = \"MOD10A1\")\n",
        "print(f'Total Time: {time.time() - start}')\n",
        "print()\n",
        "\n",
        "start = time.time()\n",
        "traindf = pull_MODIS_list(traindf, modis = \"MYD10A1\")\n",
        "print(f'Total Time: {time.time() - start}')\n",
        "\n",
        "\n",
        "#!zip -r '/content/drive/MyDrive/snowcapstone team spring 2022/MODIS_Data/MOD10A1_sierras.zip'  '/content/drive/MyDrive/snowcapstone team spring 2022/MODIS_Data/MOD10A1/'\n",
        "#!zip -r '/content/drive/MyDrive/snowcapstone team spring 2022/MODIS_Data/MYD10A1_sierras.zip'  '/content/drive/MyDrive/snowcapstone team spring 2022/MODIS_Data/MYD10A1/'"
      ],
      "metadata": {
        "id": "JPyROj2bLEQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "839e7cd3-111a-40b8-aa1d-5630cbf8a4c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 out of 68670 complete\n",
            "200 out of 68670 complete\n",
            "300 out of 68670 complete\n",
            "400 out of 68670 complete\n",
            "500 out of 68670 complete\n",
            "600 out of 68670 complete\n",
            "700 out of 68670 complete\n",
            "800 out of 68670 complete\n",
            "900 out of 68670 complete\n",
            "1000 out of 68670 complete\n",
            "1100 out of 68670 complete\n",
            "1200 out of 68670 complete\n",
            "1300 out of 68670 complete\n",
            "1400 out of 68670 complete\n",
            "1500 out of 68670 complete\n",
            "1600 out of 68670 complete\n",
            "1700 out of 68670 complete\n",
            "1800 out of 68670 complete\n",
            "1900 out of 68670 complete\n",
            "2000 out of 68670 complete\n",
            "2100 out of 68670 complete\n",
            "2200 out of 68670 complete\n",
            "2300 out of 68670 complete\n",
            "2400 out of 68670 complete\n",
            "2500 out of 68670 complete\n",
            "2600 out of 68670 complete\n",
            "2700 out of 68670 complete\n",
            "2800 out of 68670 complete\n",
            "2900 out of 68670 complete\n",
            "3000 out of 68670 complete\n",
            "3100 out of 68670 complete\n",
            "3200 out of 68670 complete\n",
            "3300 out of 68670 complete\n",
            "3400 out of 68670 complete\n",
            "3500 out of 68670 complete\n",
            "3600 out of 68670 complete\n",
            "3700 out of 68670 complete\n",
            "3800 out of 68670 complete\n",
            "3900 out of 68670 complete\n",
            "4000 out of 68670 complete\n",
            "4100 out of 68670 complete\n",
            "4200 out of 68670 complete\n",
            "4300 out of 68670 complete\n",
            "4400 out of 68670 complete\n",
            "4500 out of 68670 complete\n",
            "4600 out of 68670 complete\n",
            "4700 out of 68670 complete\n",
            "4800 out of 68670 complete\n",
            "4900 out of 68670 complete\n",
            "5000 out of 68670 complete\n",
            "5100 out of 68670 complete\n",
            "5200 out of 68670 complete\n",
            "5300 out of 68670 complete\n",
            "5400 out of 68670 complete\n",
            "5500 out of 68670 complete\n",
            "5600 out of 68670 complete\n",
            "5700 out of 68670 complete\n",
            "5800 out of 68670 complete\n",
            "5900 out of 68670 complete\n",
            "6000 out of 68670 complete\n",
            "6100 out of 68670 complete\n",
            "6200 out of 68670 complete\n",
            "6300 out of 68670 complete\n",
            "6400 out of 68670 complete\n",
            "6500 out of 68670 complete\n",
            "6600 out of 68670 complete\n",
            "6700 out of 68670 complete\n",
            "6800 out of 68670 complete\n",
            "6900 out of 68670 complete\n",
            "7000 out of 68670 complete\n",
            "7100 out of 68670 complete\n",
            "7200 out of 68670 complete\n",
            "7300 out of 68670 complete\n",
            "7400 out of 68670 complete\n",
            "7500 out of 68670 complete\n",
            "7600 out of 68670 complete\n",
            "7700 out of 68670 complete\n",
            "7800 out of 68670 complete\n",
            "7900 out of 68670 complete\n",
            "8000 out of 68670 complete\n",
            "8100 out of 68670 complete\n",
            "8200 out of 68670 complete\n",
            "8300 out of 68670 complete\n",
            "8400 out of 68670 complete\n",
            "8500 out of 68670 complete\n",
            "8600 out of 68670 complete\n",
            "8700 out of 68670 complete\n",
            "8800 out of 68670 complete\n",
            "8900 out of 68670 complete\n",
            "9000 out of 68670 complete\n",
            "9100 out of 68670 complete\n",
            "9200 out of 68670 complete\n",
            "9300 out of 68670 complete\n",
            "9400 out of 68670 complete\n",
            "9500 out of 68670 complete\n",
            "9600 out of 68670 complete\n",
            "9700 out of 68670 complete\n",
            "9800 out of 68670 complete\n",
            "9900 out of 68670 complete\n",
            "10000 out of 68670 complete\n",
            "10100 out of 68670 complete\n",
            "10200 out of 68670 complete\n",
            "10300 out of 68670 complete\n",
            "10400 out of 68670 complete\n",
            "10500 out of 68670 complete\n",
            "10600 out of 68670 complete\n",
            "10700 out of 68670 complete\n",
            "10800 out of 68670 complete\n",
            "10900 out of 68670 complete\n",
            "11000 out of 68670 complete\n",
            "11100 out of 68670 complete\n",
            "11200 out of 68670 complete\n",
            "11300 out of 68670 complete\n",
            "11400 out of 68670 complete\n",
            "11500 out of 68670 complete\n",
            "11600 out of 68670 complete\n",
            "11700 out of 68670 complete\n",
            "11800 out of 68670 complete\n",
            "11900 out of 68670 complete\n",
            "12000 out of 68670 complete\n",
            "12100 out of 68670 complete\n",
            "12200 out of 68670 complete\n",
            "12300 out of 68670 complete\n",
            "12400 out of 68670 complete\n",
            "12500 out of 68670 complete\n",
            "12600 out of 68670 complete\n",
            "12700 out of 68670 complete\n",
            "12800 out of 68670 complete\n",
            "12900 out of 68670 complete\n",
            "13000 out of 68670 complete\n",
            "13100 out of 68670 complete\n",
            "13200 out of 68670 complete\n",
            "13300 out of 68670 complete\n",
            "13400 out of 68670 complete\n",
            "13500 out of 68670 complete\n",
            "13600 out of 68670 complete\n",
            "13700 out of 68670 complete\n",
            "13800 out of 68670 complete\n",
            "13900 out of 68670 complete\n",
            "14000 out of 68670 complete\n",
            "14100 out of 68670 complete\n",
            "14200 out of 68670 complete\n",
            "14300 out of 68670 complete\n",
            "14400 out of 68670 complete\n",
            "14500 out of 68670 complete\n",
            "14600 out of 68670 complete\n",
            "14700 out of 68670 complete\n",
            "14800 out of 68670 complete\n",
            "14900 out of 68670 complete\n",
            "15000 out of 68670 complete\n",
            "15100 out of 68670 complete\n",
            "15200 out of 68670 complete\n",
            "15300 out of 68670 complete\n",
            "15400 out of 68670 complete\n",
            "15500 out of 68670 complete\n",
            "15600 out of 68670 complete\n",
            "15700 out of 68670 complete\n",
            "15800 out of 68670 complete\n",
            "15900 out of 68670 complete\n",
            "16000 out of 68670 complete\n",
            "16100 out of 68670 complete\n",
            "16200 out of 68670 complete\n",
            "16300 out of 68670 complete\n",
            "16400 out of 68670 complete\n",
            "16500 out of 68670 complete\n",
            "16600 out of 68670 complete\n",
            "16700 out of 68670 complete\n",
            "16800 out of 68670 complete\n",
            "16900 out of 68670 complete\n",
            "17000 out of 68670 complete\n",
            "17100 out of 68670 complete\n",
            "17200 out of 68670 complete\n",
            "17300 out of 68670 complete\n",
            "17400 out of 68670 complete\n",
            "17500 out of 68670 complete\n",
            "17600 out of 68670 complete\n",
            "17700 out of 68670 complete\n",
            "17800 out of 68670 complete\n",
            "17900 out of 68670 complete\n",
            "18000 out of 68670 complete\n",
            "18100 out of 68670 complete\n",
            "18200 out of 68670 complete\n",
            "18300 out of 68670 complete\n",
            "18400 out of 68670 complete\n",
            "18500 out of 68670 complete\n",
            "18600 out of 68670 complete\n",
            "18700 out of 68670 complete\n",
            "18800 out of 68670 complete\n",
            "18900 out of 68670 complete\n",
            "19000 out of 68670 complete\n",
            "19100 out of 68670 complete\n",
            "19200 out of 68670 complete\n",
            "19300 out of 68670 complete\n",
            "19400 out of 68670 complete\n",
            "19500 out of 68670 complete\n",
            "19600 out of 68670 complete\n",
            "19700 out of 68670 complete\n",
            "19800 out of 68670 complete\n",
            "19900 out of 68670 complete\n",
            "20000 out of 68670 complete\n",
            "20100 out of 68670 complete\n",
            "20200 out of 68670 complete\n",
            "20300 out of 68670 complete\n",
            "20400 out of 68670 complete\n",
            "20500 out of 68670 complete\n",
            "20600 out of 68670 complete\n",
            "20700 out of 68670 complete\n",
            "20800 out of 68670 complete\n",
            "20900 out of 68670 complete\n",
            "21000 out of 68670 complete\n",
            "21100 out of 68670 complete\n",
            "21200 out of 68670 complete\n",
            "21300 out of 68670 complete\n",
            "21400 out of 68670 complete\n",
            "21500 out of 68670 complete\n",
            "21600 out of 68670 complete\n",
            "21700 out of 68670 complete\n",
            "21800 out of 68670 complete\n",
            "21900 out of 68670 complete\n",
            "22000 out of 68670 complete\n",
            "22100 out of 68670 complete\n",
            "22200 out of 68670 complete\n",
            "22300 out of 68670 complete\n",
            "22400 out of 68670 complete\n",
            "22500 out of 68670 complete\n",
            "22600 out of 68670 complete\n",
            "22700 out of 68670 complete\n",
            "22800 out of 68670 complete\n",
            "22900 out of 68670 complete\n",
            "23000 out of 68670 complete\n",
            "23100 out of 68670 complete\n",
            "23200 out of 68670 complete\n",
            "23300 out of 68670 complete\n",
            "Request Timeout for cell_id 8ca1aaab-07de-4532-a99f-4ab8bce2f862\n",
            "23400 out of 68670 complete\n",
            "23500 out of 68670 complete\n",
            "23600 out of 68670 complete\n",
            "23700 out of 68670 complete\n",
            "23800 out of 68670 complete\n",
            "23900 out of 68670 complete\n",
            "24000 out of 68670 complete\n",
            "24100 out of 68670 complete\n",
            "24200 out of 68670 complete\n",
            "24300 out of 68670 complete\n",
            "24400 out of 68670 complete\n",
            "24500 out of 68670 complete\n",
            "24600 out of 68670 complete\n",
            "24700 out of 68670 complete\n",
            "24800 out of 68670 complete\n",
            "24900 out of 68670 complete\n",
            "25000 out of 68670 complete\n",
            "25100 out of 68670 complete\n",
            "25200 out of 68670 complete\n",
            "25300 out of 68670 complete\n",
            "25400 out of 68670 complete\n",
            "25500 out of 68670 complete\n",
            "25600 out of 68670 complete\n",
            "25700 out of 68670 complete\n",
            "25800 out of 68670 complete\n",
            "25900 out of 68670 complete\n",
            "26000 out of 68670 complete\n",
            "26100 out of 68670 complete\n",
            "26200 out of 68670 complete\n",
            "26300 out of 68670 complete\n",
            "26400 out of 68670 complete\n",
            "26500 out of 68670 complete\n",
            "26600 out of 68670 complete\n",
            "26700 out of 68670 complete\n",
            "26800 out of 68670 complete\n",
            "26900 out of 68670 complete\n",
            "27000 out of 68670 complete\n",
            "27100 out of 68670 complete\n",
            "27200 out of 68670 complete\n",
            "27300 out of 68670 complete\n",
            "27400 out of 68670 complete\n",
            "27500 out of 68670 complete\n",
            "27600 out of 68670 complete\n",
            "27700 out of 68670 complete\n",
            "27800 out of 68670 complete\n",
            "27900 out of 68670 complete\n",
            "28000 out of 68670 complete\n",
            "28100 out of 68670 complete\n",
            "28200 out of 68670 complete\n",
            "28300 out of 68670 complete\n",
            "28400 out of 68670 complete\n",
            "28500 out of 68670 complete\n",
            "28600 out of 68670 complete\n",
            "28700 out of 68670 complete\n",
            "28800 out of 68670 complete\n",
            "28900 out of 68670 complete\n",
            "29000 out of 68670 complete\n",
            "29100 out of 68670 complete\n",
            "29200 out of 68670 complete\n",
            "29300 out of 68670 complete\n",
            "29400 out of 68670 complete\n",
            "29500 out of 68670 complete\n",
            "29600 out of 68670 complete\n",
            "29700 out of 68670 complete\n",
            "29800 out of 68670 complete\n",
            "29900 out of 68670 complete\n",
            "30000 out of 68670 complete\n",
            "30100 out of 68670 complete\n",
            "30200 out of 68670 complete\n",
            "30300 out of 68670 complete\n",
            "30400 out of 68670 complete\n",
            "30500 out of 68670 complete\n",
            "30600 out of 68670 complete\n",
            "30700 out of 68670 complete\n",
            "30800 out of 68670 complete\n",
            "30900 out of 68670 complete\n",
            "31000 out of 68670 complete\n",
            "31100 out of 68670 complete\n",
            "31200 out of 68670 complete\n",
            "31300 out of 68670 complete\n",
            "31400 out of 68670 complete\n",
            "31500 out of 68670 complete\n",
            "31600 out of 68670 complete\n",
            "31700 out of 68670 complete\n",
            "31800 out of 68670 complete\n",
            "31900 out of 68670 complete\n",
            "32000 out of 68670 complete\n",
            "32100 out of 68670 complete\n",
            "32200 out of 68670 complete\n",
            "32300 out of 68670 complete\n",
            "32400 out of 68670 complete\n",
            "32500 out of 68670 complete\n",
            "32600 out of 68670 complete\n",
            "32700 out of 68670 complete\n",
            "32800 out of 68670 complete\n",
            "32900 out of 68670 complete\n",
            "33000 out of 68670 complete\n",
            "33100 out of 68670 complete\n",
            "33200 out of 68670 complete\n",
            "33300 out of 68670 complete\n",
            "33400 out of 68670 complete\n",
            "33500 out of 68670 complete\n",
            "Request Timeout for cell_id 1d90aa2a-9304-4884-953d-26f6fbc9d0d6\n",
            "33600 out of 68670 complete\n",
            "33700 out of 68670 complete\n",
            "33800 out of 68670 complete\n",
            "33900 out of 68670 complete\n",
            "34000 out of 68670 complete\n",
            "34100 out of 68670 complete\n",
            "34200 out of 68670 complete\n",
            "34300 out of 68670 complete\n",
            "34400 out of 68670 complete\n",
            "34500 out of 68670 complete\n",
            "34600 out of 68670 complete\n",
            "34700 out of 68670 complete\n",
            "34800 out of 68670 complete\n",
            "34900 out of 68670 complete\n",
            "35000 out of 68670 complete\n",
            "35100 out of 68670 complete\n",
            "35200 out of 68670 complete\n",
            "35300 out of 68670 complete\n",
            "35400 out of 68670 complete\n",
            "35500 out of 68670 complete\n",
            "35600 out of 68670 complete\n",
            "35700 out of 68670 complete\n",
            "35800 out of 68670 complete\n",
            "35900 out of 68670 complete\n",
            "36000 out of 68670 complete\n",
            "36100 out of 68670 complete\n",
            "36200 out of 68670 complete\n",
            "36300 out of 68670 complete\n",
            "36400 out of 68670 complete\n",
            "36500 out of 68670 complete\n",
            "36600 out of 68670 complete\n",
            "36700 out of 68670 complete\n",
            "36800 out of 68670 complete\n",
            "36900 out of 68670 complete\n",
            "37000 out of 68670 complete\n",
            "37100 out of 68670 complete\n",
            "37200 out of 68670 complete\n",
            "37300 out of 68670 complete\n",
            "37400 out of 68670 complete\n",
            "37500 out of 68670 complete\n",
            "37600 out of 68670 complete\n",
            "37700 out of 68670 complete\n",
            "37800 out of 68670 complete\n",
            "37900 out of 68670 complete\n",
            "38000 out of 68670 complete\n",
            "38100 out of 68670 complete\n",
            "38200 out of 68670 complete\n",
            "38300 out of 68670 complete\n",
            "38400 out of 68670 complete\n",
            "38500 out of 68670 complete\n",
            "38600 out of 68670 complete\n",
            "38700 out of 68670 complete\n",
            "38800 out of 68670 complete\n",
            "38900 out of 68670 complete\n",
            "39000 out of 68670 complete\n",
            "39100 out of 68670 complete\n",
            "39200 out of 68670 complete\n",
            "39300 out of 68670 complete\n",
            "39400 out of 68670 complete\n",
            "39500 out of 68670 complete\n",
            "39600 out of 68670 complete\n",
            "39700 out of 68670 complete\n",
            "39800 out of 68670 complete\n",
            "39900 out of 68670 complete\n",
            "40000 out of 68670 complete\n",
            "40100 out of 68670 complete\n",
            "40200 out of 68670 complete\n",
            "40300 out of 68670 complete\n",
            "40400 out of 68670 complete\n",
            "40500 out of 68670 complete\n",
            "40600 out of 68670 complete\n",
            "40700 out of 68670 complete\n",
            "40800 out of 68670 complete\n",
            "40900 out of 68670 complete\n",
            "41000 out of 68670 complete\n",
            "41100 out of 68670 complete\n",
            "41200 out of 68670 complete\n",
            "41300 out of 68670 complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Copernicus Data"
      ],
      "metadata": {
        "id": "7i_zmwwN4Q5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MATCH FUNCTION"
      ],
      "metadata": {
        "id": "5VIWcB9QjkDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_copernicus(traindf, overwrite = False, signal_timer =5):\n",
        "  start = time.time()\n",
        "  traindf[\"copernicus_filelocations\"] = \"blank\"\n",
        "  x = 0\n",
        "  length_cell_id = len(traindf.cell_id.unique())\n",
        "\n",
        "  still_working = True\n",
        "  while still_working:\n",
        "    try:\n",
        "      client = Client.open(\n",
        "      \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
        "      ignore_conformance=True,\n",
        "      )\n",
        "  \n",
        "    except Exception as e:\n",
        "      print(\"Some Error with Image Collection\")\n",
        "    else: \n",
        "      still_working = False  \n",
        "\n",
        "  for i in traindf.cell_id.unique():\n",
        "    if x % 100 == 1:\n",
        "      start = time.time()\n",
        "\n",
        "    still_working = True\n",
        "    while still_working:\n",
        "      signal.alarm(signal_timer)\n",
        "      try:\n",
        "        #create a name for the image\n",
        "        pict_name = i + '_' + 'copernicus30m'\n",
        "\n",
        "        #create the whole filename with path to the correct folder\n",
        "        filename = os.path.join('/content/Copernicus_Data', pict_name)\n",
        "\n",
        "        # Adapted from https://planetarycomputer.microsoft.com/dataset/cop-dem-glo-90#Example-Notebook :\n",
        "        \n",
        "        if not os.path.exists(filename + '.png') or overwrite:\n",
        "          area_of_interest = {\n",
        "          \"type\": \"Polygon\",\n",
        "          \"coordinates\": [list(traindf.loc[traindf.cell_id == i].iloc[0].geometry.exterior.coords)],\n",
        "          }\n",
        "\n",
        "          bbox = rasterio.features.bounds(area_of_interest)\n",
        "          search = client.search(\n",
        "              collections=[\"cop-dem-glo-30\"],\n",
        "              bbox = bbox,\n",
        "          )\n",
        "\n",
        "          \n",
        "          items = list(search.get_items())\n",
        "\n",
        "          signed_asset = planetary_computer.sign(items[0].assets[\"data\"])\n",
        "          \n",
        "          data = (\n",
        "              xarray.open_rasterio(signed_asset.href)\n",
        "              .squeeze()\n",
        "              .drop(\"band\")\n",
        "          )\n",
        "\n",
        "\n",
        "          min_lon = traindf.loc[traindf.cell_id == i].iloc[0].geometry.bounds[0]\n",
        "          min_lat = traindf.loc[traindf.cell_id == i].iloc[0].geometry.bounds[1]\n",
        "          max_lon = traindf.loc[traindf.cell_id == i].iloc[0].geometry.bounds[2]\n",
        "          max_lat = traindf.loc[traindf.cell_id == i].iloc[0].geometry.bounds[3]\n",
        "\n",
        "          mask_lon = (data.x >= min_lon) & (data.x <= max_lon)\n",
        "          mask_lat = (data.y >= min_lat) & (data.y <= max_lat)\n",
        "\n",
        "\n",
        "          cropped_data = data.where(mask_lon & mask_lat, drop=True)\n",
        "\n",
        "          #hillshade = xrspatial.hillshade(cropped_data)\n",
        "          img = stack(shade(cropped_data, cmap=\"red\"), \n",
        "                      shade(xrspatial.slope(cropped_data), cmap=\"blue\"),\n",
        "                      shade(xrspatial.aspect(cropped_data), cmap=\"green\"))\n",
        "          \n",
        "          export_image(img=img, filename=filename, background=None)\n",
        "      \n",
        "      except TimeoutException:\n",
        "          print(f\"Request Timeout for cell_id {traindf.cell_id[i]}\")\n",
        "        \n",
        "      except Exception as e:\n",
        "        print(\"Some other Error\")\n",
        "      else: \n",
        "        signal.alarm(0)\n",
        "        still_working = False\n",
        "\n",
        "        traindf.loc[traindf.cell_id == i, \"copernicus_filelocations\"] = filename + '.png'\n",
        "        if x % 100 == 0:\n",
        "          print(f'{x} out of {length_cell_id} complete')\n",
        "          print(f'Iteration Time: {time.time() - start}')\n",
        "        x += 1\n",
        "  \n",
        "  print(\"Zipping\")\n",
        "  shutil.make_archive(\"new_copernicus\", 'zip', '/content/Copernicus_Data')\n",
        "  print(\"Zipping Complete, Copying\")\n",
        "  shutil.copy(\"new_copernicus.zip\", \"/content/drive/MyDrive/snowcapstone team spring 2022/Copernicus_Data/new_copernicus.zip\")"
      ],
      "metadata": {
        "id": "MGcd6Xo7_7Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_copernicus(traindf, False)"
      ],
      "metadata": {
        "id": "DuTh-zCfKDNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindf = traindf.drop([\"region\", 'geometry', 'datestring', 'centroid', 'center_lat', 'center_long'], axis = 1)\n",
        "traindf.head()"
      ],
      "metadata": {
        "id": "PJrYQqcVZNpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(traindf).to_csv('/content/drive/MyDrive/snowcapstone team spring 2022/Modeling/traindf_modis_columns_allregions.csv')"
      ],
      "metadata": {
        "id": "352W4g_z6nZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ-aDo6l3llL"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "#Potential Ideas:\n",
        "#Include reverse distance interpolation.\n",
        "#\n",
        "\n",
        "def get_stations(df, num_stations = 5):\n",
        "  #Returns the average SWE from the X closest measurement stations on the same day\n",
        "  averages = []\n",
        "  average_elevation = []\n",
        "  median = []\n",
        "  median_elevation = []\n",
        "  max = []\n",
        "  max_elevation = []\n",
        "  #Calculating distance matrix\n",
        "  dist1 = gpd.GeoDataFrame(geometry = df.geometry.unique(), crs = \"EPSG:4326\").to_crs('+proj=cea')\n",
        "  dist2 = gpd.GeoDataFrame(geometry = trainmeta.geometry, crs = \"EPSG:4326\").to_crs('+proj=cea') \n",
        "\n",
        "  distmatrix = dist2.geometry.apply(lambda g: dist1.geometry.boundary.distance(g))\n",
        "  distmatrix.set_axis(df.cell_id.unique(), axis = 1, inplace = True)\n",
        "  distmatrix[\"station_id\"] = trainmeta.station_id.unique()\n",
        "  \n",
        "  #for each row in the df\n",
        "  for index, row in df.iterrows():\n",
        "    station_dist =distmatrix[[\"station_id\", row.cell_id]]\n",
        "\n",
        "    start_date = row.date - timedelta(days = 7)\n",
        "    end_date = row.date\n",
        "    after_start_date = trainfeatures[\"date\"] >= start_date\n",
        "    before_end_date = trainfeatures[\"date\"] <= end_date\n",
        "    between_two_dates = after_start_date & before_end_date\n",
        "    swes = trainfeatures.loc[between_two_dates]\n",
        "\n",
        "    station_swe = station_dist.merge(swes, how = 'left', on='station_id')\n",
        "    station_swe = station_swe[station_swe[\"SWE\"].notna()]\n",
        "\n",
        "    station_swe.sort_values(by = [row.cell_id, \"date\"], inplace = True)\n",
        "\n",
        "    #This is where interpolation can happen\n",
        "\n",
        "    averages.append(station_swe.head(num_stations).SWE.mean())\n",
        "    average_elevation.append(station_swe.head(num_stations).elevation_m.mean())\n",
        "    median.append(station_swe.head(num_stations).SWE.median())\n",
        "    median_elevation.append(station_swe.head(num_stations).elevation_m.median())\n",
        "    max.append(station_swe.head(num_stations).SWE.max())\n",
        "    max_elevation.append(station_swe.head(num_stations).elevation_m.max())\n",
        "\n",
        "  #return averages, median, max, average_elevation, median_elevation, max_elevation\n",
        "  return averages, average_elevation, median, median_elevation, max, max_elevation\n",
        "  '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGVnLsQbCyN8"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "#Turns off a bunch of errors\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "averages, average_elevation, median, median_elevation, max, max_elevation = get_stations(traindf)\n",
        "\n",
        "pd.options.mode.chained_assignment = 'warn'\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwDxgDwIo0CR"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "traindf[\"mean_local_swe\"] = averages\n",
        "traindf[\"median_local_swe\"] = median\n",
        "traindf[\"max_local_swe\"] = max\n",
        "traindf[\"mean_local_elevation\"] = average_elevation\n",
        "traindf[\"median_local_elevation\"] = median_elevation\n",
        "traindf[\"max_local_elevation\"] = max_elevation\n",
        "\n",
        "print(traindf.isna().sum())\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ingesting Sentinel 2 Data"
      ],
      "metadata": {
        "id": "Q8CQuwM2ywQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pulling in Data by date/1k square and saving as .tiff format"
      ],
      "metadata": {
        "id": "5qlHktGcy4cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Test that ee connection is still live\n",
        "try:\n",
        "        ee.Initialize()\n",
        "except Exception as e:\n",
        "        ee.Authenticate()\n",
        "        ee.Initialize()"
      ],
      "metadata": {
        "id": "Vc5HIf1ezGHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Import additional packages (check for duplicates)\n",
        "import pickle\n",
        "import time\n",
        "import math\n",
        "import requests, zipfile, io\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "0lR9GObqzOQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Image Collection\n",
        "\n",
        "Define image selection to Copernicus/S2 or Sentinel 2 data. \n",
        "\n",
        "Available bands and resolution here: https://gisgeography.com/sentinel-2-bands-combinations/\n",
        "\n",
        "The following visualizations are the most applicable to our study:\n",
        "\n",
        "Geology: Bands B12, B11, B2\n",
        "Vegetation: B8-B4/B8+B4\n",
        "\n",
        "Starting with focus on geology bands, this pulls in the B12(R), B11(G), B4(B)\n",
        "\n",
        "B12 and B11 are at 20m resolution, and B4 is at 10m resolution"
      ],
      "metadata": {
        "id": "gZSc2WkSzk_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentinel 2"
      ],
      "metadata": {
        "id": "by4m_1K81-aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining image\n",
        "sen2 = ee.ImageCollection(\"COPERNICUS/S2\").filterDate(startDate, endDate) \n",
        "\n",
        "#selecting bands\n",
        "sen2 = sen2.select([\"B12\",\"B11\",\"B2\"])"
      ],
      "metadata": {
        "id": "lPe39t4w2G2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentinel 1\n"
      ],
      "metadata": {
        "id": "nFUEMt2UUfEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining image\n",
        "\n",
        "sen1 = ee.ImageCollection(\"COPERNICUS/S1_GRD\").filterDate(startDate, endDate) \n",
        "\n",
        "#selecting bands\n",
        "sen1_A = sen1.select([\"HH\",\"HV\",\"angle\"])\n",
        "sen1_B = sen1.select([\"VV\", \"VH\", \"angle\"])"
      ],
      "metadata": {
        "id": "cx9vSjgxUePq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to define image download\n",
        "\n",
        "Create a funciton to download imagery. Takes the centroid from above and size input and pulls images into google drive. \n",
        "\n",
        "Len = total size of image in meters computed as the resolution of the image bands being pulled in, and the number of pixels we want to capture total (224x224). Then create bounding box around the circle to get a square. "
      ],
      "metadata": {
        "id": "FCrcVtj521fV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def image_download(image,point,image_res,n_pixels,folder_name, image_name, storage=\"Drive\"):\n",
        "    \n",
        "    \"\"\"\n",
        "    Function to download satellite images from a ee.imageCollection object.\n",
        "    We first generate a bounding box of image_res*n_pixels meters around \"point\",\n",
        "    then we clip that region from the image collection, take the mean image from the collection,\n",
        "    and send that as a task to the Google Earth Engine. \n",
        "    After that, we download the image Google Cloud Storage if storage==\"Cloud\", \n",
        "    to Google Drive if storage==\"Drive\" or to a local folder if storage==\"local\".\n",
        "    \n",
        "    Inputs:\n",
        "    -image= ee.ImageCollection object\n",
        "    -point= ee.Geometry.Point object\n",
        "    -image_res= resolution of the image in meters\n",
        "    -n_pixels= number of pixels to extract on the images\n",
        "    -storage= string indicating if we are storing the images in Google Cloud,Google Drive or locally.\n",
        "              Defaults to local storage.\n",
        "    -folder_name= string with Google Cloud bucket name if storage==\"Cloud\"\n",
        "                  string with the name of a folder in the root of Google Drive if storage==\"Drive\"\n",
        "                  string with the path to the image if storage==\"local\"\n",
        "    -image_name= string with the image_name for the TIFF image.\n",
        "\n",
        "    Output:\n",
        "     When storage==\"Drive\":\n",
        "     -task= an EE task object. we can then use task.status() to check the status of the task.\n",
        "     If the task is completed, we will see a TIFF image in \"folder_name\" with name \"image_name.tif\".\n",
        "     The image has 3 dimensions, where the first 2 are n_pixels, and the 3rd is the number of bands of \"image\".\n",
        "     When storage==\"local\":\n",
        "     -there is no output, but we will see one TIFF file per band of our image in the folder \"folder_name\".\n",
        "    \"\"\"\n",
        "    #generating the box around the point\n",
        "    len=image_res*n_pixels # for sen2, 20 meters * 224 pixels\n",
        "    region= point.buffer(len/2).bounds().getInfo()['coordinates']\n",
        "    #defining the rectangle\n",
        "    coords=np.array(region)\n",
        "    #taking min and maxs of coordinates to define the rectangle\n",
        "    coords=[np.min(coords[:,:,0]), np.min(coords[:,:,1]), np.max(coords[:,:,0]), np.max(coords[:,:,1])]\n",
        "    rectangle=ee.Geometry.Rectangle(coords)\n",
        "    \n",
        "    if storage==\"Drive\":\n",
        "        #generating the export task (dimensions is \"WIDTHxHEIGHT\")\n",
        "        task=ee.batch.Export.image.toDrive(image=image.filterBounds(rectangle).mean(), \n",
        "                            folder=folder_name, \n",
        "                            description=image_name, \n",
        "                            region=str(region), dimensions=str(n_pixels)+\"x\"+str(n_pixels))\n",
        "        #starting the task\n",
        "        task.start()\n",
        "        return task\n",
        "    \n",
        "    if storage==\"local\":\n",
        "        #downloading the image\n",
        "        r=requests.get( image.filterBounds(rectangle).mean().getDownloadURL({\n",
        "                            'name': image_name, \n",
        "                            'region': str(region),\n",
        "                            'dimensions': str(n_pixels)+\"x\"+str(n_pixels)}))\n",
        "        #unzip it to the selected directory\n",
        "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "        z.extractall(folder_name)"
      ],
      "metadata": {
        "id": "WvXDfzOq4VvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST"
      ],
      "metadata": {
        "id": "KY3Rcpvm-g6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test image\n",
        "test=ee.Geometry.Point(-120.61888999873261,39.675880337476684)\n",
        "\n",
        "#running function\n",
        "image_download(image=sen2,point=test,image_res=100,n_pixels=224,folder_name='Sen2_Tiff', image_name='test_image', storage=\"local\")"
      ],
      "metadata": {
        "id": "vJnUWTJB5EFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('Sen2_Tiff')"
      ],
      "metadata": {
        "id": "MkvywTLY-V6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterate over all of the dataframe"
      ],
      "metadata": {
        "id": "tHmiPzJr-jDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traindf.head()"
      ],
      "metadata": {
        "id": "FoXWDfyZ-lUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(traindf)):\n",
        "\n",
        "    #create a name for the image\n",
        "    image_name = traindf.cell_id[i] + '_sentinel2_' + traindf.datestring[i] + '.jpg'\n",
        "\n",
        "    \n",
        "    startDate = traindf.date[i] - timedelta(days = 365)\n",
        "    endDate = traindf.date[i] + timedelta(days = 1)\n",
        "    year = startDate.year\n",
        "    print(year)\n",
        "    print(startDate)\n",
        "    \n",
        "      #defining image\n",
        "\n",
        "    sen2 = ee.ImageCollection(\"COPERNICUS/S2\")\n",
        "      # filter date\n",
        "    sen2 = sen2.filterDate(startDate, endDate) \n",
        "      #applying cloud masking\n",
        "      #selecting bands\n",
        "    sen2 = sen2.select([\"B12\",\"B11\",\"B2\"])\n",
        "    \n",
        "      #I create a google earth images point based on the area centroid\n",
        "    centroid = ee.Geometry.Point(traindf.center_long[i], traindf.center_lat[i])\n",
        "    print(centroid)\n",
        "      \n",
        "    image_download(image=sen2, point=centroid, image_res=20, n_pixels=224, folder_name='Sen2_Tiff', image_name='image_name', storage=\"local\")\n"
      ],
      "metadata": {
        "id": "ZHuBtaXj-pYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(traindf)):\n",
        "\n",
        "    #create a name for the image\n",
        "    image_name = traindf.cell_id[i] + '_sentinel1a_' + traindf.datestring[i] + '.jpg'\n",
        "\n",
        "    \n",
        "    startDate = traindf.date[i] - timedelta(days = 7)\n",
        "    endDate = traindf.date[i] + timedelta(days = 1)\n",
        "    year = startDate.year\n",
        "    print(year)\n",
        "    print(startDate)\n",
        "    \n",
        "\n",
        "      #defining image\n",
        "\n",
        "    sen1 = ee.ImageCollection(\"COPERNICUS/S1_GRD\").filterDate(startDate, endDate) \n",
        "\n",
        "      #selecting bands\n",
        "    sen1_A = sen1.select([\"HH\",\"HV\",\"angle\"])\n",
        "      # filter date\n",
        "\n",
        "    \n",
        "      #I create a google earth images point based on the area centroid\n",
        "    centroid = ee.Geometry.Point(traindf.center_long[i], traindf.center_lat[i]).buffer(10000)\n",
        "    print(centroid)\n",
        "      \n",
        "    image_download(image=sen1_A, point=centroid, image_res=20, n_pixels=224, folder_name='Sen1a_Tiff', image_name='image_name', storage=\"local\")\n"
      ],
      "metadata": {
        "id": "apj8dWab-pbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(traindf)):\n",
        "\n",
        "    #create a name for the image\n",
        "    image_name = traindf.cell_id[i] + '_sentinel1b_' + traindf.datestring[i] + '.jpg'\n",
        "\n",
        "    \n",
        "    startDate = traindf.date[i] - timedelta(days = 7)\n",
        "    endDate = traindf.date[i] + timedelta(days = 1)\n",
        "    year = startDate.year\n",
        "    print(year)\n",
        "    print(startDate)\n",
        "    \n",
        "\n",
        "\n",
        "    sen1 = ee.ImageCollection(\"COPERNICUS/S1_GRD\").filterDate(startDate, endDate) \n",
        "\n",
        "      #selecting bands\n",
        "    sen1_B = sen1.select([\"VV\", \"VH\", \"angle\"])\n",
        "      # filter date\n",
        "\n",
        "    \n",
        "      #I create a google earth images point based on the area centroid\n",
        "    centroid = ee.Geometry.Point(traindf.center_long[i], traindf.center_lat[i])\n",
        "    print(centroid)\n",
        "      \n",
        "    image_download(image=sen1_b, point=centroid, image_res=20, n_pixels=224, folder_name='Sen1b_Tiff', image_name='image_name', storage=\"local\")\n"
      ],
      "metadata": {
        "id": "zCO4jgCyXI2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading in .tiff images and loading max, min, medians to testdf"
      ],
      "metadata": {
        "id": "e3lLrIlYy94Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pull_SENT2(traindf, overwrite = False, names_only = False):\n",
        "  filelocations = []\n",
        "  x = 0\n",
        "\n",
        "  for i in range(len(traindf.SWE)):\n",
        "\n",
        "    #create a name for the image\n",
        "    pict_name = traindf.cell_id[i] + '_sentinel2_' + traindf.datestring[i] + '.jpg'\n",
        "\n",
        "    #create the whole filename with path to the correct folder\n",
        "    filename = os.path.join('/content/drive/MyDrive/snowcapstone team spring 2022/Sen2_Tiff', pict_name)\n",
        "\n",
        "    if names_only:\n",
        "      filelocations.append(filename)\n",
        "      x += 1\n",
        "      if x % 5000 == 0:\n",
        "        print(f'{x} files already exist')\n",
        "\n",
        "    elif os.path.exists(filename) and not overwrite:\n",
        "      filelocations.append(filename)\n",
        "      x += 1\n",
        "      if x % 5000 == 0:\n",
        "        print(f'{x} files already exist')\n",
        "\n",
        "    else:\n",
        "      #We need a start date and an end date. Just like a regular python slice, \n",
        "      #the end date is not included, so by using a 1 day frame, I am actually limiting\n",
        "      #the range to only the day in question\n",
        "      start_date = traindf.date[i] - timedelta(days = 7)\n",
        "      end_date = traindf.date[i] + timedelta(days = 1)\n",
        "\n",
        "      #First I get the image collection from the MODIS data, filter it only to the days in question\n",
        "      #and select my bands, then sort so the most recent day in the group is at the top\n",
        "      Collection = ee.ImageCollection('COPERNICUS/S2') \\\n",
        "                  .filter(ee.Filter.date(start_date, end_date)) \\\n",
        "                  .select(['B11', 'B12', 'B2']) \\\n",
        "\n",
        "      #I create a google earth images point based on the area centroid\n",
        "      centroid = ee.Geometry.Point(traindf.center_long[i], traindf.center_lat[i])\n",
        "\n",
        "      #Because the image collection is limited to a single day, there is only one image\n",
        "      #So I just take it\n",
        "      point = Collection.first().unmask(0)\n",
        "\n",
        "      # Get individual band arrays and build them into an RGB image\n",
        "      # The \"buffer\" is a circular distance around the point, measured in meters right now it is 100km\n",
        "      rgb = ee.Image.rgb(point.clip(centroid.buffer(10000)).select('B11'),\n",
        "                        point.clip(centroid.buffer(10000)).select('B12'),\n",
        "                        point.clip(centroid.buffer(10000)).select('B2'))\n",
        "\n",
        "      #Now I get the url for the image\n",
        "      url = rgb.getThumbURL({'min': -20, 'max': 0})\n",
        "\n",
        "      #add the name to my list I created earlier\n",
        "      filelocations.append(filename)\n",
        "\n",
        "      #now I open the url and download the image to the specified file location\n",
        "      response = requests.get(url, stream=True)\n",
        "      with open(filename, 'wb') as out_file:\n",
        "          shutil.copyfileobj(response.raw, out_file)\n",
        "      del response\n",
        "    \n",
        "  traindf[\"Sentinel2_filelocations\"] = filelocations"
      ],
      "metadata": {
        "id": "hZ7Wfjn2boc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pull_SENT2(traindf, overwrite = True)"
      ],
      "metadata": {
        "id": "317utemDdb28"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SnowCast Showdown Data Wrangling.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}