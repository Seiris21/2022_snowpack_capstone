{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seiris21/2022_snowpack_capstone/blob/main/notebooks/data_ingestion/SnowCast%20Showdown%20Data%20Wrangling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XQtxwPWn9xYg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3262aa7-36a0-48bb-f6e6-4c1217049fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Waiting for headers] [2 InRelease 14.2 kB/88.7 kB 16%] [Connected to cloud.\r0% [Waiting for headers] [2 InRelease 88.7 kB/88.7 kB 100%] [Connected to cloud\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r                                                                               \rGet:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r                                                                               \rHit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "\r0% [4 InRelease 15.6 kB/88.7 kB 18%] [Connecting to ppa.launchpad.net (91.189.9\r0% [1 InRelease gpgv 15.9 kB] [4 InRelease 15.6 kB/88.7 kB 18%] [Waiting for he\r                                                                               \rHit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 15.9 kB] [4 InRelease 47.5 kB/88.7 kB 54%] [Connecting to \r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rGet:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,827 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [937 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [806 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,474 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,596 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [840 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,035 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,252 kB]\n",
            "Get:23 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [42.8 kB]\n",
            "Get:25 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [929 kB]\n",
            "Fetched 15.0 MB in 3s (5,860 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libgdal-dev is already the newest version (2.2.3+dfsg-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 67 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "gdal-bin is already the newest version (2.2.3+dfsg-2).\n",
            "python-gdal is already the newest version (2.2.3+dfsg-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  python3-numpy\n",
            "Suggested packages:\n",
            "  python-numpy-doc python3-nose python3-numpy-dbg\n",
            "The following NEW packages will be installed:\n",
            "  python3-gdal python3-numpy\n",
            "0 upgraded, 2 newly installed, 0 to remove and 67 not upgraded.\n",
            "Need to get 2,288 kB of archives.\n",
            "After this operation, 13.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-numpy amd64 1:1.13.3-2ubuntu1 [1,943 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-gdal amd64 2.2.3+dfsg-2 [346 kB]\n",
            "Fetched 2,288 kB in 0s (16.4 MB/s)\n",
            "Selecting previously unselected package python3-numpy.\n",
            "(Reading database ... 155320 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-numpy_1%3a1.13.3-2ubuntu1_amd64.deb ...\n",
            "Unpacking python3-numpy (1:1.13.3-2ubuntu1) ...\n",
            "Selecting previously unselected package python3-gdal.\n",
            "Preparing to unpack .../python3-gdal_2.2.3+dfsg-2_amd64.deb ...\n",
            "Unpacking python3-gdal (2.2.3+dfsg-2) ...\n",
            "Setting up python3-numpy (1:1.13.3-2ubuntu1) ...\n",
            "Setting up python3-gdal (2.2.3+dfsg-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libspatialindex-c4v5 libspatialindex-dev libspatialindex4v5\n",
            "  python3-pkg-resources\n",
            "Suggested packages:\n",
            "  python3-setuptools\n",
            "The following NEW packages will be installed:\n",
            "  libspatialindex-c4v5 libspatialindex-dev libspatialindex4v5\n",
            "  python3-pkg-resources python3-rtree\n",
            "0 upgraded, 5 newly installed, 0 to remove and 67 not upgraded.\n",
            "Need to get 671 kB of archives.\n",
            "After this operation, 3,948 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libspatialindex4v5 amd64 1.8.5-5 [219 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libspatialindex-c4v5 amd64 1.8.5-5 [51.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libspatialindex-dev amd64 1.8.5-5 [285 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-rtree all 0.8.3+ds-1 [16.9 kB]\n",
            "Fetched 671 kB in 0s (5,477 kB/s)\n",
            "Selecting previously unselected package libspatialindex4v5:amd64.\n",
            "(Reading database ... 155730 files and directories currently installed.)\n",
            "Preparing to unpack .../libspatialindex4v5_1.8.5-5_amd64.deb ...\n",
            "Unpacking libspatialindex4v5:amd64 (1.8.5-5) ...\n",
            "Selecting previously unselected package libspatialindex-c4v5:amd64.\n",
            "Preparing to unpack .../libspatialindex-c4v5_1.8.5-5_amd64.deb ...\n",
            "Unpacking libspatialindex-c4v5:amd64 (1.8.5-5) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package libspatialindex-dev:amd64.\n",
            "Preparing to unpack .../libspatialindex-dev_1.8.5-5_amd64.deb ...\n",
            "Unpacking libspatialindex-dev:amd64 (1.8.5-5) ...\n",
            "Selecting previously unselected package python3-rtree.\n",
            "Preparing to unpack .../python3-rtree_0.8.3+ds-1_all.deb ...\n",
            "Unpacking python3-rtree (0.8.3+ds-1) ...\n",
            "Setting up libspatialindex4v5:amd64 (1.8.5-5) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up libspatialindex-c4v5:amd64 (1.8.5-5) ...\n",
            "Setting up libspatialindex-dev:amd64 (1.8.5-5) ...\n",
            "Setting up python3-rtree (0.8.3+ds-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "\u001b[K     |████████████████████████████████| 16.7 MB 14.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 57.2 MB/s \n",
            "\u001b[?25h  Building wheel for geopandas (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (5.1.1)\n",
            "Collecting tornado\n",
            "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
            "\u001b[K     |████████████████████████████████| 428 kB 13.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: tornado\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\u001b[0m\n",
            "Successfully installed tornado-6.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tornado"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#%%capture\n",
        "!apt-get update\n",
        "# Install GDAL and Geopandas\n",
        "!apt-get install libgdal-dev \n",
        "!apt install gdal-bin python-gdal python3-gdal --quiet\n",
        "!apt install python3-rtree --quiet\n",
        "!pip install git+git://github.com/geopandas/geopandas.git --quiet\n",
        "\n",
        "%pip install -U tornado"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install \"dask[complete]\"\n",
        "%pip install \"dask[complete]\" --upgrade"
      ],
      "metadata": {
        "id": "izqO08-7767U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "097b24c2-b963-48be-9a23-64d17b3ff25a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask[complete] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Collecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.3.0)\n",
            "Collecting distributed>=2.0\n",
            "  Downloading distributed-2022.2.0-py3-none-any.whl (837 kB)\n",
            "\u001b[K     |████████████████████████████████| 837 kB 12.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYaml in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (3.13)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.3.5)\n",
            "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (0.11.2)\n",
            "Requirement already satisfied: bokeh>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.21.5)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 61.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (2.11.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (2.8.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (6.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (3.10.0.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (21.3)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (1.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (57.4.0)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (5.4.8)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (2.0.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (7.1.2)\n",
            "Collecting cloudpickle>=0.2.1\n",
            "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Collecting distributed>=2.0\n",
            "  Downloading distributed-2022.1.1-py3-none-any.whl (830 kB)\n",
            "\u001b[K     |████████████████████████████████| 830 kB 49.4 MB/s \n",
            "\u001b[?25h  Downloading distributed-2022.1.0-py3-none-any.whl (822 kB)\n",
            "\u001b[K     |████████████████████████████████| 822 kB 71.5 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.12.0-py3-none-any.whl (802 kB)\n",
            "\u001b[K     |████████████████████████████████| 802 kB 71.4 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.11.2-py3-none-any.whl (802 kB)\n",
            "\u001b[K     |████████████████████████████████| 802 kB 67.5 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.11.1-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 64.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (2.4.0)\n",
            "  Downloading distributed-2021.11.0-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 59.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.10.0-py3-none-any.whl (791 kB)\n",
            "\u001b[K     |████████████████████████████████| 791 kB 75.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.9.1-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 72.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.9.0-py3-none-any.whl (779 kB)\n",
            "\u001b[K     |████████████████████████████████| 779 kB 80.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (1.7.0)\n",
            "  Downloading distributed-2021.8.1-py3-none-any.whl (778 kB)\n",
            "\u001b[K     |████████████████████████████████| 778 kB 66.4 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.8.0-py3-none-any.whl (776 kB)\n",
            "\u001b[K     |████████████████████████████████| 776 kB 63.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.7.2-py3-none-any.whl (769 kB)\n",
            "\u001b[K     |████████████████████████████████| 769 kB 70.0 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.7.1-py3-none-any.whl (766 kB)\n",
            "\u001b[K     |████████████████████████████████| 766 kB 70.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.7.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 55.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.6.2-py3-none-any.whl (722 kB)\n",
            "\u001b[K     |████████████████████████████████| 722 kB 41.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.6.1-py3-none-any.whl (722 kB)\n",
            "\u001b[K     |████████████████████████████████| 722 kB 65.2 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.6.0-py3-none-any.whl (715 kB)\n",
            "\u001b[K     |████████████████████████████████| 715 kB 49.4 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.5.1-py3-none-any.whl (705 kB)\n",
            "\u001b[K     |████████████████████████████████| 705 kB 65.5 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.5.0-py3-none-any.whl (699 kB)\n",
            "\u001b[K     |████████████████████████████████| 699 kB 64.5 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.4.1-py3-none-any.whl (696 kB)\n",
            "\u001b[K     |████████████████████████████████| 696 kB 74.0 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.4.0-py3-none-any.whl (684 kB)\n",
            "\u001b[K     |████████████████████████████████| 684 kB 67.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.3.1-py3-none-any.whl (679 kB)\n",
            "\u001b[K     |████████████████████████████████| 679 kB 83.2 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.3.0-py3-none-any.whl (675 kB)\n",
            "\u001b[K     |████████████████████████████████| 675 kB 53.6 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.2.0-py3-none-any.whl (675 kB)\n",
            "\u001b[K     |████████████████████████████████| 675 kB 65.2 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.1.1-py3-none-any.whl (672 kB)\n",
            "\u001b[K     |████████████████████████████████| 672 kB 68.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.1.0-py3-none-any.whl (671 kB)\n",
            "\u001b[K     |████████████████████████████████| 671 kB 69.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2020.12.0-py3-none-any.whl (669 kB)\n",
            "\u001b[K     |████████████████████████████████| 669 kB 67.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.30.1-py3-none-any.whl (656 kB)\n",
            "\u001b[K     |████████████████████████████████| 656 kB 66.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh>=1.0.0->dask[complete]) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh>=1.0.0->dask[complete]) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[complete]) (2018.9)\n",
            "Collecting locket\n",
            "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh>=1.0.0->dask[complete]) (1.15.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.0->dask[complete]) (1.0.1)\n",
            "Installing collected packages: locket, cloudpickle, partd, fsspec, distributed\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\u001b[0m\n",
            "Successfully installed cloudpickle-2.0.0 distributed-2.30.1 fsspec-2022.2.0 locket-0.2.1 partd-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cloudpickle"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask[complete] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.21.5)\n",
            "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (0.11.2)\n",
            "Requirement already satisfied: bokeh>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.3.3)\n",
            "Requirement already satisfied: PyYaml in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (3.13)\n",
            "Requirement already satisfied: distributed>=2.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.30.1)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2022.2.0)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (1.3.5)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from dask[complete]) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (2.11.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (2.8.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (6.1)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh>=1.0.0->dask[complete]) (3.10.0.2)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (5.4.8)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (2.0.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (1.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (57.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (1.7.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0->dask[complete]) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh>=1.0.0->dask[complete]) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh>=1.0.0->dask[complete]) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[complete]) (2018.9)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask[complete]) (0.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh>=1.0.0->dask[complete]) (1.15.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.0->dask[complete]) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%capture\n",
        "%pip install pystac_client planetary_computer rasterio xarray-spatial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qEgdiEnI8wh6",
        "outputId": "34ee72f2-3c6d-447a-c516-aad023a209d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pystac_client\n",
            "  Downloading pystac_client-0.3.2-py3-none-any.whl (19 kB)\n",
            "Collecting planetary_computer\n",
            "  Downloading planetary_computer-0.4.5-py3-none-any.whl (13 kB)\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting xarray-spatial\n",
            "  Downloading xarray_spatial-0.3.2-py3-none-any.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 49.0 MB/s \n",
            "\u001b[?25hCollecting requests>=2.25\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting pystac~=1.2.0\n",
            "  Downloading pystac-1.2.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from pystac~=1.2.0->pystac_client) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7 in /usr/local/lib/python3.7/dist-packages (from pystac~=1.2.0->pystac_client) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.0->pystac~=1.2.0->pystac_client) (1.15.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25->pystac_client) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25->pystac_client) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25->pystac_client) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25->pystac_client) (1.24.3)\n",
            "Requirement already satisfied: click>=7.1 in /usr/local/lib/python3.7/dist-packages (from planetary_computer) (7.1.2)\n",
            "Collecting pydantic[dotenv]>=1.7.3\n",
            "  Downloading pydantic-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 56.1 MB/s \n",
            "\u001b[?25hCollecting pytz>=2020.5\n",
            "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 65.1 MB/s \n",
            "\u001b[?25hCollecting python-dotenv>=0.10.4\n",
            "  Downloading python_dotenv-0.19.2-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from rasterio) (0.7.2)\n",
            "Collecting affine\n",
            "  Downloading affine-2.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.21.5)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.7)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.7/dist-packages (from xarray-spatial) (0.18.2)\n",
            "Requirement already satisfied: param>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from xarray-spatial) (1.12.0)\n",
            "Collecting distributed>=2021.03.0\n",
            "  Using cached distributed-2022.2.0-py3-none-any.whl (837 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from xarray-spatial) (1.3.5)\n",
            "Collecting pyct<=0.4.6\n",
            "  Downloading pyct-0.4.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from xarray-spatial) (7.1.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from xarray-spatial) (0.51.2)\n",
            "Collecting datashader\n",
            "  Downloading datashader-0.13.0-py2.py3-none-any.whl (15.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.8 MB 38.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dask in /usr/local/lib/python3.7/dist-packages (from xarray-spatial) (2.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (21.3)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (5.4.8)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (2.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (3.13)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (6.1)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (0.11.2)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (1.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (2.11.3)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (2.0.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (1.0.3)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.03.0->xarray-spatial) (2.0.0)\n",
            "Collecting dask\n",
            "  Downloading dask-2022.2.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 65.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask->xarray-spatial) (1.2.0)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 17.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask->xarray-spatial) (2022.2.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask->xarray-spatial) (0.2.1)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2021.03.0->xarray-spatial) (1.0.1)\n",
            "Requirement already satisfied: colorcet>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from datashader->xarray-spatial) (3.0.0)\n",
            "Collecting datashape>=0.5.1\n",
            "  Downloading datashape-0.5.2.tar.gz (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from datashader->xarray-spatial) (1.4.1)\n",
            "Requirement already satisfied: bokeh>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from dask->xarray-spatial) (2.3.3)\n",
            "Collecting multipledispatch>=0.4.7\n",
            "  Downloading multipledispatch-0.6.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed>=2021.03.0->xarray-spatial) (2.0.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->xarray-spatial) (0.34.0)\n",
            "Building wheels for collected packages: datashape\n",
            "  Building wheel for datashape (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for datashape: filename=datashape-0.5.2-py3-none-any.whl size=59438 sha256=9f7f006c2f7aced10984503523d47505ebaf8bc87208f0366bebbc3c07477707\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/b7/80/333a5c3312ed4cd54f5d5b869868c14e0c6002cb5c7238b52d\n",
            "Successfully built datashape\n",
            "Installing collected packages: pyyaml, pytz, dask, pyct, multipledispatch, distributed, requests, python-dotenv, pystac, pydantic, datashape, snuggs, pystac-client, datashader, affine, xarray-spatial, rasterio, planetary-computer\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2.12.0\n",
            "    Uninstalling dask-2.12.0:\n",
            "      Successfully uninstalled dask-2.12.0\n",
            "  Attempting uninstall: pyct\n",
            "    Found existing installation: pyct 0.4.8\n",
            "    Uninstalling pyct-0.4.8:\n",
            "      Successfully uninstalled pyct-0.4.8\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2.30.1\n",
            "    Uninstalling distributed-2.30.1:\n",
            "      Successfully uninstalled distributed-2.30.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed affine-2.3.0 dask-2022.2.0 datashader-0.13.0 datashape-0.5.2 distributed-2022.2.0 multipledispatch-0.6.0 planetary-computer-0.4.5 pyct-0.4.6 pydantic-1.9.0 pystac-1.2.0 pystac-client-0.3.2 python-dotenv-0.19.2 pytz-2021.3 pyyaml-6.0 rasterio-1.2.10 requests-2.27.1 snuggs-1.4.7 xarray-spatial-0.3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pytz"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAeHA6UB-JqZ",
        "outputId": "1863e5cc-0ec3-4e4a-8c89-deabd9e4cc34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lN1ofW4_-OY8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "\n",
        "from pystac_client import Client\n",
        "import planetary_computer\n",
        "import xarray\n",
        "import dask.dataframe as dd\n",
        "import xrspatial\n",
        "from datashader.transfer_functions import shade, stack\n",
        "from datashader.colors import Elevation\n",
        "from datashader.utils import export_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBvbkksuJz8F"
      },
      "source": [
        "# Data Ingestion and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MsIAo5K3_9pv"
      },
      "outputs": [],
      "source": [
        "trainfeatures = pd.read_csv(\"/content/drive/MyDrive/snowcapstone team spring 2022/Competition_Data/ground_measures_train_features.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "uhyIte-eARhO",
        "outputId": "0e79d229-de37-4aea-8d23-a8ece35254e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-53c531ad-c6a4-4d7e-90db-01b1cf64b710\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>2013-01-01</th>\n",
              "      <th>2013-01-08</th>\n",
              "      <th>2013-01-15</th>\n",
              "      <th>2013-01-22</th>\n",
              "      <th>2013-01-29</th>\n",
              "      <th>2013-02-05</th>\n",
              "      <th>2013-02-12</th>\n",
              "      <th>2013-02-19</th>\n",
              "      <th>2013-02-26</th>\n",
              "      <th>2013-03-05</th>\n",
              "      <th>2013-03-12</th>\n",
              "      <th>2013-03-19</th>\n",
              "      <th>2013-03-26</th>\n",
              "      <th>2013-04-02</th>\n",
              "      <th>2013-04-09</th>\n",
              "      <th>2013-04-16</th>\n",
              "      <th>2013-04-23</th>\n",
              "      <th>2013-04-30</th>\n",
              "      <th>2013-05-07</th>\n",
              "      <th>2013-05-14</th>\n",
              "      <th>2013-05-21</th>\n",
              "      <th>2013-05-28</th>\n",
              "      <th>2013-06-04</th>\n",
              "      <th>2013-06-11</th>\n",
              "      <th>2013-06-18</th>\n",
              "      <th>2013-06-25</th>\n",
              "      <th>2013-12-03</th>\n",
              "      <th>2013-12-10</th>\n",
              "      <th>2013-12-17</th>\n",
              "      <th>2013-12-24</th>\n",
              "      <th>2013-12-31</th>\n",
              "      <th>2014-01-07</th>\n",
              "      <th>2014-01-14</th>\n",
              "      <th>2014-01-21</th>\n",
              "      <th>2014-01-28</th>\n",
              "      <th>2014-02-04</th>\n",
              "      <th>2014-02-11</th>\n",
              "      <th>2014-02-18</th>\n",
              "      <th>2014-02-25</th>\n",
              "      <th>...</th>\n",
              "      <th>2018-05-29</th>\n",
              "      <th>2018-06-05</th>\n",
              "      <th>2018-06-12</th>\n",
              "      <th>2018-06-19</th>\n",
              "      <th>2018-06-26</th>\n",
              "      <th>2018-12-04</th>\n",
              "      <th>2018-12-11</th>\n",
              "      <th>2018-12-18</th>\n",
              "      <th>2018-12-25</th>\n",
              "      <th>2019-01-01</th>\n",
              "      <th>2019-01-08</th>\n",
              "      <th>2019-01-15</th>\n",
              "      <th>2019-01-22</th>\n",
              "      <th>2019-01-29</th>\n",
              "      <th>2019-02-05</th>\n",
              "      <th>2019-02-12</th>\n",
              "      <th>2019-02-19</th>\n",
              "      <th>2019-02-26</th>\n",
              "      <th>2019-03-05</th>\n",
              "      <th>2019-03-12</th>\n",
              "      <th>2019-03-19</th>\n",
              "      <th>2019-03-26</th>\n",
              "      <th>2019-04-02</th>\n",
              "      <th>2019-04-09</th>\n",
              "      <th>2019-04-16</th>\n",
              "      <th>2019-04-23</th>\n",
              "      <th>2019-04-30</th>\n",
              "      <th>2019-05-07</th>\n",
              "      <th>2019-05-14</th>\n",
              "      <th>2019-05-21</th>\n",
              "      <th>2019-05-28</th>\n",
              "      <th>2019-06-04</th>\n",
              "      <th>2019-06-11</th>\n",
              "      <th>2019-06-18</th>\n",
              "      <th>2019-06-25</th>\n",
              "      <th>2019-12-03</th>\n",
              "      <th>2019-12-10</th>\n",
              "      <th>2019-12-17</th>\n",
              "      <th>2019-12-24</th>\n",
              "      <th>2019-12-31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CDEC:ADM</td>\n",
              "      <td>5.90</td>\n",
              "      <td>5.90</td>\n",
              "      <td>6.50</td>\n",
              "      <td>6.50</td>\n",
              "      <td>7.40</td>\n",
              "      <td>7.60</td>\n",
              "      <td>7.40</td>\n",
              "      <td>8.00</td>\n",
              "      <td>8.00</td>\n",
              "      <td>8.00</td>\n",
              "      <td>8.50</td>\n",
              "      <td>6.20</td>\n",
              "      <td>4.10</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1.60</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.50</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.20</td>\n",
              "      <td>2.50</td>\n",
              "      <td>3.10</td>\n",
              "      <td>4.90</td>\n",
              "      <td>4.60</td>\n",
              "      <td>6.30</td>\n",
              "      <td>6.50</td>\n",
              "      <td>10.20</td>\n",
              "      <td>10.90</td>\n",
              "      <td>12.00</td>\n",
              "      <td>14.50</td>\n",
              "      <td>17.00</td>\n",
              "      <td>18.60</td>\n",
              "      <td>20.50</td>\n",
              "      <td>22.60</td>\n",
              "      <td>22.1</td>\n",
              "      <td>21.70</td>\n",
              "      <td>21.30</td>\n",
              "      <td>18.20</td>\n",
              "      <td>15.80</td>\n",
              "      <td>9.80</td>\n",
              "      <td>0.40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.20</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.70</td>\n",
              "      <td>3.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CDEC:AGP</td>\n",
              "      <td>17.52</td>\n",
              "      <td>17.54</td>\n",
              "      <td>17.85</td>\n",
              "      <td>17.39</td>\n",
              "      <td>18.03</td>\n",
              "      <td>17.70</td>\n",
              "      <td>17.65</td>\n",
              "      <td>16.66</td>\n",
              "      <td>17.21</td>\n",
              "      <td>16.26</td>\n",
              "      <td>18.00</td>\n",
              "      <td>18.11</td>\n",
              "      <td>17.96</td>\n",
              "      <td>17.94</td>\n",
              "      <td>11.41</td>\n",
              "      <td>5.39</td>\n",
              "      <td>3.82</td>\n",
              "      <td>3.60</td>\n",
              "      <td>1.06</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1.72</td>\n",
              "      <td>4.16</td>\n",
              "      <td>3.99</td>\n",
              "      <td>3.88</td>\n",
              "      <td>5.70</td>\n",
              "      <td>6.44</td>\n",
              "      <td>7.36</td>\n",
              "      <td>7.24</td>\n",
              "      <td>7.72</td>\n",
              "      <td>8.24</td>\n",
              "      <td>9.49</td>\n",
              "      <td>9.29</td>\n",
              "      <td>8.75</td>\n",
              "      <td>...</td>\n",
              "      <td>1.82</td>\n",
              "      <td>1.98</td>\n",
              "      <td>1.93</td>\n",
              "      <td>1.66</td>\n",
              "      <td>1.56</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CDEC:ALP</td>\n",
              "      <td>12.75</td>\n",
              "      <td>13.32</td>\n",
              "      <td>14.26</td>\n",
              "      <td>14.02</td>\n",
              "      <td>13.39</td>\n",
              "      <td>13.25</td>\n",
              "      <td>14.30</td>\n",
              "      <td>13.95</td>\n",
              "      <td>15.73</td>\n",
              "      <td>15.41</td>\n",
              "      <td>16.99</td>\n",
              "      <td>14.81</td>\n",
              "      <td>15.48</td>\n",
              "      <td>14.85</td>\n",
              "      <td>12.60</td>\n",
              "      <td>8.32</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.46</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.63</td>\n",
              "      <td>1.14</td>\n",
              "      <td>3.18</td>\n",
              "      <td>3.17</td>\n",
              "      <td>3.12</td>\n",
              "      <td>3.09</td>\n",
              "      <td>3.03</td>\n",
              "      <td>3.36</td>\n",
              "      <td>3.03</td>\n",
              "      <td>2.74</td>\n",
              "      <td>2.63</td>\n",
              "      <td>10.87</td>\n",
              "      <td>10.49</td>\n",
              "      <td>10.38</td>\n",
              "      <td>...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7.34</td>\n",
              "      <td>7.56</td>\n",
              "      <td>7.70</td>\n",
              "      <td>9.50</td>\n",
              "      <td>9.87</td>\n",
              "      <td>12.72</td>\n",
              "      <td>13.99</td>\n",
              "      <td>22.74</td>\n",
              "      <td>22.70</td>\n",
              "      <td>30.36</td>\n",
              "      <td>33.76</td>\n",
              "      <td>41.57</td>\n",
              "      <td>44.08</td>\n",
              "      <td>49.38</td>\n",
              "      <td>52.70</td>\n",
              "      <td>52.8</td>\n",
              "      <td>55.08</td>\n",
              "      <td>58.53</td>\n",
              "      <td>59.03</td>\n",
              "      <td>56.72</td>\n",
              "      <td>52.21</td>\n",
              "      <td>44.03</td>\n",
              "      <td>37.23</td>\n",
              "      <td>27.66</td>\n",
              "      <td>28.66</td>\n",
              "      <td>29.52</td>\n",
              "      <td>20.81</td>\n",
              "      <td>8.71</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.69</td>\n",
              "      <td>8.04</td>\n",
              "      <td>10.74</td>\n",
              "      <td>12.67</td>\n",
              "      <td>12.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CDEC:BCB</td>\n",
              "      <td>4.30</td>\n",
              "      <td>4.42</td>\n",
              "      <td>4.62</td>\n",
              "      <td>4.53</td>\n",
              "      <td>4.67</td>\n",
              "      <td>4.90</td>\n",
              "      <td>4.90</td>\n",
              "      <td>5.06</td>\n",
              "      <td>5.11</td>\n",
              "      <td>5.23</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.43</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.50</td>\n",
              "      <td>5.65</td>\n",
              "      <td>5.66</td>\n",
              "      <td>5.80</td>\n",
              "      <td>5.81</td>\n",
              "      <td>5.73</td>\n",
              "      <td>5.62</td>\n",
              "      <td>5.44</td>\n",
              "      <td>5.46</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.78</td>\n",
              "      <td>5.67</td>\n",
              "      <td>5.75</td>\n",
              "      <td>10.49</td>\n",
              "      <td>13.04</td>\n",
              "      <td>13.10</td>\n",
              "      <td>12.82</td>\n",
              "      <td>13.83</td>\n",
              "      <td>14.29</td>\n",
              "      <td>14.02</td>\n",
              "      <td>14.23</td>\n",
              "      <td>13.81</td>\n",
              "      <td>5.18</td>\n",
              "      <td>9.33</td>\n",
              "      <td>9.55</td>\n",
              "      <td>9.12</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CDEC:BCH</td>\n",
              "      <td>2.88</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.48</td>\n",
              "      <td>3.84</td>\n",
              "      <td>3.96</td>\n",
              "      <td>4.44</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.16</td>\n",
              "      <td>3.60</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.48</td>\n",
              "      <td>1.44</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.36</td>\n",
              "      <td>...</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.60</td>\n",
              "      <td>3.12</td>\n",
              "      <td>3.60</td>\n",
              "      <td>3.48</td>\n",
              "      <td>3.48</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.80</td>\n",
              "      <td>4.92</td>\n",
              "      <td>9.00</td>\n",
              "      <td>8.76</td>\n",
              "      <td>11.88</td>\n",
              "      <td>15.36</td>\n",
              "      <td>17.88</td>\n",
              "      <td>18.96</td>\n",
              "      <td>18.96</td>\n",
              "      <td>22.92</td>\n",
              "      <td>22.2</td>\n",
              "      <td>21.24</td>\n",
              "      <td>17.04</td>\n",
              "      <td>10.92</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.88</td>\n",
              "      <td>4.56</td>\n",
              "      <td>4.68</td>\n",
              "      <td>5.04</td>\n",
              "      <td>6.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 214 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53c531ad-c6a4-4d7e-90db-01b1cf64b710')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53c531ad-c6a4-4d7e-90db-01b1cf64b710 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53c531ad-c6a4-4d7e-90db-01b1cf64b710');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Unnamed: 0  2013-01-01  2013-01-08  ...  2019-12-17  2019-12-24  2019-12-31\n",
              "0   CDEC:ADM        5.90        5.90  ...        3.40        3.70        3.40\n",
              "1   CDEC:AGP       17.52       17.54  ...        0.20         NaN         NaN\n",
              "2   CDEC:ALP       12.75       13.32  ...       10.74       12.67       12.57\n",
              "3   CDEC:BCB        4.30        4.42  ...         NaN         NaN         NaN\n",
              "4   CDEC:BCH        2.88        3.00  ...        4.68        5.04        6.00\n",
              "\n",
              "[5 rows x 214 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "trainfeatures.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "l8nO3aAqCzSS",
        "outputId": "3412f482-991a-4374-d1d0-217a8163c6dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-15107d76-1503-4c37-8513-4048a668751c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>station_id</th>\n",
              "      <th>date</th>\n",
              "      <th>SWE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CDEC:ADM</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>5.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CDEC:AGP</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>17.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CDEC:ALP</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>12.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CDEC:BCB</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>4.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CDEC:BCH</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>2.88</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15107d76-1503-4c37-8513-4048a668751c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15107d76-1503-4c37-8513-4048a668751c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15107d76-1503-4c37-8513-4048a668751c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  station_id        date    SWE\n",
              "0   CDEC:ADM  2013-01-01   5.90\n",
              "1   CDEC:AGP  2013-01-01  17.52\n",
              "2   CDEC:ALP  2013-01-01  12.75\n",
              "3   CDEC:BCB  2013-01-01   4.30\n",
              "4   CDEC:BCH  2013-01-01   2.88"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "trainfeatures = trainfeatures.melt(id_vars=['Unnamed: 0']).dropna().reset_index(drop = True)\n",
        "trainfeatures.rename(columns = {'Unnamed: 0':\"station_id\", \"variable\":\"date\", \"value\":\"SWE\"}, inplace = True)\n",
        "trainfeatures.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#These are dates where no stations had information (Discovered after using KNN approach)\n",
        "#Alternative method: Get all dates of cell_id samples, and compare those dates against what each station has for the interpolation\n",
        "nan_dates = ['2013-04-03', '2013-04-29', '2013-05-03', '2013-05-25', '2013-06-01', '2013-06-08', '2016-02-08', '2016-03-26', '2016-04-01', '2016-04-03', '2016-04-04',\n",
        " '2016-04-07', '2016-04-16', '2016-05-09', '2016-05-27', '2016-06-26', '2017-01-28', '2017-01-29', '2018-03-04', '2018-03-30', '2018-03-31', '2018-04-22', '2018-04-23', \n",
        " '2018-04-25', '2018-04-26', '2018-05-24', '2018-05-28', '2018-06-01', '2018-06-02', '2019-03-09', '2019-03-15', '2019-03-16', '2019-03-17', '2019-03-24', '2019-03-25', \n",
        " '2019-03-29', '2019-04-07', '2019-04-08', '2019-04-17', '2019-04-18', '2019-04-19', '2019-04-21', '2019-04-27', '2019-04-28', '2019-05-01', '2019-05-02', '2019-05-03', \n",
        " '2019-06-05', '2019-06-08', '2019-06-09', '2019-06-10', '2019-06-13', '2019-06-14', '2019-06-24']"
      ],
      "metadata": {
        "id": "Idoe0HdCX19m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear regression implementation, filling in based on nan_dates list\n",
        "supplement = []\n",
        "\n",
        "#Iterate through all the unique stations\n",
        "for station in trainfeatures['station_id'].unique(): #['CDEC:SSM']: #\n",
        "  #Get subset for this station\n",
        "  subset = trainfeatures[trainfeatures['station_id']==station].copy()\n",
        "  #make filler rows with missing dates\n",
        "  filler = [[station,date,np.nan] for date in nan_dates]\n",
        "  #Append filler rows to subset and sort on date and reset index\n",
        "  subset = subset.append(pd.DataFrame(filler, columns=['station_id','date','SWE'])).sort_values(by='date').reset_index(drop=True)\n",
        "  #print(station,len(subset.index))\n",
        "  #print(subset.head())\n",
        "  for date in nan_dates:\n",
        "    #Find NaN date\n",
        "    nan_index = subset.index[subset['date'] == date].tolist()[0]\n",
        "    nan_date = datetime.strptime(date,'%Y-%m-%d')\n",
        "    \n",
        "    #There is a conditional needed for stations that stopped reporting before 2019\n",
        "    try:\n",
        "      count=0\n",
        "      #Find older date that HAS value. Sometimes needed because filler inserted NaNs\n",
        "      while subset.iloc[nan_index-1-count].isnull().any():\n",
        "        count+=1\n",
        "      #Older date (nan-1)\n",
        "      if (nan_index-1-count)>=0:\n",
        "        older_date = datetime.strptime(subset.iloc[nan_index-1-count]['date'],'%Y-%m-%d')\n",
        "        older_swe = subset.iloc[nan_index-1-count]['SWE']\n",
        "      else:\n",
        "        older_date = datetime.strptime(subset.iloc[nan_index-1]['date'],'%Y-%m-%d')\n",
        "        older_swe = np.nan\n",
        "      #print('Older',nan_index-1,older_date,older_swe)\n",
        "      #print('NaN-inserted',nan_index,nan_date)\n",
        "\n",
        "      #Newer date is next date that HAS value, otherwise enter except\n",
        "      counter=0\n",
        "      while subset.iloc[nan_index+1+counter].isnull().any():\n",
        "        counter+=1\n",
        "      #Newer date\n",
        "      newer_date = datetime.strptime(subset.iloc[nan_index+1+counter]['date'],'%Y-%m-%d')\n",
        "      newer_swe = subset.iloc[nan_index+1+counter]['SWE']\n",
        "      #print('newer',nan_index+1+counter,newer_date,newer_swe)\n",
        "      #print('______________________________')\n",
        "\n",
        "      #Change per day\n",
        "      delta_day = (newer_swe-older_swe)/(newer_date-older_date).days\n",
        "\n",
        "      #Add expected change to older swe\n",
        "      est_swe = older_swe + (delta_day*(nan_date-older_date).days)\n",
        "\n",
        "      #Add \"entry\" row to supplement\n",
        "      supplement.append([station,date,est_swe])\n",
        "    #IndexError happens when the last date is actually from the nan list. Because of this, We DEFINITELY need to do some inter-station interpolation\n",
        "    except IndexError:\n",
        "      supplement.append([station,date,np.nan])\n",
        "\n",
        "#Problem with simple linear interpolation: There are large enough gaps that the \"missing days\" in the data sometimes are the closest dates to themselves"
      ],
      "metadata": {
        "id": "20uFlk86YCcx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add incomplete supplement (testing to see how many knn nans are filled in)\n",
        "trainfeatures = trainfeatures.append(pd.DataFrame(supplement, columns=['station_id','date','SWE'])).sort_values(by='date').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "u8_40htVYjCc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "j2_EMS6rFL5k",
        "outputId": "f11a7c92-7a61-4d2c-ccc8-950ca3eee26e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cce6c0c0-6ec5-4c96-a671-4c9f68ea0bec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>station_id</th>\n",
              "      <th>name</th>\n",
              "      <th>elevation_m</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CDEC:ADM</td>\n",
              "      <td>Adin Mountain</td>\n",
              "      <td>1889.76</td>\n",
              "      <td>41.237000</td>\n",
              "      <td>-120.792000</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CDEC:AGP</td>\n",
              "      <td>Agnew Pass</td>\n",
              "      <td>2880.36</td>\n",
              "      <td>37.726631</td>\n",
              "      <td>-119.141731</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CDEC:ALP</td>\n",
              "      <td>Alpha (Smud)</td>\n",
              "      <td>2316.48</td>\n",
              "      <td>38.804192</td>\n",
              "      <td>-120.215652</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CDEC:BCB</td>\n",
              "      <td>Blackcap Basin</td>\n",
              "      <td>3139.44</td>\n",
              "      <td>37.066685</td>\n",
              "      <td>-118.773010</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CDEC:BCH</td>\n",
              "      <td>Beach Meadows</td>\n",
              "      <td>2331.72</td>\n",
              "      <td>36.126095</td>\n",
              "      <td>-118.293457</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cce6c0c0-6ec5-4c96-a671-4c9f68ea0bec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cce6c0c0-6ec5-4c96-a671-4c9f68ea0bec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cce6c0c0-6ec5-4c96-a671-4c9f68ea0bec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  station_id            name  elevation_m   latitude   longitude       state\n",
              "0   CDEC:ADM   Adin Mountain      1889.76  41.237000 -120.792000  California\n",
              "1   CDEC:AGP      Agnew Pass      2880.36  37.726631 -119.141731  California\n",
              "2   CDEC:ALP    Alpha (Smud)      2316.48  38.804192 -120.215652  California\n",
              "3   CDEC:BCB  Blackcap Basin      3139.44  37.066685 -118.773010  California\n",
              "4   CDEC:BCH   Beach Meadows      2331.72  36.126095 -118.293457  California"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "trainmeta = pd.read_csv(\"/content/drive/MyDrive/snowcapstone team spring 2022/Competition_Data/ground_measures_metadata.csv\")\n",
        "trainmeta.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MoHOpJocFcCd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2802af16-1aff-4763-81ac-72f0d7c07dd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7596e2e8-fa37-4a38-8906-8d3eef47bf4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>station_id</th>\n",
              "      <th>date</th>\n",
              "      <th>SWE</th>\n",
              "      <th>name</th>\n",
              "      <th>elevation_m</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CDEC:ADM</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>5.9</td>\n",
              "      <td>Adin Mountain</td>\n",
              "      <td>1889.760000</td>\n",
              "      <td>41.237000</td>\n",
              "      <td>-120.792000</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SNOTEL:628_UT_SNTL</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>9.8</td>\n",
              "      <td>Mill-D North</td>\n",
              "      <td>2731.922363</td>\n",
              "      <td>40.658829</td>\n",
              "      <td>-111.636833</td>\n",
              "      <td>Utah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SNOTEL:629_CO_SNTL</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>3.6</td>\n",
              "      <td>Mineral Creek</td>\n",
              "      <td>3060.191895</td>\n",
              "      <td>37.847469</td>\n",
              "      <td>-107.726570</td>\n",
              "      <td>Colorado</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SNOTEL:633_CA_SNTL</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>9.4</td>\n",
              "      <td>Monitor Pass</td>\n",
              "      <td>2531.668701</td>\n",
              "      <td>38.668301</td>\n",
              "      <td>-119.608704</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SNOTEL:637_ID_SNTL</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>6.9</td>\n",
              "      <td>Mores Creek Summit</td>\n",
              "      <td>1859.280029</td>\n",
              "      <td>43.931999</td>\n",
              "      <td>-115.665878</td>\n",
              "      <td>Idaho</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7596e2e8-fa37-4a38-8906-8d3eef47bf4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7596e2e8-fa37-4a38-8906-8d3eef47bf4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7596e2e8-fa37-4a38-8906-8d3eef47bf4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           station_id        date  SWE  ...   latitude   longitude       state\n",
              "0            CDEC:ADM  2013-01-01  5.9  ...  41.237000 -120.792000  California\n",
              "1  SNOTEL:628_UT_SNTL  2013-01-01  9.8  ...  40.658829 -111.636833        Utah\n",
              "2  SNOTEL:629_CO_SNTL  2013-01-01  3.6  ...  37.847469 -107.726570    Colorado\n",
              "3  SNOTEL:633_CA_SNTL  2013-01-01  9.4  ...  38.668301 -119.608704  California\n",
              "4  SNOTEL:637_ID_SNTL  2013-01-01  6.9  ...  43.931999 -115.665878       Idaho\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "trainfeatures = trainfeatures.merge(trainmeta, how = 'left', on='station_id')\n",
        "trainfeatures.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrRzKQu9G8pL",
        "outputId": "469acb76-5478-4ac6-b773-466023ae74f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                cell_id  ...                                           geometry\n",
            "0  0003f387-71c4-48f6-b2b0-d853bd4f0aba  ...  POLYGON ((-118.71895 37.07419, -118.71895 37.0...\n",
            "1  000617d8-8c14-43e2-b708-7e3a69fe3cc3  ...  POLYGON ((-107.07679 37.78042, -107.07679 37.7...\n",
            "2  000863e7-21e6-477d-b799-f5675c348627  ...  POLYGON ((-119.40167 37.02400, -119.40167 37.0...\n",
            "3  000ba8d9-d6d5-48da-84a2-1fa54951fae1  ...  POLYGON ((-119.32082 37.43171, -119.32082 37.4...\n",
            "4  00146204-d4e9-4cd8-8f86-d1ef133c5b6d  ...  POLYGON ((-118.52132 36.65735, -118.52132 36.6...\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "gridcells = gpd.read_file('/content/drive/MyDrive/snowcapstone team spring 2022/Competition_Data/grid_cells.geojson')\n",
        "print(gridcells.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "QBFn6NWaOnlu",
        "outputId": "b608492c-046e-400b-dedf-9a2f840635f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-35c6b4aa-70f8-4845-b8b1-b0db1c6fd38e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell_id</th>\n",
              "      <th>date</th>\n",
              "      <th>SWE</th>\n",
              "      <th>region</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00c4db22-a423-41a4-ada6-a8b1b04153a4</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>12.7</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-121.93492 41.16327, -121.93492 41.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>018cf1a1-f945-4097-9c47-0c4690538bb5</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>20.4</td>\n",
              "      <td>sierras</td>\n",
              "      <td>POLYGON ((-120.61440 39.67242, -120.61440 39.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01be2cc7-ef77-4e4d-80ed-c4f8139162c3</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>37.0</td>\n",
              "      <td>sierras</td>\n",
              "      <td>POLYGON ((-119.60829 38.27575, -119.60829 38.2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>02c3ec4a-8de4-4284-9ec1-5a942d3d098e</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>2.3</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-107.19357 44.57879, -107.19357 44.5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>02cf33c2-c8e2-48b9-bf72-92506e97e251</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>8.0</td>\n",
              "      <td>central rockies</td>\n",
              "      <td>POLYGON ((-106.60068 40.39461, -106.60068 40.4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91485</th>\n",
              "      <td>fd4492f2-8aa9-4279-bdc0-73991786943f</td>\n",
              "      <td>2019-12-31</td>\n",
              "      <td>1.3</td>\n",
              "      <td>central rockies</td>\n",
              "      <td>POLYGON ((-105.07354 38.87270, -105.07354 38.8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91486</th>\n",
              "      <td>fde3221a-9ce3-45a9-857f-bd196b07aa05</td>\n",
              "      <td>2019-12-31</td>\n",
              "      <td>5.6</td>\n",
              "      <td>central rockies</td>\n",
              "      <td>POLYGON ((-106.10661 39.29804, -106.10661 39.3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91487</th>\n",
              "      <td>fdeb8912-f9d1-445d-aadb-e943534f67fe</td>\n",
              "      <td>2019-12-31</td>\n",
              "      <td>8.8</td>\n",
              "      <td>central rockies</td>\n",
              "      <td>POLYGON ((-107.92120 37.79462, -107.92120 37.8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91488</th>\n",
              "      <td>fe33672e-7ea7-4c5d-8639-96b2cc7edb0c</td>\n",
              "      <td>2019-12-31</td>\n",
              "      <td>2.9</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-122.02475 43.89659, -122.02475 43.9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91489</th>\n",
              "      <td>ff01e8c2-19a2-4a89-af0e-608b8f40ad5f</td>\n",
              "      <td>2019-12-31</td>\n",
              "      <td>4.7</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-111.37972 44.41861, -111.37972 44.4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91490 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35c6b4aa-70f8-4845-b8b1-b0db1c6fd38e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35c6b4aa-70f8-4845-b8b1-b0db1c6fd38e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35c6b4aa-70f8-4845-b8b1-b0db1c6fd38e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    cell_id  ...                                           geometry\n",
              "0      00c4db22-a423-41a4-ada6-a8b1b04153a4  ...  POLYGON ((-121.93492 41.16327, -121.93492 41.1...\n",
              "1      018cf1a1-f945-4097-9c47-0c4690538bb5  ...  POLYGON ((-120.61440 39.67242, -120.61440 39.6...\n",
              "2      01be2cc7-ef77-4e4d-80ed-c4f8139162c3  ...  POLYGON ((-119.60829 38.27575, -119.60829 38.2...\n",
              "3      02c3ec4a-8de4-4284-9ec1-5a942d3d098e  ...  POLYGON ((-107.19357 44.57879, -107.19357 44.5...\n",
              "4      02cf33c2-c8e2-48b9-bf72-92506e97e251  ...  POLYGON ((-106.60068 40.39461, -106.60068 40.4...\n",
              "...                                     ...  ...                                                ...\n",
              "91485  fd4492f2-8aa9-4279-bdc0-73991786943f  ...  POLYGON ((-105.07354 38.87270, -105.07354 38.8...\n",
              "91486  fde3221a-9ce3-45a9-857f-bd196b07aa05  ...  POLYGON ((-106.10661 39.29804, -106.10661 39.3...\n",
              "91487  fdeb8912-f9d1-445d-aadb-e943534f67fe  ...  POLYGON ((-107.92120 37.79462, -107.92120 37.8...\n",
              "91488  fe33672e-7ea7-4c5d-8639-96b2cc7edb0c  ...  POLYGON ((-122.02475 43.89659, -122.02475 43.9...\n",
              "91489  ff01e8c2-19a2-4a89-af0e-608b8f40ad5f  ...  POLYGON ((-111.37972 44.41861, -111.37972 44.4...\n",
              "\n",
              "[91490 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "traindf = pd.read_csv(\"/content/drive/MyDrive/snowcapstone team spring 2022/Competition_Data/train_labels.csv\")\n",
        "\n",
        "traindf = traindf.melt(id_vars=[\"cell_id\"]).dropna().reset_index(drop = True)\n",
        "traindf.rename(columns = {\"cell_id\":\"cell_id\", \"variable\":\"date\", \"value\":\"SWE\"}, inplace = True)\n",
        "\n",
        "traindf = traindf.merge(gridcells, how = 'left', on='cell_id')\n",
        "\n",
        "\n",
        "traindf = gpd.GeoDataFrame(traindf, crs =\"EPSG:4326\")\n",
        "traindf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "print(len(traindf.loc[pd.to_datetime(traindf.date) > datetime.strptime(\"2016-01-01\", \"%Y-%m-%d\"), \"region\"]))\n",
        "print(len(traindf.loc[traindf[\"region\"] == \"sierras\", \"region\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKxVUMLeMgiS",
        "outputId": "23e90f0d-24f7-458b-971b-ddcc2edbed6c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68670\n",
            "37017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "kX-A4GznjM1D",
        "outputId": "5f9e76a5-40e4-487d-d0fa-1a602ab80a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91490\n",
            "500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3c88c6e1-f350-4b2f-adc5-d60ff13207e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell_id</th>\n",
              "      <th>date</th>\n",
              "      <th>SWE</th>\n",
              "      <th>region</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00c4db22-a423-41a4-ada6-a8b1b04153a4</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>10.6</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-121.93492 41.16327, -121.93492 41.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>018cf1a1-f945-4097-9c47-0c4690538bb5</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>16.4</td>\n",
              "      <td>sierras</td>\n",
              "      <td>POLYGON ((-120.61440 39.67242, -120.61440 39.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01be2cc7-ef77-4e4d-80ed-c4f8139162c3</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>21.1</td>\n",
              "      <td>sierras</td>\n",
              "      <td>POLYGON ((-119.60829 38.27575, -119.60829 38.2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>02c3ec4a-8de4-4284-9ec1-5a942d3d098e</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>2.0</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-107.19357 44.57879, -107.19357 44.5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>02cf33c2-c8e2-48b9-bf72-92506e97e251</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>9.2</td>\n",
              "      <td>central rockies</td>\n",
              "      <td>POLYGON ((-106.60068 40.39461, -106.60068 40.4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c88c6e1-f350-4b2f-adc5-d60ff13207e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c88c6e1-f350-4b2f-adc5-d60ff13207e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c88c6e1-f350-4b2f-adc5-d60ff13207e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                cell_id  ...                                           geometry\n",
              "0  00c4db22-a423-41a4-ada6-a8b1b04153a4  ...  POLYGON ((-121.93492 41.16327, -121.93492 41.1...\n",
              "1  018cf1a1-f945-4097-9c47-0c4690538bb5  ...  POLYGON ((-120.61440 39.67242, -120.61440 39.6...\n",
              "2  01be2cc7-ef77-4e4d-80ed-c4f8139162c3  ...  POLYGON ((-119.60829 38.27575, -119.60829 38.2...\n",
              "3  02c3ec4a-8de4-4284-9ec1-5a942d3d098e  ...  POLYGON ((-107.19357 44.57879, -107.19357 44.5...\n",
              "4  02cf33c2-c8e2-48b9-bf72-92506e97e251  ...  POLYGON ((-106.60068 40.39461, -106.60068 40.4...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "print(len(traindf))\n",
        "traindf = traindf.loc[pd.to_datetime(traindf.date) >= datetime.strptime(\"2016-01-01\", \"%Y-%m-%d\")].reset_index(drop = True).iloc[0:500]\n",
        "print(len(traindf[\"region\"]))\n",
        "traindf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "4-HHxU28O1j1",
        "outputId": "7ef360f1-78fc-4018-aa8a-89a932c91310"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b8b8b375-352f-400e-8233-80f93355388a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>station_id</th>\n",
              "      <th>name</th>\n",
              "      <th>elevation_m</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>state</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CDEC:ADM</td>\n",
              "      <td>Adin Mountain</td>\n",
              "      <td>1889.760000</td>\n",
              "      <td>41.237000</td>\n",
              "      <td>-120.792000</td>\n",
              "      <td>California</td>\n",
              "      <td>POINT (-120.79200 41.23700)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CDEC:AGP</td>\n",
              "      <td>Agnew Pass</td>\n",
              "      <td>2880.360000</td>\n",
              "      <td>37.726631</td>\n",
              "      <td>-119.141731</td>\n",
              "      <td>California</td>\n",
              "      <td>POINT (-119.14173 37.72663)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CDEC:ALP</td>\n",
              "      <td>Alpha (Smud)</td>\n",
              "      <td>2316.480000</td>\n",
              "      <td>38.804192</td>\n",
              "      <td>-120.215652</td>\n",
              "      <td>California</td>\n",
              "      <td>POINT (-120.21565 38.80419)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CDEC:BCB</td>\n",
              "      <td>Blackcap Basin</td>\n",
              "      <td>3139.440000</td>\n",
              "      <td>37.066685</td>\n",
              "      <td>-118.773010</td>\n",
              "      <td>California</td>\n",
              "      <td>POINT (-118.77301 37.06668)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CDEC:BCH</td>\n",
              "      <td>Beach Meadows</td>\n",
              "      <td>2331.720000</td>\n",
              "      <td>36.126095</td>\n",
              "      <td>-118.293457</td>\n",
              "      <td>California</td>\n",
              "      <td>POINT (-118.29346 36.12609)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>SNOTEL:989_ID_SNTL</td>\n",
              "      <td>Moscow Mountain</td>\n",
              "      <td>1432.560059</td>\n",
              "      <td>46.805000</td>\n",
              "      <td>-116.853500</td>\n",
              "      <td>Idaho</td>\n",
              "      <td>POINT (-116.85350 46.80500)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>SNOTEL:990_WA_SNTL</td>\n",
              "      <td>Beaver Pass</td>\n",
              "      <td>1106.423950</td>\n",
              "      <td>48.879299</td>\n",
              "      <td>-121.255501</td>\n",
              "      <td>Washington</td>\n",
              "      <td>POINT (-121.25550 48.87930)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>SNOTEL:992_UT_SNTL</td>\n",
              "      <td>Bear River RS</td>\n",
              "      <td>2675.229492</td>\n",
              "      <td>40.885201</td>\n",
              "      <td>-110.827698</td>\n",
              "      <td>Utah</td>\n",
              "      <td>POINT (-110.82770 40.88520)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>SNOTEL:998_WA_SNTL</td>\n",
              "      <td>Easy Pass</td>\n",
              "      <td>1606.296021</td>\n",
              "      <td>48.859329</td>\n",
              "      <td>-121.438950</td>\n",
              "      <td>Washington</td>\n",
              "      <td>POINT (-121.43895 48.85933)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>699</th>\n",
              "      <td>SNOTEL:999_WA_SNTL</td>\n",
              "      <td>Marten Ridge</td>\n",
              "      <td>1072.895996</td>\n",
              "      <td>48.762920</td>\n",
              "      <td>-121.698227</td>\n",
              "      <td>Washington</td>\n",
              "      <td>POINT (-121.69823 48.76292)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>700 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8b8b375-352f-400e-8233-80f93355388a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8b8b375-352f-400e-8233-80f93355388a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8b8b375-352f-400e-8233-80f93355388a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             station_id  ...                     geometry\n",
              "0              CDEC:ADM  ...  POINT (-120.79200 41.23700)\n",
              "1              CDEC:AGP  ...  POINT (-119.14173 37.72663)\n",
              "2              CDEC:ALP  ...  POINT (-120.21565 38.80419)\n",
              "3              CDEC:BCB  ...  POINT (-118.77301 37.06668)\n",
              "4              CDEC:BCH  ...  POINT (-118.29346 36.12609)\n",
              "..                  ...  ...                          ...\n",
              "695  SNOTEL:989_ID_SNTL  ...  POINT (-116.85350 46.80500)\n",
              "696  SNOTEL:990_WA_SNTL  ...  POINT (-121.25550 48.87930)\n",
              "697  SNOTEL:992_UT_SNTL  ...  POINT (-110.82770 40.88520)\n",
              "698  SNOTEL:998_WA_SNTL  ...  POINT (-121.43895 48.85933)\n",
              "699  SNOTEL:999_WA_SNTL  ...  POINT (-121.69823 48.76292)\n",
              "\n",
              "[700 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "gdf = gpd.GeoDataFrame(trainmeta, \n",
        "                       geometry = gpd.points_from_xy(trainmeta.longitude, trainmeta.latitude),\n",
        "                       crs = \"EPSG:4326\")\n",
        "\n",
        "gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZxpooIsbdNFY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#fig, ax = plt.subplots(figsize = (240,240))\n",
        "#\n",
        "#states = gpd.read_file('/content/drive/MyDrive/snowcapstone team spring 2022/Competition_Data/USMap/cb_2018_us_state_20m.shp')\n",
        "#states = states.to_crs(\"EPSG:4326\")\n",
        "#states = states[states['STUSPS'].isin(['WA', 'OR', 'CA', 'NV', 'MT', 'ID', 'WY', 'NM', 'CO' ,'UT', 'AZ'])]\n",
        "#statemap = states.boundary.plot(ax=ax, linewidth=5, zorder = 1)\n",
        "#\n",
        "#gpd.GeoDataFrame(traindf[\"geometry\"]).to_crs(states.crs).plot(ax=ax, facecolor=\"none\", edgecolor='grey')\n",
        "#\n",
        "#gdf[\"geometry\"].plot(ax = ax, markersize = 200, color = 'red',marker = '*', zorder = 2)\n",
        "#\n",
        "#plt.autoscale(False)\n",
        "#ax.axis(\"off\")\n",
        "#\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM2V6oLfIRBk"
      },
      "source": [
        "# Adding Station Data\n",
        "\n",
        "In this section we will take the measurements of ground stations and add those as features to our data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainfeatures = trainfeatures[['station_id',\t'date',\t'SWE',\t'name']]"
      ],
      "metadata": {
        "id": "ieW9vdPnTcGA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Balltree/KNN approach"
      ],
      "metadata": {
        "id": "C-2zyvRcpeip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import BallTree\n",
        "\n",
        "#Adapted from AutoGIS| University of Helsinki\n",
        "# https://automating-gis-processes.github.io/site/notebooks/L3/nearest-neighbor-faster.html\n",
        "def get_knearest(src_points, candidates, knn=1):\n",
        "  '''\n",
        "  K nearest neighbors for every source point given candidate points\n",
        "  '''\n",
        "  #Make candidates BallTree format\n",
        "  tree = BallTree(candidates,leaf_size=15,metric='haversine')\n",
        "\n",
        "  #Find closest points\n",
        "  distances, indices = tree.query(src_points, k=knn)\n",
        "\n",
        "  #Transpose into arrays\n",
        "  distances = distances.transpose()\n",
        "  indices = indices.transpose()\n",
        "\n",
        "  #neighbor_idx = []\n",
        "  #neighbor_dist = []\n",
        "   \n",
        "  return(indices, distances)\n",
        "  #Iterate for k neighbors\n",
        "  #for i in range(knn):\n",
        "  #  neighbor_idx.append(indices[i])\n",
        "  #  neighbor_dist.append(distances[i])\n",
        "  #Return list of lists in order of KNN\n",
        "  #return(neighbor_idx,neighbor_dist)\n",
        "\n",
        "\n",
        "\n",
        "  return distances,indices\n",
        "\n",
        "def nearest_neighbor(left_gdf, right_gdf, return_dist=False, knn=1):\n",
        "  \"\"\"\n",
        "  For each point in left_gdf, find closest point in right GeoDataFrame and return them.\n",
        "\n",
        "  NOTICE: Assumes that the input Points are in WGS84 projection (lat/lon).\n",
        "  \"\"\"\n",
        "  #Some Nan buffer to KNN search\n",
        "  knn = knn*3\n",
        "\n",
        "  left_geom_col = left_gdf.geometry.name\n",
        "  right_geom_col = right_gdf.geometry.name\n",
        "\n",
        "  # Ensure that index in right gdf is formed of sequential numbers\n",
        "  right = right_gdf.copy().reset_index(drop=True)\n",
        "\n",
        "  # Parse coordinates from points and insert them into a numpy array as RADIANS\n",
        "  # For left radians, data is in polygon format, so apply meter crs, get centroid, and revert\n",
        "  left_radians = np.array(left_gdf[left_geom_col].to_crs('epsg:4087').centroid.to_crs(\"EPSG:4326\").apply(lambda geom: (geom.x * np.pi / 180, geom.y * np.pi / 180)).to_list())\n",
        "  right_radians = np.array(right[right_geom_col].apply(lambda geom: (geom.x * np.pi / 180, geom.y * np.pi / 180)).to_list())\n",
        "\n",
        "\n",
        "  # Find the nearest points\n",
        "  # -----------------------\n",
        "  # closest ==> index in right_gdf that corresponds to the closest point\n",
        "  # dist ==> distance between the nearest neighbors (in meters)\n",
        "\n",
        "  closest, dist = get_knearest(src_points=left_radians, candidates=right_radians, knn=knn)\n",
        "\n",
        "  #return(closest,dist)\n",
        "    \n",
        "  closest_points = gpd.GeoDataFrame()\n",
        "    \n",
        "  #Loop for knn\n",
        "  for i in range(knn):\n",
        "    # Return points from right GeoDataFrame that are closest to points in left GeoDataFrame\n",
        "    #Loop to return closest starting from 0 idx\n",
        "    closest_points['station_id_'+str(i)] = right['station_id'].loc[closest[i]].values\n",
        "    closest_points['elevation_m_'+str(i)] = right['elevation_m'].loc[closest[i]].values\n",
        "\n",
        "    # Add distance if requested\n",
        "    if return_dist:\n",
        "      # Convert to meters from radians\n",
        "      earth_radius = 6371000  # meters\n",
        "      closest_points['distance_'+str(i)] = dist[i] * earth_radius\n",
        "\n",
        "  return closest_points\n",
        "\n",
        "def inverseDmean(df,power):\n",
        "  #Formula for inverse Distance Average = ((x1/d1^p)+(x2/d2^p)....)/((1/d1^p)+(1/d2^p)....)\n",
        "  #https://gisgeography.com/inverse-distance-weighting-idw-interpolation/\n",
        "  subset = df.filter(regex='distance_[0-9]+|SWE_[0-9]+')\n",
        "  numerator = pd.DataFrame()\n",
        "  denominator = pd.DataFrame()\n",
        "\n",
        "  for i in range(int(subset.shape[1]/2)):\n",
        "    numerator['x_'+str(i)]=subset['SWE_'+str(i)]/(subset['distance_'+str(i)]**power)\n",
        "    denominator['x_'+str(i)]=1/(subset['distance_'+str(i)]**power)\n",
        "\n",
        "  #There are cells without SWE data. We do not want this in the inverse Distance Calculation\n",
        "  nulls = np.where(pd.isnull(numerator))\n",
        "  for row,column in zip(nulls[0],nulls[1]):\n",
        "    denominator.at[row, denominator.columns[column]] = np.nan\n",
        "  \n",
        "  numerator['sum']=numerator.sum(axis=1)\n",
        "  #print(numerator.head())\n",
        "  denominator['sum']=denominator.sum(axis=1)\n",
        "  #print(denominator.head())\n",
        "\n",
        "  return(numerator['sum']/denominator['sum'])\n",
        "\n",
        "def swe_calculation(train, labels, closest_stations, knn=1):\n",
        "  #Join labels with closest_stations\n",
        "  labels_joined = labels.join(closest_stations)\n",
        "\n",
        "  #Prepare column names\n",
        "  SWE_names=[]\n",
        "  elevation_names=[]\n",
        "  reordered_columns = ['cell_id', 'date', 'SWE', 'region', 'geometry',\n",
        "                       'mean_inversed_swe', 'mean_local_swe',\t'median_local_swe',\t'max_local_swe', 'min_local_swe',\n",
        "                       'mean_local_elevation',\t'median_local_elevation',\t'max_local_elevation','min_local_elevation']\n",
        "  for i in range(knn):\n",
        "    reordered_columns.extend(['station_id_'+str(i),'elevation_m_'+str(i),'distance_'+str(i),'SWE_'+str(i)])\n",
        "    SWE_names.append('SWE_'+str(i))\n",
        "    elevation_names.append('elevation_m_'+str(i))\n",
        "  \n",
        "  #Merge against cell_id+date to get closest stations for each cell\n",
        "  idx = 0\n",
        "  for i in range(knn*3):\n",
        "    train\n",
        "    if i == 0:\n",
        "      tmp_merged = pd.merge(labels_joined, train, how=\"left\", left_on=['station_id_'+str(i), 'date'], right_on=['station_id','date'],suffixes=(None,'_'+str(i))).drop(columns= ['station_id'])\n",
        "    else:\n",
        "      tmp_merged = pd.merge(tmp_merged, train, how=\"left\", left_on=['station_id_'+str(i), 'date'], right_on=['station_id','date'],suffixes=(None,'_'+str(i))).drop(columns= ['station_id'])\n",
        "\n",
        "  #Filter out nearest neighbors with NaN, get 5 closest WITH VALUES\n",
        "  filtered = []\n",
        "  for idx,row in tmp_merged.iterrows():\n",
        "    index = []\n",
        "    values = []\n",
        "    i=0\n",
        "    counter=0\n",
        "    while i<knn:\n",
        "      if not pd.isna(row['SWE_'+str(counter)]):\n",
        "        i+=1\n",
        "        index.append(counter)\n",
        "      counter+=1\n",
        "    for j in index:\n",
        "      values.extend([row['station_id_'+str(j)], row['elevation_m_'+str(j)], row['distance_'+str(j)], row['SWE_'+str(j)]])\n",
        "    filtered.append(values)\n",
        "\n",
        "  #Re-merge with cell data\n",
        "  merged_train = labels.join(pd.DataFrame(filtered,columns=reordered_columns[-4*knn:]))\n",
        "\n",
        "  #Calculations\n",
        "  #Elevations\n",
        "  # Normal Mean\n",
        "  merged_train['mean_local_elevation']=merged_train[elevation_names].mean(axis=1)\n",
        "  # Median\n",
        "  merged_train['median_local_elevation']=merged_train[elevation_names].median(axis=1)\n",
        "  # Max\n",
        "  merged_train['max_local_elevation']=merged_train[elevation_names].max(axis=1)\n",
        "  # Min\n",
        "  merged_train['min_local_elevation']=merged_train[elevation_names].min(axis=1)\n",
        "\n",
        "  #SWE\n",
        "  #Inverse Distance Mean\n",
        "  merged_train['mean_inversed_swe']=inverseDmean(merged_train,2)\n",
        "  #Normal Mean\n",
        "  merged_train['mean_local_swe']=merged_train[SWE_names].mean(axis=1)\n",
        "  #Median\n",
        "  merged_train['median_local_swe']=merged_train[SWE_names].median(axis=1)\n",
        "  #Min\n",
        "  merged_train['min_local_swe']=merged_train[SWE_names].min(axis=1)\n",
        "  #Max\n",
        "  merged_train['max_local_swe']=merged_train[SWE_names].max(axis=1)\n",
        "\n",
        "  #Reorder Columns\n",
        "  merged_train=merged_train[reordered_columns]\n",
        "\n",
        "  return(merged_train)"
      ],
      "metadata": {
        "id": "-RusgZofpduJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn=5\n",
        "#DO NOT want traindf.date or trainfeatures in datetime format\n",
        "\n",
        "closest_stations = nearest_neighbor(traindf, gdf, return_dist=True,knn=knn)\n",
        "traindf = swe_calculation(train=trainfeatures, labels=traindf, closest_stations=closest_stations, knn=knn)"
      ],
      "metadata": {
        "id": "LH4_ggwkrja0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindf.sample(frac = .1).head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "mEob6VOmvsnd",
        "outputId": "2de59759-fc67-45ef-c20c-91ffd93e1244"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-668c6b10-b557-49b6-945a-bebbba19200b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell_id</th>\n",
              "      <th>date</th>\n",
              "      <th>SWE</th>\n",
              "      <th>region</th>\n",
              "      <th>geometry</th>\n",
              "      <th>mean_inversed_swe</th>\n",
              "      <th>mean_local_swe</th>\n",
              "      <th>median_local_swe</th>\n",
              "      <th>max_local_swe</th>\n",
              "      <th>min_local_swe</th>\n",
              "      <th>mean_local_elevation</th>\n",
              "      <th>median_local_elevation</th>\n",
              "      <th>max_local_elevation</th>\n",
              "      <th>min_local_elevation</th>\n",
              "      <th>station_id_0</th>\n",
              "      <th>elevation_m_0</th>\n",
              "      <th>distance_0</th>\n",
              "      <th>SWE_0</th>\n",
              "      <th>station_id_1</th>\n",
              "      <th>elevation_m_1</th>\n",
              "      <th>distance_1</th>\n",
              "      <th>SWE_1</th>\n",
              "      <th>station_id_2</th>\n",
              "      <th>elevation_m_2</th>\n",
              "      <th>distance_2</th>\n",
              "      <th>SWE_2</th>\n",
              "      <th>station_id_3</th>\n",
              "      <th>elevation_m_3</th>\n",
              "      <th>distance_3</th>\n",
              "      <th>SWE_3</th>\n",
              "      <th>station_id_4</th>\n",
              "      <th>elevation_m_4</th>\n",
              "      <th>distance_4</th>\n",
              "      <th>SWE_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>cdfc27f0-b990-45f7-bac6-7c674cd157ac</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>14.8</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-121.92594 46.17510, -121.92594 46.1...</td>\n",
              "      <td>12.971607</td>\n",
              "      <td>17.82</td>\n",
              "      <td>19.10</td>\n",
              "      <td>25.20</td>\n",
              "      <td>6.10</td>\n",
              "      <td>1111.910400</td>\n",
              "      <td>1197.864014</td>\n",
              "      <td>1353.312012</td>\n",
              "      <td>652.271973</td>\n",
              "      <td>SNOTEL:1104_WA_SNTL</td>\n",
              "      <td>652.271973</td>\n",
              "      <td>5261.324716</td>\n",
              "      <td>6.10</td>\n",
              "      <td>SNOTEL:591_WA_SNTL</td>\n",
              "      <td>1197.864014</td>\n",
              "      <td>6565.533205</td>\n",
              "      <td>19.10</td>\n",
              "      <td>SNOTEL:1263_WA_SNTL</td>\n",
              "      <td>1353.312012</td>\n",
              "      <td>8626.967743</td>\n",
              "      <td>17.40</td>\n",
              "      <td>SNOTEL:804_WA_SNTL</td>\n",
              "      <td>1307.592041</td>\n",
              "      <td>19198.823688</td>\n",
              "      <td>25.20</td>\n",
              "      <td>SNOTEL:553_WA_SNTL</td>\n",
              "      <td>1048.511963</td>\n",
              "      <td>24938.841865</td>\n",
              "      <td>21.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>06ec1554-a0ea-41cf-85f8-43f4b48c7599</td>\n",
              "      <td>2016-01-19</td>\n",
              "      <td>13.1</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-121.07254 46.35519, -121.07254 46.3...</td>\n",
              "      <td>17.071266</td>\n",
              "      <td>16.46</td>\n",
              "      <td>18.60</td>\n",
              "      <td>20.70</td>\n",
              "      <td>8.40</td>\n",
              "      <td>1394.764819</td>\n",
              "      <td>1374.647949</td>\n",
              "      <td>1633.728027</td>\n",
              "      <td>1207.008057</td>\n",
              "      <td>SNOTEL:1129_WA_SNTL</td>\n",
              "      <td>1633.728027</td>\n",
              "      <td>36587.182453</td>\n",
              "      <td>20.70</td>\n",
              "      <td>SNOTEL:863_WA_SNTL</td>\n",
              "      <td>1353.312012</td>\n",
              "      <td>37587.651716</td>\n",
              "      <td>15.80</td>\n",
              "      <td>SNOTEL:375_WA_SNTL</td>\n",
              "      <td>1405.128052</td>\n",
              "      <td>38368.001172</td>\n",
              "      <td>18.60</td>\n",
              "      <td>SNOTEL:702_WA_SNTL</td>\n",
              "      <td>1374.647949</td>\n",
              "      <td>48630.352344</td>\n",
              "      <td>18.80</td>\n",
              "      <td>SNOTEL:1231_WA_SNTL</td>\n",
              "      <td>1207.008057</td>\n",
              "      <td>49212.092327</td>\n",
              "      <td>8.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>38c54275-89ca-48e7-b8e6-c6ef320622f3</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>4.8</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-118.83573 44.00653, -118.83573 44.0...</td>\n",
              "      <td>8.004374</td>\n",
              "      <td>8.64</td>\n",
              "      <td>7.70</td>\n",
              "      <td>20.10</td>\n",
              "      <td>2.40</td>\n",
              "      <td>1713.585596</td>\n",
              "      <td>1597.151978</td>\n",
              "      <td>2334.768066</td>\n",
              "      <td>1472.183960</td>\n",
              "      <td>SNOTEL:563_OR_SNTL</td>\n",
              "      <td>1597.151978</td>\n",
              "      <td>24954.655814</td>\n",
              "      <td>7.70</td>\n",
              "      <td>SNOTEL:605_OR_SNTL</td>\n",
              "      <td>1514.855957</td>\n",
              "      <td>67864.200582</td>\n",
              "      <td>5.20</td>\n",
              "      <td>SNOTEL:422_OR_SNTL</td>\n",
              "      <td>1472.183960</td>\n",
              "      <td>70838.183402</td>\n",
              "      <td>2.40</td>\n",
              "      <td>SNOTEL:494_OR_SNTL</td>\n",
              "      <td>1648.968018</td>\n",
              "      <td>71148.646775</td>\n",
              "      <td>7.80</td>\n",
              "      <td>SNOTEL:477_OR_SNTL</td>\n",
              "      <td>2334.768066</td>\n",
              "      <td>73240.404852</td>\n",
              "      <td>20.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>ce76ce00-c8b5-4597-8ca3-1ec9db795b50</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>6.1</td>\n",
              "      <td>other</td>\n",
              "      <td>POLYGON ((-111.20904 43.56554, -111.20904 43.5...</td>\n",
              "      <td>10.429468</td>\n",
              "      <td>10.56</td>\n",
              "      <td>9.30</td>\n",
              "      <td>17.80</td>\n",
              "      <td>5.00</td>\n",
              "      <td>2417.368799</td>\n",
              "      <td>2490.216064</td>\n",
              "      <td>2822.447998</td>\n",
              "      <td>2072.639893</td>\n",
              "      <td>SNOTEL:770_ID_SNTL</td>\n",
              "      <td>2072.639893</td>\n",
              "      <td>29685.753297</td>\n",
              "      <td>5.00</td>\n",
              "      <td>SNOTEL:1082_WY_SNTL</td>\n",
              "      <td>2822.447998</td>\n",
              "      <td>32863.836817</td>\n",
              "      <td>17.80</td>\n",
              "      <td>SNOTEL:689_WY_SNTL</td>\n",
              "      <td>2499.360107</td>\n",
              "      <td>33528.014335</td>\n",
              "      <td>9.30</td>\n",
              "      <td>SNOTEL:347_MT_SNTL</td>\n",
              "      <td>2490.216064</td>\n",
              "      <td>38908.254729</td>\n",
              "      <td>15.60</td>\n",
              "      <td>SNOTEL:761_ID_SNTL</td>\n",
              "      <td>2202.179932</td>\n",
              "      <td>41638.329171</td>\n",
              "      <td>5.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>6e96bf06-cbc5-45b5-a36b-e37864226099</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>2.5</td>\n",
              "      <td>sierras</td>\n",
              "      <td>POLYGON ((-118.55726 37.17447, -118.55726 37.1...</td>\n",
              "      <td>2.267444</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.33</td>\n",
              "      <td>11.99</td>\n",
              "      <td>0.98</td>\n",
              "      <td>3108.960000</td>\n",
              "      <td>3017.520000</td>\n",
              "      <td>3474.720000</td>\n",
              "      <td>2956.560000</td>\n",
              "      <td>CDEC:SWM</td>\n",
              "      <td>3108.960000</td>\n",
              "      <td>860.125172</td>\n",
              "      <td>2.26</td>\n",
              "      <td>CDEC:BGP</td>\n",
              "      <td>2987.040000</td>\n",
              "      <td>9797.156249</td>\n",
              "      <td>0.98</td>\n",
              "      <td>CDEC:RCK</td>\n",
              "      <td>2956.560000</td>\n",
              "      <td>24347.787316</td>\n",
              "      <td>8.69</td>\n",
              "      <td>CDEC:MTM</td>\n",
              "      <td>3017.520000</td>\n",
              "      <td>28836.544441</td>\n",
              "      <td>11.99</td>\n",
              "      <td>CDEC:UTY</td>\n",
              "      <td>3474.720000</td>\n",
              "      <td>33458.446680</td>\n",
              "      <td>3.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-668c6b10-b557-49b6-945a-bebbba19200b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-668c6b10-b557-49b6-945a-bebbba19200b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-668c6b10-b557-49b6-945a-bebbba19200b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                  cell_id        date  ...    distance_4  SWE_4\n",
              "166  cdfc27f0-b990-45f7-bac6-7c674cd157ac  2016-01-05  ...  24938.841865  21.30\n",
              "439  06ec1554-a0ea-41cf-85f8-43f4b48c7599  2016-01-19  ...  49212.092327   8.40\n",
              "47   38c54275-89ca-48e7-b8e6-c6ef320622f3  2016-01-05  ...  73240.404852  20.10\n",
              "167  ce76ce00-c8b5-4597-8ca3-1ec9db795b50  2016-01-05  ...  41638.329171   5.10\n",
              "83   6e96bf06-cbc5-45b5-a36b-e37864226099  2016-01-05  ...  33458.446680   3.33\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindf = traindf[['cell_id','date','SWE','region','geometry','mean_inversed_swe',\n",
        "                   'mean_local_swe','median_local_swe','max_local_swe','min_local_swe',\n",
        "                   'mean_local_elevation','median_local_elevation','max_local_elevation','min_local_elevation',]]\n",
        "                   \n",
        "print(traindf.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz4DAKdyzUq4",
        "outputId": "1205f5fc-76a3-4705-e7ae-30bf69803c39"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cell_id                   0\n",
            "date                      0\n",
            "SWE                       0\n",
            "region                    0\n",
            "geometry                  0\n",
            "mean_inversed_swe         0\n",
            "mean_local_swe            0\n",
            "median_local_swe          0\n",
            "max_local_swe             0\n",
            "min_local_swe             0\n",
            "mean_local_elevation      0\n",
            "median_local_elevation    0\n",
            "max_local_elevation       0\n",
            "min_local_elevation       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udf7IEQnIMOe"
      },
      "source": [
        "# Modis Data\n",
        "\n",
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "import requests\n",
        "import ee\n",
        "from datetime import datetime, timedelta\n",
        "import signal\n",
        "\n",
        "class TimeoutException(Exception):   # Custom exception class\n",
        "    pass\n",
        "\n",
        "def timeout_handler(signum, frame):   # Custom signal handler\n",
        "    raise TimeoutException\n",
        "\n",
        "signal.signal(signal.SIGALRM, timeout_handler)\n",
        "\n",
        "traindf[\"date\"] = pd.to_datetime(traindf.date)\n",
        "trainfeatures['date'] = pd.to_datetime(trainfeatures.date)\n",
        "\n",
        "#I am creating a string version of the date to use as a filename\n",
        "traindf[\"datestring\"] = traindf.date.map(lambda d: str(d.year)+d.strftime('%j'))\n",
        "\n",
        "#Now I calculate my centroid from the provided geometry\n",
        "#Ignore the warnings this creates. It is in a projected crs\n",
        "traindf[\"centroid\"] = traindf.geometry.to_crs('+proj=cea').centroid\n",
        "traindf[\"center_lat\"] = traindf.centroid.y\n",
        "traindf[\"center_long\"] = traindf.centroid.x\n",
        "\n",
        "#Logging in to Earth Engine\n",
        "try:\n",
        "        ee.Initialize()\n",
        "except Exception as e:\n",
        "        ee.Authenticate()\n",
        "        ee.Initialize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqbPeNPdaI1n",
        "outputId": "978c9766-f2c8-4812-8ab3-6e08e9453dc5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/geopandas/geodataframe.py:1387: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.7/dist-packages/geopandas/geodataframe.py:1387: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pull_MODIS(traindf, modis, overwrite = False, names_only = False):\n",
        "  filelocations = []\n",
        "  x = 0\n",
        "\n",
        "  for i in range(len(traindf.SWE)):\n",
        "\n",
        "    #create a name for the image\n",
        "    pict_name = traindf.cell_id[i] + '_' + modis + '_' + traindf.datestring[i] + '.jpg'\n",
        "\n",
        "    #create the whole filename with path to the correct folder\n",
        "    filename = os.path.join('/content/', modis, pict_name)\n",
        "\n",
        "    if names_only:\n",
        "      filelocations.append(filename)\n",
        "      x += 1\n",
        "      if x % 5000 == 0:\n",
        "        print(f'{x} files already exist')\n",
        "\n",
        "    elif os.path.exists(filename) and not overwrite:\n",
        "      filelocations.append(filename)\n",
        "      x += 1\n",
        "      if x % 5000 == 0:\n",
        "        print(f'{x} files already exist')\n",
        "\n",
        "    else:\n",
        "      #We need a start date and an end date. Just like a regular python slice, \n",
        "      #the end date is not included, so by using a 1 day frame, I am actually limiting\n",
        "      #the range to only the day in question\n",
        "      start_date = traindf.date[i] - timedelta(days = 7)\n",
        "      end_date = traindf.date[i] + timedelta(days = 1)\n",
        "\n",
        "      #First I get the image collection from the MODIS data, filter it only to the days in question\n",
        "      #and select my bands, then sort so the most recent day in the group is at the top\n",
        "      Collection = ee.ImageCollection(f'MODIS/006/{modis}') \\\n",
        "                  .filter(ee.Filter.date(start_date, end_date)) \\\n",
        "                  .filter(ee.Filter.notNull(['system:index'])) \\\n",
        "                  .select(['NDSI_Snow_Cover', 'Snow_Albedo_Daily_Tile', 'NDSI']) \\\n",
        "                  .sort('system:index', False) \n",
        "\n",
        "      #I create a google earth images point based on the area centroid\n",
        "      centroid = ee.Geometry.Point(traindf.center_long[i], traindf.center_lat[i])\n",
        "\n",
        "      #Because the image collection is limited to a single day, there is only one image\n",
        "      #So I just take it\n",
        "      point = Collection.first().unmask(0)\n",
        "\n",
        "      # Get individual band arrays and build them into an RGB image\n",
        "      # The \"buffer\" is a circular distance around the point, measured in meters right now it is 100km\n",
        "      rgb = ee.Image.rgb(point.clip(centroid.buffer(10000)).select('NDSI_Snow_Cover').divide(100), #I divide by 100 to get it between 0 and 1\n",
        "                        point.clip(centroid.buffer(10000)).select('Snow_Albedo_Daily_Tile').divide(100), #I divide by 100 to get it between 0 and 1\n",
        "                        point.clip(centroid.buffer(10000)).select('NDSI').divide(10000)).visualize() #I divide by 10000 to get it between 0 and 1\n",
        "\n",
        "      #Now I get the url for the image\n",
        "      url = rgb.getThumbURL()\n",
        "\n",
        "      #add the name to my list I created earlier\n",
        "      filelocations.append(filename)\n",
        "\n",
        "      #now I open the url and download the image to the specified file location\n",
        "      response = requests.get(url, stream=True)\n",
        "      with open(filename, 'wb') as out_file:\n",
        "          shutil.copyfileobj(response.raw, out_file)\n",
        "      del response\n",
        "    \n",
        "  traindf[f\"{modis}_filelocations\"] = filelocations"
      ],
      "metadata": {
        "id": "uijUxpazQtC2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pull_MODIS_list(traindf, modis, signal_timer = 5):\n",
        "  datalist = []\n",
        "  x= 0\n",
        "\n",
        "  still_working = True\n",
        "  while still_working:\n",
        "    try:\n",
        "      Collection = ee.ImageCollection(f'MODIS/006/{modis}') \\\n",
        "                  .select(['NDSI_Snow_Cover', 'Snow_Albedo_Daily_Tile', 'NDSI']) \n",
        "      \n",
        "    except Exception as e:\n",
        "      print(\"Some Error with Image Collection\")\n",
        "    else: \n",
        "      signal.alarm(0)\n",
        "      still_working = False        \n",
        "  \n",
        "\n",
        "  for i in range(len(traindf.SWE)):\n",
        "    still_working = True\n",
        "    while still_working:\n",
        "      signal.alarm(signal_timer)\n",
        "      try:\n",
        "        row = [traindf.cell_id[i]]\n",
        "\n",
        "        #We need a start date and an end date. Just like a regular python slice, \n",
        "        #the end date is not included, so by using a 1 day frame, I am actually limiting\n",
        "        #the range to only the day in question\n",
        "        start_date = traindf.date[i] - timedelta(days = 7)\n",
        "        end_date = traindf.date[i] + timedelta(days = 1)\n",
        "\n",
        "        #First I get the image collection from the MODIS data, filter it only to the days in question\n",
        "        #and select my bands, then sort so the most recent day in the group is at the top\n",
        "        DatedCollection = Collection.filter(ee.Filter.date(start_date, end_date)) \\\n",
        "                                    .filter(ee.Filter.notNull(['system:index'])) \\\n",
        "                                    .sort('system:index', False) \n",
        "\n",
        "        #Because the image collection is limited to a single day, there is only one image\n",
        "        #So I just take it\n",
        "        point = DatedCollection.first().unmask(0)\n",
        "        aoi = ee.Geometry.Polygon(list(traindf.iloc[i].geometry.exterior.coords))\n",
        "        bands = point.sampleRectangle(region = aoi)\n",
        "\n",
        "\n",
        "        # Get individual band arrays.\n",
        "        SnowCover = bands.get('NDSI_Snow_Cover')\n",
        "        Albedo = bands.get('Snow_Albedo_Daily_Tile')\n",
        "        NDSI = bands.get('NDSI')\n",
        "\n",
        "        # Transfer the arrays from server to client and cast as np array.\n",
        "        SnowCover = np.array(SnowCover.getInfo()).mean() / 100\n",
        "        Albedo = np.array(Albedo.getInfo()).mean() /100\n",
        "        NDSI = np.array(NDSI.getInfo()).mean() /10000\n",
        "\n",
        "        row.extend([SnowCover, Albedo, NDSI])\n",
        "\n",
        "        datalist.append(row)\n",
        "      \n",
        "      except TimeoutException:\n",
        "        print(f\"Request Timeout for cell_id {traindf.cell_id[i]}\")\n",
        "      \n",
        "      except Exception as e:\n",
        "        print(\"Some other Error\")\n",
        "      else: \n",
        "        signal.alarm(0)\n",
        "        still_working = False\n",
        "        x+=1\n",
        "        if x % 100 == 0:\n",
        "          print(f'{x} out of {len(traindf.SWE)} complete')\n",
        "\n",
        "  data = pd.DataFrame(datalist, columns = ['cell_id', 'SnowCover', 'Albedo', 'NDSI'])\n",
        "  print(data)\n",
        "  #traindf[f\"{modis}_filelocations\"] = filelocations"
      ],
      "metadata": {
        "id": "GaaXWEf7P8MX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time "
      ],
      "metadata": {
        "id": "Ud6-utPfU2wJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "pull_MODIS_list(traindf, modis = \"MOD10A1\")\n",
        "print(f'New Time: {time.time() - start}')\n",
        "\n",
        "start = time.time()\n",
        "pull_MODIS(traindf, modis = \"MOD10A1\", overwrite = False, names_only = False)\n",
        "print(f'Old Time: {time.time() - start}')\n",
        "\n",
        "#!zip -r '/content/drive/MyDrive/snowcapstone team spring 2022/MODIS_Data/MOD10A1_sierras.zip'  '/content/drive/MyDrive/snowcapstone team spring 2022/MODIS_Data/MOD10A1/'\n",
        "#!zip -r '/content/drive/MyDrive/snowcapstone team spring 2022/MODIS_Data/MYD10A1_sierras.zip'  '/content/drive/MyDrive/snowcapstone team spring 2022/MODIS_Data/MYD10A1/'"
      ],
      "metadata": {
        "id": "JPyROj2bLEQK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "ba8e14d4-3b39-41e6-c386-017a42b1b9c6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 out of 500 complete\n",
            "200 out of 500 complete\n",
            "300 out of 500 complete\n",
            "400 out of 500 complete\n",
            "500 out of 500 complete\n",
            "                                  cell_id  SnowCover  Albedo      NDSI\n",
            "0    00c4db22-a423-41a4-ada6-a8b1b04153a4      0.000   0.000  0.376250\n",
            "1    018cf1a1-f945-4097-9c47-0c4690538bb5      0.000   0.000  0.424373\n",
            "2    01be2cc7-ef77-4e4d-80ed-c4f8139162c3      0.000   0.000  0.376310\n",
            "3    02c3ec4a-8de4-4284-9ec1-5a942d3d098e      0.232   0.104  0.357160\n",
            "4    02cf33c2-c8e2-48b9-bf72-92506e97e251      0.720   0.314  0.726033\n",
            "..                                    ...        ...     ...       ...\n",
            "495  58c7b21d-f68f-4293-907b-34d0a0976bab      0.577   0.397  0.583700\n",
            "496  5e252b65-58dd-421f-a0db-3d4669bfb235      0.000   0.000  0.276933\n",
            "497  629e076c-b9b1-4716-8e60-a225668de40f      0.364   0.274  0.602127\n",
            "498  630bae26-a6cc-4a36-bbe5-40dc15b38dea      0.644   0.540  0.649900\n",
            "499  631ed3c9-7863-4e7c-86fa-4bfb043f2851      0.000   0.000  0.408247\n",
            "\n",
            "[500 rows x 4 columns]\n",
            "New Time: 370.08906412124634\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-3f8fc4b68548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpull_MODIS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"MOD10A1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Old Time: {time.time() - start}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-4b3290f60d04>\u001b[0m in \u001b[0;36mpull_MODIS\u001b[0;34m(traindf, modis, overwrite, names_only)\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0;31m#now I open the url and download the image to the specified file location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m           \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/MOD10A1/MOD10A1/00c4db22-a423-41a4-ada6-a8b1b04153a4_MOD10A1_2016005.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Copernicus Data"
      ],
      "metadata": {
        "id": "7i_zmwwN4Q5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MATCH FUNCTION"
      ],
      "metadata": {
        "id": "5VIWcB9QjkDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_copernicus(traindf, overwrite = False):\n",
        "  traindf[\"copernicus_filelocations\"] = \"blank\"\n",
        "  x = 0\n",
        "  length_cell_id = len(traindf.cell_id.unique())\n",
        "\n",
        "  for i in traindf.cell_id.unique():\n",
        "    #create a name for the image\n",
        "    pict_name = i + '_' + 'copernicus90m'\n",
        "\n",
        "    #create the whole filename with path to the correct folder\n",
        "    filename = os.path.join('/content/drive/MyDrive/snowcapstone team spring 2022/Copernicus_Data', pict_name)\n",
        "\n",
        "    # Adapted from https://planetarycomputer.microsoft.com/dataset/cop-dem-glo-90#Example-Notebook :\n",
        "    \n",
        "    if not os.path.exists(filename + '.png') or overwrite:\n",
        "      client = Client.open(\n",
        "          \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
        "          ignore_conformance=True,\n",
        "      )\n",
        "\n",
        "      point = [traindf.loc[traindf.cell_id == i, \"center_long\"].iloc[0], \n",
        "              traindf.loc[traindf.cell_id == i, \"center_lat\"].iloc[0]]\n",
        "      \n",
        "      search = client.search(\n",
        "          collections=[\"cop-dem-glo-90\"],\n",
        "          intersects={\"type\": \"Point\", \"coordinates\": point},\n",
        "      )\n",
        "\n",
        "      items = list(search.get_items())\n",
        "\n",
        "      signed_asset = planetary_computer.sign(items[0].assets[\"data\"])\n",
        "      \n",
        "      data = (\n",
        "          xarray.open_rasterio(signed_asset.href)\n",
        "          .squeeze()\n",
        "          .drop(\"band\")\n",
        "          .mean()\n",
        "      )\n",
        "      min_lon = min([j[0] for j in [y for y in traindf.loc[traindf.cell_id == i, \"geometry\"].iloc[0].centroid.buffer(.05).boundary.coords]])\n",
        "      min_lat = min([j[1] for j in [y for y in traindf.loc[traindf.cell_id == i, \"geometry\"].iloc[0].centroid.buffer(.05).boundary.coords]])\n",
        "      max_lon = max([j[0] for j in [y for y in traindf.loc[traindf.cell_id == i, \"geometry\"].iloc[0].centroid.buffer(.05).boundary.coords]])\n",
        "      max_lat = max([j[1] for j in [y for y in traindf.loc[traindf.cell_id == i, \"geometry\"].iloc[0].centroid.buffer(.05).boundary.coords]])\n",
        "\n",
        "      mask_lon = (data.x >= min_lon) & (data.x <= max_lon)\n",
        "      mask_lat = (data.y >= min_lat) & (data.x <= max_lat)\n",
        "\n",
        "      cropped_data = data.where(mask_lon & mask_lat, drop=True)\n",
        "\n",
        "      hillshade = xrspatial.hillshade(cropped_data)\n",
        "      img = stack(shade(hillshade, cmap=[\"white\", \"gray\"]), shade(cropped_data, cmap=Elevation, alpha=128))\n",
        "      export_image(img=img, filename=filename, background=None)\n",
        "\n",
        "    traindf.loc[traindf.cell_id == i, \"copernicus_filelocations\"] = filename + '.png'\n",
        "    if x % 500 == 0:\n",
        "      print(f'{x} out of {length_cell_id} complete')\n",
        "    x += 1"
      ],
      "metadata": {
        "id": "MGcd6Xo7_7Pl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_copernicus(traindf, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "DuTh-zCfKDNQ",
        "outputId": "a2439b83-1941-49df-dd7a-9b8ad80ec871"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-725402e4284d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_copernicus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-bfab6b2ad182>\u001b[0m in \u001b[0;36mget_copernicus\u001b[0;34m(traindf, overwrite)\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mmax_lat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraindf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraindf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"geometry\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentroid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboundary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m       \u001b[0mmask_lon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmin_lon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_lon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m       \u001b[0mmask_lat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmin_lat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_lat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xarray/core/common.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    238\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         raise AttributeError(\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0;34m\"{!r} object has no attribute {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         )\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataArray' object has no attribute 'x'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindf = traindf.drop([\"region\", 'geometry', 'datestring', 'centroid', 'center_lat', 'center_long'], axis = 1)\n",
        "traindf.head()"
      ],
      "metadata": {
        "id": "PJrYQqcVZNpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(traindf).to_csv('/content/drive/MyDrive/snowcapstone team spring 2022/Modeling/traindf_allregions.csv')"
      ],
      "metadata": {
        "id": "352W4g_z6nZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ-aDo6l3llL"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "#Potential Ideas:\n",
        "#Include reverse distance interpolation.\n",
        "#\n",
        "\n",
        "def get_stations(df, num_stations = 5):\n",
        "  #Returns the average SWE from the X closest measurement stations on the same day\n",
        "  averages = []\n",
        "  average_elevation = []\n",
        "  median = []\n",
        "  median_elevation = []\n",
        "  max = []\n",
        "  max_elevation = []\n",
        "  #Calculating distance matrix\n",
        "  dist1 = gpd.GeoDataFrame(geometry = df.geometry.unique(), crs = \"EPSG:4326\").to_crs('+proj=cea')\n",
        "  dist2 = gpd.GeoDataFrame(geometry = trainmeta.geometry, crs = \"EPSG:4326\").to_crs('+proj=cea') \n",
        "\n",
        "  distmatrix = dist2.geometry.apply(lambda g: dist1.geometry.boundary.distance(g))\n",
        "  distmatrix.set_axis(df.cell_id.unique(), axis = 1, inplace = True)\n",
        "  distmatrix[\"station_id\"] = trainmeta.station_id.unique()\n",
        "  \n",
        "  #for each row in the df\n",
        "  for index, row in df.iterrows():\n",
        "    station_dist =distmatrix[[\"station_id\", row.cell_id]]\n",
        "\n",
        "    start_date = row.date - timedelta(days = 7)\n",
        "    end_date = row.date\n",
        "    after_start_date = trainfeatures[\"date\"] >= start_date\n",
        "    before_end_date = trainfeatures[\"date\"] <= end_date\n",
        "    between_two_dates = after_start_date & before_end_date\n",
        "    swes = trainfeatures.loc[between_two_dates]\n",
        "\n",
        "    station_swe = station_dist.merge(swes, how = 'left', on='station_id')\n",
        "    station_swe = station_swe[station_swe[\"SWE\"].notna()]\n",
        "\n",
        "    station_swe.sort_values(by = [row.cell_id, \"date\"], inplace = True)\n",
        "\n",
        "    #This is where interpolation can happen\n",
        "\n",
        "    averages.append(station_swe.head(num_stations).SWE.mean())\n",
        "    average_elevation.append(station_swe.head(num_stations).elevation_m.mean())\n",
        "    median.append(station_swe.head(num_stations).SWE.median())\n",
        "    median_elevation.append(station_swe.head(num_stations).elevation_m.median())\n",
        "    max.append(station_swe.head(num_stations).SWE.max())\n",
        "    max_elevation.append(station_swe.head(num_stations).elevation_m.max())\n",
        "\n",
        "  #return averages, median, max, average_elevation, median_elevation, max_elevation\n",
        "  return averages, average_elevation, median, median_elevation, max, max_elevation\n",
        "  '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGVnLsQbCyN8"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "#Turns off a bunch of errors\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "averages, average_elevation, median, median_elevation, max, max_elevation = get_stations(traindf)\n",
        "\n",
        "pd.options.mode.chained_assignment = 'warn'\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwDxgDwIo0CR"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "traindf[\"mean_local_swe\"] = averages\n",
        "traindf[\"median_local_swe\"] = median\n",
        "traindf[\"max_local_swe\"] = max\n",
        "traindf[\"mean_local_elevation\"] = average_elevation\n",
        "traindf[\"median_local_elevation\"] = median_elevation\n",
        "traindf[\"max_local_elevation\"] = max_elevation\n",
        "\n",
        "print(traindf.isna().sum())\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ingesting Sentinel 2 Data"
      ],
      "metadata": {
        "id": "Q8CQuwM2ywQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pulling in Data by date/1k square and saving as .tiff format"
      ],
      "metadata": {
        "id": "5qlHktGcy4cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Test that ee connection is still live\n",
        "try:\n",
        "        ee.Initialize()\n",
        "except Exception as e:\n",
        "        ee.Authenticate()\n",
        "        ee.Initialize()"
      ],
      "metadata": {
        "id": "Vc5HIf1ezGHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Import additional packages (check for duplicates)\n",
        "import pickle\n",
        "import time\n",
        "import math\n",
        "import requests, zipfile, io\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "0lR9GObqzOQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Image Collection\n",
        "\n",
        "Define image selection to Copernicus/S2 or Sentinel 2 data. \n",
        "\n",
        "Available bands and resolution here: https://gisgeography.com/sentinel-2-bands-combinations/\n",
        "\n",
        "The following visualizations are the most applicable to our study:\n",
        "\n",
        "Geology: Bands B12, B11, B2\n",
        "Vegetation: B8-B4/B8+B4\n",
        "\n",
        "Starting with focus on geology bands, this pulls in the B12(R), B11(G), B4(B)\n",
        "\n",
        "B12 and B11 are at 20m resolution, and B4 is at 10m resolution"
      ],
      "metadata": {
        "id": "gZSc2WkSzk_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentinel 2"
      ],
      "metadata": {
        "id": "by4m_1K81-aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining image\n",
        "sen2 = ee.ImageCollection(\"COPERNICUS/S2\").filterDate(startDate, endDate) \n",
        "\n",
        "#selecting bands\n",
        "sen2 = sen2.select([\"B12\",\"B11\",\"B2\"])"
      ],
      "metadata": {
        "id": "lPe39t4w2G2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentinel 1\n"
      ],
      "metadata": {
        "id": "nFUEMt2UUfEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining image\n",
        "\n",
        "sen1 = ee.ImageCollection(\"COPERNICUS/S1_GRD\").filterDate(startDate, endDate) \n",
        "\n",
        "#selecting bands\n",
        "sen1_A = sen1.select([\"HH\",\"HV\",\"angle\"])\n",
        "sen1_B = sen1.select([\"VV\", \"VH\", \"angle\"])"
      ],
      "metadata": {
        "id": "cx9vSjgxUePq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to define image download\n",
        "\n",
        "Create a funciton to download imagery. Takes the centroid from above and size input and pulls images into google drive. \n",
        "\n",
        "Len = total size of image in meters computed as the resolution of the image bands being pulled in, and the number of pixels we want to capture total (224x224). Then create bounding box around the circle to get a square. "
      ],
      "metadata": {
        "id": "FCrcVtj521fV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def image_download(image,point,image_res,n_pixels,folder_name, image_name, storage=\"Drive\"):\n",
        "    \n",
        "    \"\"\"\n",
        "    Function to download satellite images from a ee.imageCollection object.\n",
        "    We first generate a bounding box of image_res*n_pixels meters around \"point\",\n",
        "    then we clip that region from the image collection, take the mean image from the collection,\n",
        "    and send that as a task to the Google Earth Engine. \n",
        "    After that, we download the image Google Cloud Storage if storage==\"Cloud\", \n",
        "    to Google Drive if storage==\"Drive\" or to a local folder if storage==\"local\".\n",
        "    \n",
        "    Inputs:\n",
        "    -image= ee.ImageCollection object\n",
        "    -point= ee.Geometry.Point object\n",
        "    -image_res= resolution of the image in meters\n",
        "    -n_pixels= number of pixels to extract on the images\n",
        "    -storage= string indicating if we are storing the images in Google Cloud,Google Drive or locally.\n",
        "              Defaults to local storage.\n",
        "    -folder_name= string with Google Cloud bucket name if storage==\"Cloud\"\n",
        "                  string with the name of a folder in the root of Google Drive if storage==\"Drive\"\n",
        "                  string with the path to the image if storage==\"local\"\n",
        "    -image_name= string with the image_name for the TIFF image.\n",
        "\n",
        "    Output:\n",
        "     When storage==\"Drive\":\n",
        "     -task= an EE task object. we can then use task.status() to check the status of the task.\n",
        "     If the task is completed, we will see a TIFF image in \"folder_name\" with name \"image_name.tif\".\n",
        "     The image has 3 dimensions, where the first 2 are n_pixels, and the 3rd is the number of bands of \"image\".\n",
        "     When storage==\"local\":\n",
        "     -there is no output, but we will see one TIFF file per band of our image in the folder \"folder_name\".\n",
        "    \"\"\"\n",
        "    #generating the box around the point\n",
        "    len=image_res*n_pixels # for sen2, 20 meters * 224 pixels\n",
        "    region= point.buffer(len/2).bounds().getInfo()['coordinates']\n",
        "    #defining the rectangle\n",
        "    coords=np.array(region)\n",
        "    #taking min and maxs of coordinates to define the rectangle\n",
        "    coords=[np.min(coords[:,:,0]), np.min(coords[:,:,1]), np.max(coords[:,:,0]), np.max(coords[:,:,1])]\n",
        "    rectangle=ee.Geometry.Rectangle(coords)\n",
        "    \n",
        "    if storage==\"Drive\":\n",
        "        #generating the export task (dimensions is \"WIDTHxHEIGHT\")\n",
        "        task=ee.batch.Export.image.toDrive(image=image.filterBounds(rectangle).mean(), \n",
        "                            folder=folder_name, \n",
        "                            description=image_name, \n",
        "                            region=str(region), dimensions=str(n_pixels)+\"x\"+str(n_pixels))\n",
        "        #starting the task\n",
        "        task.start()\n",
        "        return task\n",
        "    \n",
        "    if storage==\"local\":\n",
        "        #downloading the image\n",
        "        r=requests.get( image.filterBounds(rectangle).mean().getDownloadURL({\n",
        "                            'name': image_name, \n",
        "                            'region': str(region),\n",
        "                            'dimensions': str(n_pixels)+\"x\"+str(n_pixels)}))\n",
        "        #unzip it to the selected directory\n",
        "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "        z.extractall(folder_name)"
      ],
      "metadata": {
        "id": "WvXDfzOq4VvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST"
      ],
      "metadata": {
        "id": "KY3Rcpvm-g6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test image\n",
        "test=ee.Geometry.Point(-120.61888999873261,39.675880337476684)\n",
        "\n",
        "#running function\n",
        "image_download(image=sen2,point=test,image_res=100,n_pixels=224,folder_name='Sen2_Tiff', image_name='test_image', storage=\"local\")"
      ],
      "metadata": {
        "id": "vJnUWTJB5EFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('Sen2_Tiff')"
      ],
      "metadata": {
        "id": "MkvywTLY-V6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterate over all of the dataframe"
      ],
      "metadata": {
        "id": "tHmiPzJr-jDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traindf.head()"
      ],
      "metadata": {
        "id": "FoXWDfyZ-lUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(traindf)):\n",
        "\n",
        "    #create a name for the image\n",
        "    image_name = traindf.cell_id[i] + '_sentinel2_' + traindf.datestring[i] + '.jpg'\n",
        "\n",
        "    \n",
        "    startDate = traindf.date[i] - timedelta(days = 365)\n",
        "    endDate = traindf.date[i] + timedelta(days = 1)\n",
        "    year = startDate.year\n",
        "    print(year)\n",
        "    print(startDate)\n",
        "    \n",
        "      #defining image\n",
        "\n",
        "    sen2 = ee.ImageCollection(\"COPERNICUS/S2\")\n",
        "      # filter date\n",
        "    sen2 = sen2.filterDate(startDate, endDate) \n",
        "      #applying cloud masking\n",
        "      #selecting bands\n",
        "    sen2 = sen2.select([\"B12\",\"B11\",\"B2\"])\n",
        "    \n",
        "      #I create a google earth images point based on the area centroid\n",
        "    centroid = ee.Geometry.Point(traindf.center_long[i], traindf.center_lat[i])\n",
        "    print(centroid)\n",
        "      \n",
        "    image_download(image=sen2, point=centroid, image_res=20, n_pixels=224, folder_name='Sen2_Tiff', image_name='image_name', storage=\"local\")\n"
      ],
      "metadata": {
        "id": "ZHuBtaXj-pYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(traindf)):\n",
        "\n",
        "    #create a name for the image\n",
        "    image_name = traindf.cell_id[i] + '_sentinel1a_' + traindf.datestring[i] + '.jpg'\n",
        "\n",
        "    \n",
        "    startDate = traindf.date[i] - timedelta(days = 7)\n",
        "    endDate = traindf.date[i] + timedelta(days = 1)\n",
        "    year = startDate.year\n",
        "    print(year)\n",
        "    print(startDate)\n",
        "    \n",
        "\n",
        "      #defining image\n",
        "\n",
        "    sen1 = ee.ImageCollection(\"COPERNICUS/S1_GRD\").filterDate(startDate, endDate) \n",
        "\n",
        "      #selecting bands\n",
        "    sen1_A = sen1.select([\"HH\",\"HV\",\"angle\"])\n",
        "      # filter date\n",
        "\n",
        "    \n",
        "      #I create a google earth images point based on the area centroid\n",
        "    centroid = ee.Geometry.Point(traindf.center_long[i], traindf.center_lat[i]).buffer(10000)\n",
        "    print(centroid)\n",
        "      \n",
        "    image_download(image=sen1_A, point=centroid, image_res=20, n_pixels=224, folder_name='Sen1a_Tiff', image_name='image_name', storage=\"local\")\n"
      ],
      "metadata": {
        "id": "apj8dWab-pbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(traindf)):\n",
        "\n",
        "    #create a name for the image\n",
        "    image_name = traindf.cell_id[i] + '_sentinel1b_' + traindf.datestring[i] + '.jpg'\n",
        "\n",
        "    \n",
        "    startDate = traindf.date[i] - timedelta(days = 7)\n",
        "    endDate = traindf.date[i] + timedelta(days = 1)\n",
        "    year = startDate.year\n",
        "    print(year)\n",
        "    print(startDate)\n",
        "    \n",
        "\n",
        "\n",
        "    sen1 = ee.ImageCollection(\"COPERNICUS/S1_GRD\").filterDate(startDate, endDate) \n",
        "\n",
        "      #selecting bands\n",
        "    sen1_B = sen1.select([\"VV\", \"VH\", \"angle\"])\n",
        "      # filter date\n",
        "\n",
        "    \n",
        "      #I create a google earth images point based on the area centroid\n",
        "    centroid = ee.Geometry.Point(traindf.center_long[i], traindf.center_lat[i])\n",
        "    print(centroid)\n",
        "      \n",
        "    image_download(image=sen1_b, point=centroid, image_res=20, n_pixels=224, folder_name='Sen1b_Tiff', image_name='image_name', storage=\"local\")\n"
      ],
      "metadata": {
        "id": "zCO4jgCyXI2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading in .tiff images and loading max, min, medians to testdf"
      ],
      "metadata": {
        "id": "e3lLrIlYy94Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pull_SENT2(traindf, overwrite = False, names_only = False):\n",
        "  filelocations = []\n",
        "  x = 0\n",
        "\n",
        "  for i in range(len(traindf.SWE)):\n",
        "\n",
        "    #create a name for the image\n",
        "    pict_name = traindf.cell_id[i] + '_sentinel2_' + traindf.datestring[i] + '.jpg'\n",
        "\n",
        "    #create the whole filename with path to the correct folder\n",
        "    filename = os.path.join('/content/drive/MyDrive/snowcapstone team spring 2022/Sen2_Tiff', pict_name)\n",
        "\n",
        "    if names_only:\n",
        "      filelocations.append(filename)\n",
        "      x += 1\n",
        "      if x % 5000 == 0:\n",
        "        print(f'{x} files already exist')\n",
        "\n",
        "    elif os.path.exists(filename) and not overwrite:\n",
        "      filelocations.append(filename)\n",
        "      x += 1\n",
        "      if x % 5000 == 0:\n",
        "        print(f'{x} files already exist')\n",
        "\n",
        "    else:\n",
        "      #We need a start date and an end date. Just like a regular python slice, \n",
        "      #the end date is not included, so by using a 1 day frame, I am actually limiting\n",
        "      #the range to only the day in question\n",
        "      start_date = traindf.date[i] - timedelta(days = 7)\n",
        "      end_date = traindf.date[i] + timedelta(days = 1)\n",
        "\n",
        "      #First I get the image collection from the MODIS data, filter it only to the days in question\n",
        "      #and select my bands, then sort so the most recent day in the group is at the top\n",
        "      Collection = ee.ImageCollection('COPERNICUS/S2') \\\n",
        "                  .filter(ee.Filter.date(start_date, end_date)) \\\n",
        "                  .select(['B11', 'B12', 'B2']) \\\n",
        "\n",
        "      #I create a google earth images point based on the area centroid\n",
        "      centroid = ee.Geometry.Point(traindf.center_long[i], traindf.center_lat[i])\n",
        "\n",
        "      #Because the image collection is limited to a single day, there is only one image\n",
        "      #So I just take it\n",
        "      point = Collection.first().unmask(0)\n",
        "\n",
        "      # Get individual band arrays and build them into an RGB image\n",
        "      # The \"buffer\" is a circular distance around the point, measured in meters right now it is 100km\n",
        "      rgb = ee.Image.rgb(point.clip(centroid.buffer(10000)).select('B11'),\n",
        "                        point.clip(centroid.buffer(10000)).select('B12'),\n",
        "                        point.clip(centroid.buffer(10000)).select('B2'))\n",
        "\n",
        "      #Now I get the url for the image\n",
        "      url = rgb.getThumbURL({'min': -20, 'max': 0})\n",
        "\n",
        "      #add the name to my list I created earlier\n",
        "      filelocations.append(filename)\n",
        "\n",
        "      #now I open the url and download the image to the specified file location\n",
        "      response = requests.get(url, stream=True)\n",
        "      with open(filename, 'wb') as out_file:\n",
        "          shutil.copyfileobj(response.raw, out_file)\n",
        "      del response\n",
        "    \n",
        "  traindf[\"Sentinel2_filelocations\"] = filelocations"
      ],
      "metadata": {
        "id": "hZ7Wfjn2boc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pull_SENT2(traindf, overwrite = True)"
      ],
      "metadata": {
        "id": "317utemDdb28"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SnowCast Showdown Data Wrangling.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}